{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "DrtZG214KEs1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd906886af174867b377efb85f2da2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b197731b2de476186d20cdb05010686",
              "IPY_MODEL_646ef05d729448b28df97bc3191088ad",
              "IPY_MODEL_c4baa1d3ce66443fa94a0e787c7110a1"
            ],
            "layout": "IPY_MODEL_df1475597c3b41819fb55d780c213de7"
          }
        },
        "5b197731b2de476186d20cdb05010686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6be5363eef88484f8b9922588a34bb15",
            "placeholder": "​",
            "style": "IPY_MODEL_b4ad4f30bda849099b2fea162c753c5d",
            "value": "README.md: "
          }
        },
        "646ef05d729448b28df97bc3191088ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4061165b0694f07ba65d2cf214ea0d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a513074f12d443c4a98ffd4eda7c5769",
            "value": 1
          }
        },
        "c4baa1d3ce66443fa94a0e787c7110a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4efc3d6f50cd42ecba3af50da34f1a43",
            "placeholder": "​",
            "style": "IPY_MODEL_242f96a904a449ffa247a3312f5e45bb",
            "value": " 8.92k/? [00:00&lt;00:00, 1.05MB/s]"
          }
        },
        "df1475597c3b41819fb55d780c213de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be5363eef88484f8b9922588a34bb15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ad4f30bda849099b2fea162c753c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4061165b0694f07ba65d2cf214ea0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a513074f12d443c4a98ffd4eda7c5769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4efc3d6f50cd42ecba3af50da34f1a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "242f96a904a449ffa247a3312f5e45bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee9528c9c7824417a691836fd0c57daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71efa948def7492e8a6857aeb329ec72",
              "IPY_MODEL_184f772aa1d14e518e70981a0b393456",
              "IPY_MODEL_0e477f561ec34ce189284a662b3d0ef9"
            ],
            "layout": "IPY_MODEL_e408073989c449c694256904152ad160"
          }
        },
        "71efa948def7492e8a6857aeb329ec72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fcd8c377fca4e41bdac91dd15ae0793",
            "placeholder": "​",
            "style": "IPY_MODEL_341511a47a8d407abb5c021d8b5b3b92",
            "value": "squad_v2/train-00000-of-00001.parquet: 100%"
          }
        },
        "184f772aa1d14e518e70981a0b393456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d525cb7da7f4f0ea2b2366264ebf675",
            "max": 16369982,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adee4d3808af479f897e841652441962",
            "value": 16369982
          }
        },
        "0e477f561ec34ce189284a662b3d0ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_858df6d1f0d541b4adfcff246168134e",
            "placeholder": "​",
            "style": "IPY_MODEL_707cc369d1694336bd7a222f9433cf5c",
            "value": " 16.4M/16.4M [00:02&lt;00:00, 7.19MB/s]"
          }
        },
        "e408073989c449c694256904152ad160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fcd8c377fca4e41bdac91dd15ae0793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "341511a47a8d407abb5c021d8b5b3b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d525cb7da7f4f0ea2b2366264ebf675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adee4d3808af479f897e841652441962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "858df6d1f0d541b4adfcff246168134e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707cc369d1694336bd7a222f9433cf5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8261d5e8cd35409ea98748e0fd4586df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3947be0c669341bba30c2d6542361a0b",
              "IPY_MODEL_8b6f9bd3bd58420da4309c68564131e0",
              "IPY_MODEL_a5f782dbc77b479da9d441b5bf6fc824"
            ],
            "layout": "IPY_MODEL_e59ce27f943b4ba1be97cde907448584"
          }
        },
        "3947be0c669341bba30c2d6542361a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37c0af5e8e1e415ab8e2154581df1c61",
            "placeholder": "​",
            "style": "IPY_MODEL_14eae5eb88154deb8b7788e59a9d632e",
            "value": "squad_v2/validation-00000-of-00001.parqu(…): 100%"
          }
        },
        "8b6f9bd3bd58420da4309c68564131e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e0a4a5083e4aab9b3203e4c3def51c",
            "max": 1350511,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87429750ddb84e3aba8a49e4bb983fca",
            "value": 1350511
          }
        },
        "a5f782dbc77b479da9d441b5bf6fc824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa31fe1a8904940aba0f1f290b4355e",
            "placeholder": "​",
            "style": "IPY_MODEL_8a49b6130d434139bd8e6ae79db5ec1a",
            "value": " 1.35M/1.35M [00:00&lt;00:00, 2.51MB/s]"
          }
        },
        "e59ce27f943b4ba1be97cde907448584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37c0af5e8e1e415ab8e2154581df1c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14eae5eb88154deb8b7788e59a9d632e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70e0a4a5083e4aab9b3203e4c3def51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87429750ddb84e3aba8a49e4bb983fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6aa31fe1a8904940aba0f1f290b4355e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a49b6130d434139bd8e6ae79db5ec1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "412f2bbc89a146009001929defe4d9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4759d442965d4314adf8b5d5eb414f0b",
              "IPY_MODEL_e0fb7164bf3b4d5a982211176ee3a963",
              "IPY_MODEL_a6be1e49487b4e55893c810240de27dc"
            ],
            "layout": "IPY_MODEL_265faec9f93e4e3fbe6cbc0ba58561c8"
          }
        },
        "4759d442965d4314adf8b5d5eb414f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f8d858265b4f20bb21f6854353b75d",
            "placeholder": "​",
            "style": "IPY_MODEL_4283276a8fcc403a965554833b5f25f3",
            "value": "Generating train split: 100%"
          }
        },
        "e0fb7164bf3b4d5a982211176ee3a963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f3c5582b3a4860a859d569e2d24d66",
            "max": 130319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45130aa9f380442990e5422338755777",
            "value": 130319
          }
        },
        "a6be1e49487b4e55893c810240de27dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd9fbaf46934e8f8b3ff0b94746a625",
            "placeholder": "​",
            "style": "IPY_MODEL_288eced4bfaa422e9cfb2aae5ec8581f",
            "value": " 130319/130319 [00:00&lt;00:00, 455260.30 examples/s]"
          }
        },
        "265faec9f93e4e3fbe6cbc0ba58561c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f8d858265b4f20bb21f6854353b75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4283276a8fcc403a965554833b5f25f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3f3c5582b3a4860a859d569e2d24d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45130aa9f380442990e5422338755777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dd9fbaf46934e8f8b3ff0b94746a625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288eced4bfaa422e9cfb2aae5ec8581f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc5c692aeb0643fc800522306a694548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6896690385e449fd84db433f6439a161",
              "IPY_MODEL_81852636c19d45ce99ab5642c73dfe56",
              "IPY_MODEL_2ca4b52a0d524983b719359fa81a9a9b"
            ],
            "layout": "IPY_MODEL_c7d220a4f666468b9ee07b2514b0a514"
          }
        },
        "6896690385e449fd84db433f6439a161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5aeec5ac594e02a8af203554510514",
            "placeholder": "​",
            "style": "IPY_MODEL_529263d4bb1d48cb95f549d4bae78302",
            "value": "Generating validation split: 100%"
          }
        },
        "81852636c19d45ce99ab5642c73dfe56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef1976b7a0e14522ac208ab14d1d4119",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24b66ec0e2e1486485c8eeb6b2ddd3ef",
            "value": 11873
          }
        },
        "2ca4b52a0d524983b719359fa81a9a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c81124a6df54cba9369fce5d5cb2b0c",
            "placeholder": "​",
            "style": "IPY_MODEL_98c6487f14d34215adbc92c99176e62a",
            "value": " 11873/11873 [00:00&lt;00:00, 496822.18 examples/s]"
          }
        },
        "c7d220a4f666468b9ee07b2514b0a514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5aeec5ac594e02a8af203554510514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529263d4bb1d48cb95f549d4bae78302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef1976b7a0e14522ac208ab14d1d4119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b66ec0e2e1486485c8eeb6b2ddd3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c81124a6df54cba9369fce5d5cb2b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c6487f14d34215adbc92c99176e62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0915fb6c7dbf4db18c619f69318bd9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bd246c348334e51bbf95178b374e2f3",
              "IPY_MODEL_e12da962660f4b1fab84eb7ab2993f68",
              "IPY_MODEL_064ae4d3de9347c8a374fa624cd2c728"
            ],
            "layout": "IPY_MODEL_0041138f5f5b4f3cafb9a625afebfe7c"
          }
        },
        "5bd246c348334e51bbf95178b374e2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03bdc13b3c6f4ff7adfc47947c6dc3e8",
            "placeholder": "​",
            "style": "IPY_MODEL_ea2c99d0c7b84246bcd1e35fe35f9347",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e12da962660f4b1fab84eb7ab2993f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d75e2b518334c7c9aaf214b79a65071",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd8c369644f4bb6b090f1080d4ef75e",
            "value": 48
          }
        },
        "064ae4d3de9347c8a374fa624cd2c728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab259abf8f6441b8a41f9b332bad591",
            "placeholder": "​",
            "style": "IPY_MODEL_e56fa948d71e41529ac215acd6c5bfa3",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.94kB/s]"
          }
        },
        "0041138f5f5b4f3cafb9a625afebfe7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03bdc13b3c6f4ff7adfc47947c6dc3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2c99d0c7b84246bcd1e35fe35f9347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d75e2b518334c7c9aaf214b79a65071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd8c369644f4bb6b090f1080d4ef75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ab259abf8f6441b8a41f9b332bad591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56fa948d71e41529ac215acd6c5bfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8079be45376a4aeabdaa58d6de4590d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96e6e4ab8939453f9b109b93278f9fe5",
              "IPY_MODEL_2081d165985f4e5f838951d0548c2fa6",
              "IPY_MODEL_f8716281ba0447eca1d5620d7293b63e"
            ],
            "layout": "IPY_MODEL_bf660c549eed4550a45c5c86863028d9"
          }
        },
        "96e6e4ab8939453f9b109b93278f9fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e070cb2e1e468f8752aa94db900ddc",
            "placeholder": "​",
            "style": "IPY_MODEL_66a8ea8a9d9046de8f22592a21298754",
            "value": "config.json: 100%"
          }
        },
        "2081d165985f4e5f838951d0548c2fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_715e787fdee047db94e656a3b04f789b",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87935dd7dc224fc8b1021fdf3f1f7870",
            "value": 483
          }
        },
        "f8716281ba0447eca1d5620d7293b63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eae6a579a174b9ea07ddb18da7d546f",
            "placeholder": "​",
            "style": "IPY_MODEL_eeb6848594114ec69175344364f5c485",
            "value": " 483/483 [00:00&lt;00:00, 57.9kB/s]"
          }
        },
        "bf660c549eed4550a45c5c86863028d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e070cb2e1e468f8752aa94db900ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a8ea8a9d9046de8f22592a21298754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "715e787fdee047db94e656a3b04f789b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87935dd7dc224fc8b1021fdf3f1f7870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eae6a579a174b9ea07ddb18da7d546f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb6848594114ec69175344364f5c485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eb6c1fc73824adc93addb13b057847e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e783c65e5a84fc193e4d4fe390984c1",
              "IPY_MODEL_8ebc06cb0c3f4803a9d04f25c8d6f951",
              "IPY_MODEL_398f665a17054a65aa3dc31a9ae2468e"
            ],
            "layout": "IPY_MODEL_6b283eb026424929a91fae1a992fea86"
          }
        },
        "0e783c65e5a84fc193e4d4fe390984c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e31742a1d64a099b1296c9ab91e078",
            "placeholder": "​",
            "style": "IPY_MODEL_40e2e87f513b49efab3b0efedbe1152d",
            "value": "vocab.txt: 100%"
          }
        },
        "8ebc06cb0c3f4803a9d04f25c8d6f951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca45ada8f20e4b2e8205be70d52b2247",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5e905a62a314c18a096a0cf46aa2abc",
            "value": 231508
          }
        },
        "398f665a17054a65aa3dc31a9ae2468e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5f4105e83b348ff90dc86be162a647e",
            "placeholder": "​",
            "style": "IPY_MODEL_af27e38a42fe41c8a95ed0e0526552d4",
            "value": " 232k/232k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "6b283eb026424929a91fae1a992fea86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e31742a1d64a099b1296c9ab91e078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e2e87f513b49efab3b0efedbe1152d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca45ada8f20e4b2e8205be70d52b2247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e905a62a314c18a096a0cf46aa2abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5f4105e83b348ff90dc86be162a647e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af27e38a42fe41c8a95ed0e0526552d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f4374983334d708da527a75279bbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5655f96b6a9c4263963d76ad1445dfdc",
              "IPY_MODEL_49aae9ef75ba4e6595319618909fab52",
              "IPY_MODEL_4a63a8011cf8413697fe437987d5ca79"
            ],
            "layout": "IPY_MODEL_f6870951efa8440cb8644d7ad1513e57"
          }
        },
        "5655f96b6a9c4263963d76ad1445dfdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e405e5dd22d84546be3e1722a112f3ed",
            "placeholder": "​",
            "style": "IPY_MODEL_f4bee6b989f0441b9a8e91647bc9be67",
            "value": "tokenizer.json: 100%"
          }
        },
        "49aae9ef75ba4e6595319618909fab52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4941928dd5d4bdbbf86ab26508a874b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edfda4fb3d624e31802b874000a81d4f",
            "value": 466062
          }
        },
        "4a63a8011cf8413697fe437987d5ca79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bde12af479448cba4bf2afd1bad6ffd",
            "placeholder": "​",
            "style": "IPY_MODEL_d8822be920e1406f9a3a64cfe28006a8",
            "value": " 466k/466k [00:00&lt;00:00, 2.19MB/s]"
          }
        },
        "f6870951efa8440cb8644d7ad1513e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e405e5dd22d84546be3e1722a112f3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bee6b989f0441b9a8e91647bc9be67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4941928dd5d4bdbbf86ab26508a874b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfda4fb3d624e31802b874000a81d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bde12af479448cba4bf2afd1bad6ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8822be920e1406f9a3a64cfe28006a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f56ec8a6fb51454aa209c390b4a18848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b2ed06981ef4a4eba9de923a1b9c8c2",
              "IPY_MODEL_4fa59914b6194b18b93776b94510c9e6",
              "IPY_MODEL_323404981cf242489c653ff8a23dc41b"
            ],
            "layout": "IPY_MODEL_1e75b88cbe7543bb8de690d670c8e0c8"
          }
        },
        "4b2ed06981ef4a4eba9de923a1b9c8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4d9348ce984c418c523e8dee277bcf",
            "placeholder": "​",
            "style": "IPY_MODEL_e16e07044ad54f3ca4ae44500daaea9d",
            "value": "Map: 100%"
          }
        },
        "4fa59914b6194b18b93776b94510c9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ee99b18d2c34b77bf0b5b526fd9c056",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_820fa29fccc34895866d8a6e31220d00",
            "value": 11873
          }
        },
        "323404981cf242489c653ff8a23dc41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d65cecc05cd4590a0108277d685e2ac",
            "placeholder": "​",
            "style": "IPY_MODEL_142a03fad41249ac9110090382291901",
            "value": " 11873/11873 [00:07&lt;00:00, 1746.34 examples/s]"
          }
        },
        "1e75b88cbe7543bb8de690d670c8e0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf4d9348ce984c418c523e8dee277bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e16e07044ad54f3ca4ae44500daaea9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee99b18d2c34b77bf0b5b526fd9c056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "820fa29fccc34895866d8a6e31220d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d65cecc05cd4590a0108277d685e2ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142a03fad41249ac9110090382291901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bff78972cbf64ec3b76387a33b57c482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5690cda286c34c7ab2c29d28ddf10b29",
              "IPY_MODEL_596e270c8d36499a8370df5bdb1c8c87",
              "IPY_MODEL_bd860a7cd41c453a9b38c6ac40c6e106"
            ],
            "layout": "IPY_MODEL_a77e7138486b4a45a09c781058132966"
          }
        },
        "5690cda286c34c7ab2c29d28ddf10b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbfedd82e6ec4d16b6e954b433b537f5",
            "placeholder": "​",
            "style": "IPY_MODEL_8989726ab74a435cbb8e22f9a703ff91",
            "value": "model.safetensors: 100%"
          }
        },
        "596e270c8d36499a8370df5bdb1c8c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc7d6847e5584175ae1eece15476955e",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b63cc63695624697826b3f9d1ac1db75",
            "value": 267954768
          }
        },
        "bd860a7cd41c453a9b38c6ac40c6e106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5b0843e18547d4a42645313e8f760f",
            "placeholder": "​",
            "style": "IPY_MODEL_50b48971da5442cbbc5ea0e9809b8d97",
            "value": " 268M/268M [00:00&lt;00:00, 198MB/s]"
          }
        },
        "a77e7138486b4a45a09c781058132966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbfedd82e6ec4d16b6e954b433b537f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8989726ab74a435cbb8e22f9a703ff91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc7d6847e5584175ae1eece15476955e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b63cc63695624697826b3f9d1ac1db75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a5b0843e18547d4a42645313e8f760f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b48971da5442cbbc5ea0e9809b8d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17f88e02ed2a493ebb1454644d3690b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbb4fce297d7457cb46977679150d72e",
              "IPY_MODEL_9fd04db1161d4971ba0a84603f0f0652",
              "IPY_MODEL_859a76c7fe8d44878cae09bdf2d96176"
            ],
            "layout": "IPY_MODEL_51f25b12dd1b44a0a79f129172869407"
          }
        },
        "dbb4fce297d7457cb46977679150d72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c83801fb3b54c16bd27be0e25fe1711",
            "placeholder": "​",
            "style": "IPY_MODEL_541ac6bb97c943179ee30840f1229fe4",
            "value": "Map: 100%"
          }
        },
        "9fd04db1161d4971ba0a84603f0f0652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bbf4bd01ee34b418baa0a775e8d8bf4",
            "max": 32579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ce53d853f4e4b289805f897c2c890bc",
            "value": 32579
          }
        },
        "859a76c7fe8d44878cae09bdf2d96176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b56a8cded44602a5646015224ba5b1",
            "placeholder": "​",
            "style": "IPY_MODEL_73ed2e2142934b25b8afd2e0ec495049",
            "value": " 32579/32579 [00:18&lt;00:00, 1802.90 examples/s]"
          }
        },
        "51f25b12dd1b44a0a79f129172869407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c83801fb3b54c16bd27be0e25fe1711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "541ac6bb97c943179ee30840f1229fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bbf4bd01ee34b418baa0a775e8d8bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce53d853f4e4b289805f897c2c890bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24b56a8cded44602a5646015224ba5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ed2e2142934b25b8afd2e0ec495049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c8a010a060c4c3195700a6fe866ba85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eecdfe0ff63745f2af457dd87f7e1168",
              "IPY_MODEL_cb40ce7b2ba64cecba14ecc2027f6123",
              "IPY_MODEL_a30589d4263a4650ba0cf0346c7fe8e7"
            ],
            "layout": "IPY_MODEL_1b5ba670b05048449fa2da78065575ec"
          }
        },
        "eecdfe0ff63745f2af457dd87f7e1168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a25d94ac51014319ad86f7d121bf41a4",
            "placeholder": "​",
            "style": "IPY_MODEL_767570f67f95496aa0ed105802d67c98",
            "value": "Map: 100%"
          }
        },
        "cb40ce7b2ba64cecba14ecc2027f6123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da34873570847d19e1bdc563aea1310",
            "max": 65159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6701dfd3e14741fe8a6d7e2e3520baeb",
            "value": 65159
          }
        },
        "a30589d4263a4650ba0cf0346c7fe8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43022dc1790442a884bc22360b2e6801",
            "placeholder": "​",
            "style": "IPY_MODEL_7f70d009680e4e3e8b2da7da9ee54748",
            "value": " 65159/65159 [00:38&lt;00:00, 1694.39 examples/s]"
          }
        },
        "1b5ba670b05048449fa2da78065575ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25d94ac51014319ad86f7d121bf41a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "767570f67f95496aa0ed105802d67c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3da34873570847d19e1bdc563aea1310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6701dfd3e14741fe8a6d7e2e3520baeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43022dc1790442a884bc22360b2e6801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f70d009680e4e3e8b2da7da9ee54748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf6795b6099430da00ac3b06e29dc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21662eede9974b028dd4478a0a1df75b",
              "IPY_MODEL_97136229767543fdac6d8bcbe5299064",
              "IPY_MODEL_14b736215075420e90ef1a9284fd68f6"
            ],
            "layout": "IPY_MODEL_4631bb1b4a6140c4b669f224dc957f0a"
          }
        },
        "21662eede9974b028dd4478a0a1df75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeacdd781e0b46b5b5a84e9f313a49a1",
            "placeholder": "​",
            "style": "IPY_MODEL_6a9339acff5b4cc09e99f362285e6bfd",
            "value": "Map: 100%"
          }
        },
        "97136229767543fdac6d8bcbe5299064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40e3430dc524054a56077e71afe32e4",
            "max": 104255,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2d574e0bad747bc89835a4e6345b60a",
            "value": 104255
          }
        },
        "14b736215075420e90ef1a9284fd68f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17723bc2382241429202140a0504b74e",
            "placeholder": "​",
            "style": "IPY_MODEL_71a756333ec74067b186292d031e22c5",
            "value": " 104255/104255 [01:02&lt;00:00, 1640.01 examples/s]"
          }
        },
        "4631bb1b4a6140c4b669f224dc957f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeacdd781e0b46b5b5a84e9f313a49a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9339acff5b4cc09e99f362285e6bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40e3430dc524054a56077e71afe32e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d574e0bad747bc89835a4e6345b60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17723bc2382241429202140a0504b74e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a756333ec74067b186292d031e22c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88efe91a8c594cc0a8173aebd6f4a202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0668a656e8a4860926d9c765f562d5f",
              "IPY_MODEL_fc10f017a65340a9be1781cc795d5154",
              "IPY_MODEL_a34565b551624e6aaf8d3e1fdbaf44d1"
            ],
            "layout": "IPY_MODEL_c61bc2d1a1cb4e458e7a166716fa0de7"
          }
        },
        "e0668a656e8a4860926d9c765f562d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a9ba6c0664249639d5658f5e4ea0063",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9d08bf2e984cafaa95df9e9c35f881",
            "value": "Map: 100%"
          }
        },
        "fc10f017a65340a9be1781cc795d5154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f45d8d2ad354547b4e0e943fb5b9ba8",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fce0237ba36446e29a881da3fb500fd4",
            "value": 100
          }
        },
        "a34565b551624e6aaf8d3e1fdbaf44d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a333fd6164483f90abedd81f798705",
            "placeholder": "​",
            "style": "IPY_MODEL_279acfa7af22480fa46ba059e8ec34da",
            "value": " 100/100 [00:00&lt;00:00, 1381.78 examples/s]"
          }
        },
        "c61bc2d1a1cb4e458e7a166716fa0de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9ba6c0664249639d5658f5e4ea0063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9d08bf2e984cafaa95df9e9c35f881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f45d8d2ad354547b4e0e943fb5b9ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce0237ba36446e29a881da3fb500fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22a333fd6164483f90abedd81f798705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279acfa7af22480fa46ba059e8ec34da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "306751b1f3564337a559fa3423af6302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ae32d6ba1aa454ca872584ab7cf6afa",
              "IPY_MODEL_c734baa8c0d04df8acb6c794145b26c3",
              "IPY_MODEL_cb385708c83a4e2ebfe9a993bff20575"
            ],
            "layout": "IPY_MODEL_82bd9230e2b3445e8e52eadbd29663b9"
          }
        },
        "9ae32d6ba1aa454ca872584ab7cf6afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6693e8ee01fe465ab3ff85e79c6b2ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_6bc7e6fce43b4b618269e0b4a0abf9a4",
            "value": "Map: 100%"
          }
        },
        "c734baa8c0d04df8acb6c794145b26c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879d5389db9e43d5bbf4b73d1d05e494",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af38c074ff174a4dac67f1540065d35d",
            "value": 500
          }
        },
        "cb385708c83a4e2ebfe9a993bff20575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea67afec5324f3a9e0268be7d2b7f95",
            "placeholder": "​",
            "style": "IPY_MODEL_6cd133246f6547e39d3f3fb5d65bccf0",
            "value": " 500/500 [00:00&lt;00:00, 1652.62 examples/s]"
          }
        },
        "82bd9230e2b3445e8e52eadbd29663b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6693e8ee01fe465ab3ff85e79c6b2ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc7e6fce43b4b618269e0b4a0abf9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "879d5389db9e43d5bbf4b73d1d05e494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af38c074ff174a4dac67f1540065d35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ea67afec5324f3a9e0268be7d2b7f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd133246f6547e39d3f3fb5d65bccf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b726cb6d1f34b5285f21dd974154298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75edfa5727ff439b917b0ad2fc91b75d",
              "IPY_MODEL_8c790be895714c0aa177f6ae91ce43cd",
              "IPY_MODEL_5b08f052392a4043a43237d0232d2e3b"
            ],
            "layout": "IPY_MODEL_25cda5285e744aeca861305098c1d2f0"
          }
        },
        "75edfa5727ff439b917b0ad2fc91b75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c05a83b2f91424b9839052ae62d24d7",
            "placeholder": "​",
            "style": "IPY_MODEL_4d3e38536f024fbfbe22371ed3ba92b5",
            "value": "Map: 100%"
          }
        },
        "8c790be895714c0aa177f6ae91ce43cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2881985c9e8147fb9801ae9c8aef88a2",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_753c5592207d44d287a242b0060cabbc",
            "value": 1000
          }
        },
        "5b08f052392a4043a43237d0232d2e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be65b24ccb6f4ec8a96b4697cb88678c",
            "placeholder": "​",
            "style": "IPY_MODEL_90e7b245816646938e904df131ef74ac",
            "value": " 1000/1000 [00:00&lt;00:00, 1742.37 examples/s]"
          }
        },
        "25cda5285e744aeca861305098c1d2f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c05a83b2f91424b9839052ae62d24d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3e38536f024fbfbe22371ed3ba92b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2881985c9e8147fb9801ae9c8aef88a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753c5592207d44d287a242b0060cabbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be65b24ccb6f4ec8a96b4697cb88678c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e7b245816646938e904df131ef74ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quantifying the Environmental Cost of AI: Carbon Emissions in Language Model Fine-Tuning for Question Answering\n",
        "\n",
        "> ### **Project Goal** : As language models continue to play a larger role in natural language processing, their environmental impact has become an important issue to consider. While much of the research in this area focuses on improving model accuracy, the energy use and carbon footprint involved in training these systems are often overlooked or poorly documented. This project aims to explore that imbalance by studying how improvements in model performance relate to the environmental costs of fine-tuning.\n"
      ],
      "metadata": {
        "id": "jT7GJLlUasqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Strategy 1: Full Fine-Tuning (Model DistilBERT)"
      ],
      "metadata": {
        "id": "EDFB_pSelc1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install codecarbon\n",
        "!pip install evaluate codecarbon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwY_kTISlSSE",
        "outputId": "ead28ea4-6af1-451b-c3f2-14bde3b14bf8",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.12/dist-packages (from codecarbon) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from codecarbon) (8.3.1)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.23.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from codecarbon) (7.1.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.12.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.580.82)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from codecarbon) (3.14.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.32.4)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2025.2)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->codecarbon) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.4.2)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from questionary->codecarbon) (3.0.52)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.12/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<4.0,>=3.1 in /usr/local/lib/python3.12/dist-packages (from yaspin->fief-client[cli]->codecarbon) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.23)\n",
            "Collecting evaluate\n",
            "  Using cached evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.12/dist-packages (from codecarbon) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from codecarbon) (8.3.1)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.23.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from codecarbon) (7.1.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.12.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.580.82)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from codecarbon) (3.14.3)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2025.2)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (3.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.4.2)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from questionary->codecarbon) (3.0.52)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.12/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<4.0,>=3.1 in /usr/local/lib/python3.12/dist-packages (from yaspin->fief-client[cli]->codecarbon) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.23)\n",
            "Using cached evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Necessary Libraries\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    default_data_collator,\n",
        "    pipeline\n",
        ")\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "from codecarbon import EmissionsTracker\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zsuW8wdlhSb",
        "outputId": "cbc85e7a-64cf-44f2-e809-d5a899e8707a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1: Loading The Stanford Question Answering Dataset (SQuAD) Dataset"
      ],
      "metadata": {
        "id": "6YcR2XtolnYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squad = load_dataset(\"squad_v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "dd906886af174867b377efb85f2da2f9",
            "5b197731b2de476186d20cdb05010686",
            "646ef05d729448b28df97bc3191088ad",
            "c4baa1d3ce66443fa94a0e787c7110a1",
            "df1475597c3b41819fb55d780c213de7",
            "6be5363eef88484f8b9922588a34bb15",
            "b4ad4f30bda849099b2fea162c753c5d",
            "a4061165b0694f07ba65d2cf214ea0d3",
            "a513074f12d443c4a98ffd4eda7c5769",
            "4efc3d6f50cd42ecba3af50da34f1a43",
            "242f96a904a449ffa247a3312f5e45bb",
            "ee9528c9c7824417a691836fd0c57daf",
            "71efa948def7492e8a6857aeb329ec72",
            "184f772aa1d14e518e70981a0b393456",
            "0e477f561ec34ce189284a662b3d0ef9",
            "e408073989c449c694256904152ad160",
            "7fcd8c377fca4e41bdac91dd15ae0793",
            "341511a47a8d407abb5c021d8b5b3b92",
            "0d525cb7da7f4f0ea2b2366264ebf675",
            "adee4d3808af479f897e841652441962",
            "858df6d1f0d541b4adfcff246168134e",
            "707cc369d1694336bd7a222f9433cf5c",
            "8261d5e8cd35409ea98748e0fd4586df",
            "3947be0c669341bba30c2d6542361a0b",
            "8b6f9bd3bd58420da4309c68564131e0",
            "a5f782dbc77b479da9d441b5bf6fc824",
            "e59ce27f943b4ba1be97cde907448584",
            "37c0af5e8e1e415ab8e2154581df1c61",
            "14eae5eb88154deb8b7788e59a9d632e",
            "70e0a4a5083e4aab9b3203e4c3def51c",
            "87429750ddb84e3aba8a49e4bb983fca",
            "6aa31fe1a8904940aba0f1f290b4355e",
            "8a49b6130d434139bd8e6ae79db5ec1a",
            "412f2bbc89a146009001929defe4d9c2",
            "4759d442965d4314adf8b5d5eb414f0b",
            "e0fb7164bf3b4d5a982211176ee3a963",
            "a6be1e49487b4e55893c810240de27dc",
            "265faec9f93e4e3fbe6cbc0ba58561c8",
            "56f8d858265b4f20bb21f6854353b75d",
            "4283276a8fcc403a965554833b5f25f3",
            "a3f3c5582b3a4860a859d569e2d24d66",
            "45130aa9f380442990e5422338755777",
            "5dd9fbaf46934e8f8b3ff0b94746a625",
            "288eced4bfaa422e9cfb2aae5ec8581f",
            "fc5c692aeb0643fc800522306a694548",
            "6896690385e449fd84db433f6439a161",
            "81852636c19d45ce99ab5642c73dfe56",
            "2ca4b52a0d524983b719359fa81a9a9b",
            "c7d220a4f666468b9ee07b2514b0a514",
            "0b5aeec5ac594e02a8af203554510514",
            "529263d4bb1d48cb95f549d4bae78302",
            "ef1976b7a0e14522ac208ab14d1d4119",
            "24b66ec0e2e1486485c8eeb6b2ddd3ef",
            "5c81124a6df54cba9369fce5d5cb2b0c",
            "98c6487f14d34215adbc92c99176e62a"
          ]
        },
        "id": "eYkn3aL9lvj9",
        "outputId": "e25d5953-d114-4b2c-bbff-9e02c29eae98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd906886af174867b377efb85f2da2f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "squad_v2/train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee9528c9c7824417a691836fd0c57daf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "squad_v2/validation-00000-of-00001.parqu(…):   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8261d5e8cd35409ea98748e0fd4586df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "412f2bbc89a146009001929defe4d9c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc5c692aeb0643fc800522306a694548"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SQuAD Format: \",squad)\n",
        "print(f\"\\nFull training set size: {len(squad['train'])}\")\n",
        "print(f\"\\nValidation set size: {len(squad['validation'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mt2IAWUlv6X",
        "outputId": "28f77dc6-ce2a-4e81-9739-133a43872f0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SQuAD Format:  DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 130319\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 11873\n",
            "    })\n",
            "})\n",
            "\n",
            "Full training set size: 130319\n",
            "\n",
            "Validation set size: 11873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"========== Data Format Within SQuAD Training Set ==========\")\n",
        "print(\"\\n Context at Index[0]: \", squad[\"train\"][0]['context'])\n",
        "print(\"\\n Question at Index[0]: \", squad[\"train\"][0]['question'])\n",
        "print(\"\\n Answers at Index[0]: \", squad[\"train\"][0]['answers'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsV1W9ETlwLj",
        "outputId": "95fd5e10-f09f-40d7-f2d2-0c3930dec430"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Data Format Within SQuAD Training Set ==========\n",
            "\n",
            " Context at Index[0]:  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
            "\n",
            " Question at Index[0]:  When did Beyonce start becoming popular?\n",
            "\n",
            " Answers at Index[0]:  {'text': ['in the late 1990s'], 'answer_start': [269]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qn0jweFVl0We"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Qz-_-0kl5q1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2: Tokenization For the Model Function"
      ],
      "metadata": {
        "id": "5z2N-Gz3l0ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Autotokenizer automatically picks the correct tokenizer for given model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "16ktu0CDl4r2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "0915fb6c7dbf4db18c619f69318bd9e4",
            "5bd246c348334e51bbf95178b374e2f3",
            "e12da962660f4b1fab84eb7ab2993f68",
            "064ae4d3de9347c8a374fa624cd2c728",
            "0041138f5f5b4f3cafb9a625afebfe7c",
            "03bdc13b3c6f4ff7adfc47947c6dc3e8",
            "ea2c99d0c7b84246bcd1e35fe35f9347",
            "7d75e2b518334c7c9aaf214b79a65071",
            "efd8c369644f4bb6b090f1080d4ef75e",
            "3ab259abf8f6441b8a41f9b332bad591",
            "e56fa948d71e41529ac215acd6c5bfa3",
            "8079be45376a4aeabdaa58d6de4590d5",
            "96e6e4ab8939453f9b109b93278f9fe5",
            "2081d165985f4e5f838951d0548c2fa6",
            "f8716281ba0447eca1d5620d7293b63e",
            "bf660c549eed4550a45c5c86863028d9",
            "a0e070cb2e1e468f8752aa94db900ddc",
            "66a8ea8a9d9046de8f22592a21298754",
            "715e787fdee047db94e656a3b04f789b",
            "87935dd7dc224fc8b1021fdf3f1f7870",
            "2eae6a579a174b9ea07ddb18da7d546f",
            "eeb6848594114ec69175344364f5c485",
            "1eb6c1fc73824adc93addb13b057847e",
            "0e783c65e5a84fc193e4d4fe390984c1",
            "8ebc06cb0c3f4803a9d04f25c8d6f951",
            "398f665a17054a65aa3dc31a9ae2468e",
            "6b283eb026424929a91fae1a992fea86",
            "62e31742a1d64a099b1296c9ab91e078",
            "40e2e87f513b49efab3b0efedbe1152d",
            "ca45ada8f20e4b2e8205be70d52b2247",
            "d5e905a62a314c18a096a0cf46aa2abc",
            "a5f4105e83b348ff90dc86be162a647e",
            "af27e38a42fe41c8a95ed0e0526552d4",
            "26f4374983334d708da527a75279bbb6",
            "5655f96b6a9c4263963d76ad1445dfdc",
            "49aae9ef75ba4e6595319618909fab52",
            "4a63a8011cf8413697fe437987d5ca79",
            "f6870951efa8440cb8644d7ad1513e57",
            "e405e5dd22d84546be3e1722a112f3ed",
            "f4bee6b989f0441b9a8e91647bc9be67",
            "a4941928dd5d4bdbbf86ab26508a874b",
            "edfda4fb3d624e31802b874000a81d4f",
            "8bde12af479448cba4bf2afd1bad6ffd",
            "d8822be920e1406f9a3a64cfe28006a8"
          ]
        },
        "outputId": "ae7b0800-6756-47e3-fdda-d4dc6692efae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0915fb6c7dbf4db18c619f69318bd9e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8079be45376a4aeabdaa58d6de4590d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1eb6c1fc73824adc93addb13b057847e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26f4374983334d708da527a75279bbb6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    contexts = [c.strip() for c in examples[\"context\"]]\n",
        "\n",
        "    # Tokenize\n",
        "    tokenized = tokenizer(\n",
        "        questions,\n",
        "        contexts,\n",
        "        max_length=384,\n",
        "        stride=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=\"only_second\",         #Truncate from context\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "    )\n",
        "\n",
        "    # Mapping back to original samples\n",
        "    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n",
        "    offset_mapping = tokenized[\"offset_mapping\"]\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        sample_idx = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_idx]\n",
        "\n",
        "        # In no answer case\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "            continue\n",
        "\n",
        "        start_char = answers[\"answer_start\"][0]\n",
        "        end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "        seq_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "        # Find context section\n",
        "        context_start = seq_ids.index(1) if 1 in seq_ids else 0\n",
        "        context_end = len(seq_ids) - 1 - seq_ids[::-1].index(1) if 1 in seq_ids else len(seq_ids) - 1\n",
        "\n",
        "        # If answer not inside context → mark no answer\n",
        "        if not (offsets[context_start][0] <= start_char and offsets[context_end][1] >= end_char):\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "            continue\n",
        "\n",
        "        # Find start token\n",
        "        token_start = context_start\n",
        "        while token_start <= context_end and offsets[token_start][0] <= start_char:\n",
        "            token_start += 1\n",
        "        start_positions.append(token_start - 1)\n",
        "\n",
        "        # Find end token\n",
        "        token_end = context_end\n",
        "        while token_end >= context_start and offsets[token_end][1] >= end_char:\n",
        "            token_end -= 1\n",
        "        end_positions.append(token_end + 1)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "gD28U6xrl45G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess validation set (full)\n",
        "print(\"\\n🔄 Preprocessing validation set...\")\n",
        "tokenized_validation = squad[\"validation\"].map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=squad[\"validation\"].column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "f56ec8a6fb51454aa209c390b4a18848",
            "4b2ed06981ef4a4eba9de923a1b9c8c2",
            "4fa59914b6194b18b93776b94510c9e6",
            "323404981cf242489c653ff8a23dc41b",
            "1e75b88cbe7543bb8de690d670c8e0c8",
            "cf4d9348ce984c418c523e8dee277bcf",
            "e16e07044ad54f3ca4ae44500daaea9d",
            "9ee99b18d2c34b77bf0b5b526fd9c056",
            "820fa29fccc34895866d8a6e31220d00",
            "0d65cecc05cd4590a0108277d685e2ac",
            "142a03fad41249ac9110090382291901"
          ]
        },
        "id": "q74X9XTMl5F3",
        "outputId": "e283d6c1-2d7f-427c-c312-a8cec264912e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Preprocessing validation set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f56ec8a6fb51454aa209c390b4a18848"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_validation.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEouPPA_l-HN",
        "outputId": "604a9cf9-943c-4b37-da69-046f79b91b9b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': List(Value('int32')),\n",
              " 'attention_mask': List(Value('int8')),\n",
              " 'offset_mapping': List(List(Value('int64'))),\n",
              " 'start_positions': Value('int64'),\n",
              " 'end_positions': Value('int64')}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepareing function for tokenization based of training size of the data.\n",
        "\n",
        "def prepare_dataset(train_data, size_fraction, preprocess_fn):\n",
        "\n",
        "    #Create and preprocess a subset of training data.\n",
        "    num_samples = int(len(train_data) * size_fraction)\n",
        "    train_subset = train_data.select(range(num_samples))\n",
        "\n",
        "    print(f\"🔄 Preprocessing {num_samples} training samples...\")\n",
        "    tokenized_train = train_subset.map(\n",
        "        preprocess_fn,\n",
        "        batched=True,\n",
        "        remove_columns=train_subset.column_names\n",
        "    )\n",
        "\n",
        "    return tokenized_train, num_samples"
      ],
      "metadata": {
        "id": "N2vLL0gAl-Tc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3K3sGq6Gl-f8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3: Training The DistilBert Model Functions"
      ],
      "metadata": {
        "id": "XdJOJApbmDiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Architecture:\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"\\n🛠 DistilBERT Model Architecture:\")\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"\\nTransformer layers:\",model.config.n_layers)\n",
        "print(\"\\nHidden size:\",model.config.dim)\n",
        "print('\\nIntermediate feed-forward size:',model.config.hidden_dim)\n",
        "print(\"\\nAttention heads:\",model.config.n_heads)\n",
        "print(\"\\nMax positional embeddings:\", model.config.max_position_embeddings)\n",
        "print(\"\\nVocabulary size:\", model.config.vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426,
          "referenced_widgets": [
            "bff78972cbf64ec3b76387a33b57c482",
            "5690cda286c34c7ab2c29d28ddf10b29",
            "596e270c8d36499a8370df5bdb1c8c87",
            "bd860a7cd41c453a9b38c6ac40c6e106",
            "a77e7138486b4a45a09c781058132966",
            "cbfedd82e6ec4d16b6e954b433b537f5",
            "8989726ab74a435cbb8e22f9a703ff91",
            "dc7d6847e5584175ae1eece15476955e",
            "b63cc63695624697826b3f9d1ac1db75",
            "8a5b0843e18547d4a42645313e8f760f",
            "50b48971da5442cbbc5ea0e9809b8d97"
          ]
        },
        "id": "l_m7R8IxmHV0",
        "outputId": "2db5d661-077f-4f0f-ae52-b7e521492c04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bff78972cbf64ec3b76387a33b57c482"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "🛠 DistilBERT Model Architecture:\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Transformer layers: 6\n",
            "\n",
            "Hidden size: 768\n",
            "\n",
            "Intermediate feed-forward size: 3072\n",
            "\n",
            "Attention heads: 12\n",
            "\n",
            "Max positional embeddings: 512\n",
            "\n",
            "Vocabulary size: 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom compute metrics function for F1 and Exact Match\n",
        "def compute_metrics(pred):\n",
        "    predictions, labels = pred\n",
        "    start_preds = np.argmax(predictions[0], axis=1)\n",
        "    end_preds = np.argmax(predictions[1], axis=1)\n",
        "\n",
        "    start_true = labels[0]\n",
        "    end_true = labels[1]\n",
        "\n",
        "    # Calculate exact match\n",
        "    exact_matches = ((start_preds == start_true) & (end_preds == end_true)).sum()\n",
        "    exact_match = exact_matches / len(start_true)\n",
        "\n",
        "    # Calculate F1 score (token overlap)\n",
        "    f1_scores = []\n",
        "    for start_p, end_p, start_t, end_t in zip(start_preds, end_preds, start_true, end_true):\n",
        "        pred_tokens = set(range(start_p, end_p + 1))\n",
        "        true_tokens = set(range(start_t, end_t + 1))\n",
        "\n",
        "        if len(pred_tokens) == 0 and len(true_tokens) == 0:\n",
        "            f1_scores.append(1.0)\n",
        "        elif len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
        "            f1_scores.append(0.0)\n",
        "        else:\n",
        "            overlap = len(pred_tokens & true_tokens)\n",
        "            precision = overlap / len(pred_tokens)\n",
        "            recall = overlap / len(true_tokens)\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "    return {\n",
        "        \"exact_match\": exact_match,\n",
        "        \"f1\": avg_f1\n",
        "    }"
      ],
      "metadata": {
        "id": "JplgJ5BumHh0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(tokenized_train, tokenized_eval, tokenizer, compute_metrics_fn,\n",
        "                size_fraction, model_name):\n",
        "\n",
        "    # Load fresh model\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "    # Setup output directory\n",
        "    output_dir = f\"results_distilbert_{int(size_fraction*100)}pct\"\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=3e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=2,\n",
        "        weight_decay=0.01,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        push_to_hub=False,\n",
        "        logging_steps=100,\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        compute_metrics=compute_metrics_fn\n",
        "    )\n",
        "\n",
        "    # Start carbon tracking\n",
        "    tracker = EmissionsTracker(\n",
        "        project_name=f\"DistilBERT_{int(size_fraction*100)}pct\",\n",
        "        output_dir=output_dir\n",
        "    )\n",
        "    tracker.start()\n",
        "\n",
        "    # Train\n",
        "    print(\"🏋️ Training model...\")\n",
        "    train_results = trainer.train()\n",
        "\n",
        "    # Stop carbon tracking\n",
        "    tracker.stop()\n",
        "\n",
        "    emissions_data = tracker.final_emissions_data\n",
        "\n",
        "    return trainer, train_results, emissions_data, output_dir\n"
      ],
      "metadata": {
        "id": "ckLtCZSLmHuk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVu3KY31mII4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLVjbcclmOCe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4: Evaluating And Saving The Results Functions\n",
        "\n",
        "> We will be training our model on various data sizes from our SQuAD dataset.\n",
        ">\n",
        "> Training Data Variation: [25%, 50%, 80%]"
      ],
      "metadata": {
        "id": "SwgTY34DmOYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_save(trainer, train_results, emissions_data, output_dir,\n",
        "                      size_fraction, num_samples):\n",
        "    \"\"\"Evaluate model, print results, and save artifacts.\"\"\"\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"📊 Evaluating model...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    #Calculate trainable parameters for Full Fine-tuning\n",
        "    model = trainer.model\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_percentage = 100 * trainable_params / total_params\n",
        "\n",
        "    # Compile results\n",
        "    result_entry = {\n",
        "        \"training_method\": \"Full Fine-Tuning\",\n",
        "        \"model_name\": \"DistilBERT\",\n",
        "        'dataset_size%': int(size_fraction*100),\n",
        "        \"train_samples\": num_samples,\n",
        "        \"valid_samples\": len(tokenized_validation),\n",
        "        \"trainable_params\": trainable_params,\n",
        "        \"total_params\": total_params,\n",
        "        \"trainable_percentage\": trainable_percentage,\n",
        "\n",
        "        # Performance metrics\n",
        "        \"f1_score\": eval_results[\"eval_f1\"],\n",
        "        \"exact_match\": eval_results[\"eval_exact_match\"],\n",
        "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
        "        \"training_time_hours\": train_results.metrics[\"train_runtime\"] / 3600,\n",
        "\n",
        "        # Emissions data (direct access to EmissionsData attributes)\n",
        "        \"emissions_rate_kg_per_s\": emissions_data.emissions_rate,\n",
        "        \"emissions_kg\": emissions_data.emissions,\n",
        "        \"timestamp\": emissions_data.timestamp,\n",
        "        \"duration_seconds\": emissions_data.duration,\n",
        "        \"duration_hours\": emissions_data.duration / 3600,\n",
        "\n",
        "        # Energy consumption\n",
        "        \"energy_consumed_kwh\": emissions_data.energy_consumed,\n",
        "        \"cpu_energy_kwh\": emissions_data.cpu_energy,\n",
        "        \"gpu_energy_kwh\": emissions_data.gpu_energy,\n",
        "        \"ram_energy_kwh\": emissions_data.ram_energy,\n",
        "\n",
        "        # Power draw\n",
        "        \"cpu_power_w\": emissions_data.cpu_power,\n",
        "        \"gpu_power_w\": emissions_data.gpu_power,\n",
        "        \"ram_power_w\": emissions_data.ram_power,\n",
        "\n",
        "        # Location and system info\n",
        "        \"country_name\": emissions_data.country_name,\n",
        "        \"country_iso_code\": emissions_data.country_iso_code,\n",
        "        \"region\": emissions_data.region,\n",
        "        \"cloud_provider\": emissions_data.cloud_provider,\n",
        "        \"cloud_region\": emissions_data.cloud_region,\n",
        "        \"on_cloud\": emissions_data.on_cloud,\n",
        "\n",
        "        # System specifications\n",
        "        \"os\": emissions_data.os,\n",
        "        \"python_version\": emissions_data.python_version,\n",
        "        \"cpu_count\": emissions_data.cpu_count,\n",
        "        \"cpu_model\": emissions_data.cpu_model,\n",
        "        \"gpu_count\": emissions_data.gpu_count,\n",
        "        \"gpu_model\": emissions_data.gpu_model,\n",
        "        \"ram_total_size_gb\": emissions_data.ram_total_size,\n",
        "\n",
        "        # Additional metrics\n",
        "        \"pue\": emissions_data.pue,\n",
        "        \"codecarbon_version\": emissions_data.codecarbon_version,\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"\\n📈 FINE-TUNING RESULTS SUMMARY FOR {size_fraction*100}% DATASET:\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"  Training Method: Full Fine-Tuning\")\n",
        "    print(f\"  Model: DistilBERT\")\n",
        "\n",
        "    print(f\"\\n🔧 Model Parameters:\")\n",
        "    print(f\"  Total Parameters: {total_params:,}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"  Trainable Percentage: {trainable_percentage:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"\\n🎯 Performance Metrics:\")\n",
        "    print(f\"  F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"  Exact Match: {eval_results['eval_exact_match']:.4f}\")\n",
        "    print(f\"  Eval Loss: {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\n⚡ Energy Consumption:\")\n",
        "    print(f\"  Total Energy: {emissions_data.energy_consumed:.6f} kWh\")\n",
        "    print(f\"  CPU Energy: {emissions_data.cpu_energy:.6f} kWh ({emissions_data.cpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  GPU Energy: {emissions_data.gpu_energy:.6f} kWh ({emissions_data.gpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  RAM Energy: {emissions_data.ram_energy:.6f} kWh ({emissions_data.ram_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n🔌 Average Power Draw:\")\n",
        "    print(f\"  CPU Power: {emissions_data.cpu_power:.2f} W\")\n",
        "    print(f\"  GPU Power: {emissions_data.gpu_power:.2f} W\")\n",
        "    print(f\"  RAM Power: {emissions_data.ram_power:.2f} W\")\n",
        "    print(f\"  Total Power: {emissions_data.cpu_power + emissions_data.gpu_power + emissions_data.ram_power:.2f} W\")\n",
        "\n",
        "    print(f\"\\n🌱 Carbon Footprint:\")\n",
        "    print(f\"  Total CO2 Emissions: {emissions_data.emissions:.6f} kg\")\n",
        "    print(f\"  Emissions Rate: {emissions_data.emissions_rate:.9f} kg/s\")\n",
        "    print(f\"  Duration: {emissions_data.duration/3600:.2f} hours\")\n",
        "    print(f\"  Training Time (Trainer): {train_results.metrics['train_runtime']/3600:.2f} hours\")\n",
        "\n",
        "    print(f\"\\n📍 Location & Infrastructure:\")\n",
        "    print(f\"  Country: {emissions_data.country_name} ({emissions_data.country_iso_code})\")\n",
        "    print(f\"  Region: {emissions_data.region}\")\n",
        "    print(f\"  On Cloud: {emissions_data.on_cloud}\")\n",
        "    print(f\"  PUE (Power Usage Effectiveness): {emissions_data.pue}\")\n",
        "\n",
        "    print(f\"\\n💻 System Specifications:\")\n",
        "    print(f\"  OS: {emissions_data.os}\")\n",
        "    print(f\"  CPU: {emissions_data.cpu_model} ({emissions_data.cpu_count} cores)\")\n",
        "    if emissions_data.gpu_count and emissions_data.gpu_model:\n",
        "        print(f\"  GPU: {emissions_data.gpu_model} (Count: {emissions_data.gpu_count})\")\n",
        "    else:\n",
        "        print(f\"  GPU: None detected\")\n",
        "    print(f\"  RAM: {emissions_data.ram_total_size:.2f} GB\")\n",
        "    print(f\"  Python: {emissions_data.python_version}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "\n",
        "    # Save model\n",
        "    trainer.save_model(f\"{output_dir}/final_model\")\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del trainer.model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result_entry"
      ],
      "metadata": {
        "id": "9CPJ12uUmSGG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(size_fraction, train_data, eval_data, tokenizer, preprocess_fn, compute_metrics_fn, model_name):\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🚀 Training with {size_fraction*100}% of training data\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Step 1: Prepare dataset\n",
        "    tokenized_train, num_samples = prepare_dataset(train_data, size_fraction, preprocess_fn)\n",
        "\n",
        "    # Step 2: Train model\n",
        "    trainer, train_results, emissions_data, output_dir = train_model(\n",
        "        tokenized_train, eval_data, tokenizer, compute_metrics_fn,\n",
        "        size_fraction, model_name\n",
        "    )\n",
        "\n",
        "    # Step 3: Evaluate and save\n",
        "    result_entry = evaluate_and_save(trainer, train_results, emissions_data, output_dir, size_fraction, num_samples)\n",
        "\n",
        "    return result_entry"
      ],
      "metadata": {
        "id": "ttEc4sECmSSm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store results\n",
        "results_summary = []"
      ],
      "metadata": {
        "id": "_9x0PvPSmSfo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Considering 25% of data for training the model\n",
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 1: FULL FINE-TUNING WITH 25.0% TRAINING DATASET\")\n",
        "print(\"=\"*80)\n",
        "result1 = run_experiment(\n",
        "        size_fraction=0.25,\n",
        "        train_data=squad[\"train\"],\n",
        "        eval_data=tokenized_validation,\n",
        "        tokenizer=tokenizer,\n",
        "        preprocess_fn=preprocess_function,\n",
        "        compute_metrics_fn=compute_metrics,\n",
        "        model_name=\"distilbert-base-uncased\"\n",
        "    )\n",
        "\n",
        "results_summary.append(result1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "17f88e02ed2a493ebb1454644d3690b8",
            "dbb4fce297d7457cb46977679150d72e",
            "9fd04db1161d4971ba0a84603f0f0652",
            "859a76c7fe8d44878cae09bdf2d96176",
            "51f25b12dd1b44a0a79f129172869407",
            "4c83801fb3b54c16bd27be0e25fe1711",
            "541ac6bb97c943179ee30840f1229fe4",
            "9bbf4bd01ee34b418baa0a775e8d8bf4",
            "7ce53d853f4e4b289805f897c2c890bc",
            "24b56a8cded44602a5646015224ba5b1",
            "73ed2e2142934b25b8afd2e0ec495049"
          ]
        },
        "id": "kD1HFhJsmSt9",
        "outputId": "d09887ea-4f6c-48cb-e043-6f5b73329a49",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 1: FULL FINE-TUNING WITH 25.0% TRAINING DATASET\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Training with 25.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 32579 training samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32579 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17f88e02ed2a493ebb1454644d3690b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1941336186.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "[codecarbon WARNING @ 23:49:53] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 23:49:53] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 23:49:53] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 23:49:54] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 23:49:54] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 23:49:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 23:49:54] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 23:49:54] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 23:49:54] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 23:49:54] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 23:49:54] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 23:49:54]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 23:49:54]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 23:49:54]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 23:49:54]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 23:49:54]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 23:49:54]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 23:49:54]   GPU count: 1\n",
            "[codecarbon INFO @ 23:49:54]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 23:49:54] Emissions data (if any) will be saved to file /content/results_distilbert_25pct/emissions.csv\n",
            "[codecarbon WARNING @ 23:49:54] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 23:49:54] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 23:49:54] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 23:49:55] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 23:49:55] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 23:49:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 23:49:55] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 23:49:55] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 23:49:55] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 23:49:55] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 23:49:55] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 23:49:55]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 23:49:55]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 23:49:55]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 23:49:55]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 23:49:55]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 23:49:55]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 23:49:55]   GPU count: 1\n",
            "[codecarbon INFO @ 23:49:55]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 23:49:55] Emissions data (if any) will be saved to file /content/results_distilbert_25pct/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdikshaph07\u001b[0m (\u001b[33mdikshaph07-rutgers-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251126_235001-twn3zvoj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface/runs/twn3zvoj' target=\"_blank\">ethereal-paper-16</a></strong> to <a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface' target=\"_blank\">https://wandb.ai/dikshaph07-rutgers-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface/runs/twn3zvoj' target=\"_blank\">https://wandb.ai/dikshaph07-rutgers-university/huggingface/runs/twn3zvoj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4102' max='4102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4102/4102 02:53, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.306500</td>\n",
              "      <td>1.750965</td>\n",
              "      <td>0.387341</td>\n",
              "      <td>0.456665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.948800</td>\n",
              "      <td>2.024458</td>\n",
              "      <td>0.369540</td>\n",
              "      <td>0.450653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 23:50:10] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:50:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:50:10] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 23:50:10] Energy consumed for all GPUs : 0.000488 kWh. Total GPU Power : 117.0655624188808 W\n",
            "[codecarbon INFO @ 23:50:10] 0.000824 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:50:18] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:50:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:50:18] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 23:50:18] Energy consumed for all GPUs : 0.000892 kWh. Total GPU Power : 213.89731008617676 W\n",
            "[codecarbon INFO @ 23:50:18] 0.001227 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:50:25] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:50:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:50:25] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 23:50:25] Energy consumed for all GPUs : 0.001472 kWh. Total GPU Power : 236.1247678692552 W\n",
            "[codecarbon INFO @ 23:50:25] 0.002143 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:50:33] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:50:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:50:33] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 23:50:33] Energy consumed for all GPUs : 0.001882 kWh. Total GPU Power : 237.5479889899087 W\n",
            "[codecarbon INFO @ 23:50:33] 0.002552 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:50:40] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:50:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:50:40] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 23:50:40] Energy consumed for all GPUs : 0.002460 kWh. Total GPU Power : 237.3578982169373 W\n",
            "[codecarbon INFO @ 23:50:40] 0.003467 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:50:48] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:50:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:50:48] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 23:50:48] Energy consumed for all GPUs : 0.002868 kWh. Total GPU Power : 236.99329980878773 W\n",
            "[codecarbon INFO @ 23:50:48] 0.003874 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:50:55] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:50:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:50:55] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 23:50:55] Energy consumed for all GPUs : 0.003446 kWh. Total GPU Power : 236.50183143385172 W\n",
            "[codecarbon INFO @ 23:50:55] 0.004787 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:03] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:03] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 23:51:03] Energy consumed for all GPUs : 0.003836 kWh. Total GPU Power : 232.37168964654163 W\n",
            "[codecarbon INFO @ 23:51:03] 0.005178 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:10] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:10] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 23:51:10] Energy consumed for all GPUs : 0.004421 kWh. Total GPU Power : 234.17532675444227 W\n",
            "[codecarbon INFO @ 23:51:10] 0.006097 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:18] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:18] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 23:51:18] Energy consumed for all GPUs : 0.004835 kWh. Total GPU Power : 239.76547725389946 W\n",
            "[codecarbon INFO @ 23:51:18] 0.006512 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:25] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:25] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 23:51:25] Energy consumed for all GPUs : 0.005329 kWh. Total GPU Power : 217.86758145802992 W\n",
            "[codecarbon INFO @ 23:51:25] 0.007340 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:33] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:33] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 23:51:33] Energy consumed for all GPUs : 0.005613 kWh. Total GPU Power : 186.64606639517024 W\n",
            "[codecarbon INFO @ 23:51:33] 0.007625 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:40] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:40] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 23:51:40] Energy consumed for all GPUs : 0.006188 kWh. Total GPU Power : 206.41738457444575 W\n",
            "[codecarbon INFO @ 23:51:40] 0.008536 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:48] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:48] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 23:51:48] Energy consumed for all GPUs : 0.006596 kWh. Total GPU Power : 235.91458024879063 W\n",
            "[codecarbon INFO @ 23:51:48] 0.008942 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:55] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:51:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:51:55] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 23:51:55] Energy consumed for all GPUs : 0.007172 kWh. Total GPU Power : 236.29370079479452 W\n",
            "[codecarbon INFO @ 23:51:55] 0.009854 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:51:55] 0.038655 g.CO2eq/s mean an estimation of 1,219.0330179667283 kg.CO2eq/year\n",
            "[codecarbon INFO @ 23:52:03] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:03] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 23:52:03] Energy consumed for all GPUs : 0.007581 kWh. Total GPU Power : 236.5533674231582 W\n",
            "[codecarbon INFO @ 23:52:03] 0.010263 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:03] 0.040256 g.CO2eq/s mean an estimation of 1,269.5284007201208 kg.CO2eq/year\n",
            "[codecarbon INFO @ 23:52:10] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:10] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 23:52:10] Energy consumed for all GPUs : 0.008166 kWh. Total GPU Power : 238.60769846062146 W\n",
            "[codecarbon INFO @ 23:52:10] 0.011184 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:18] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:18] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 23:52:18] Energy consumed for all GPUs : 0.008578 kWh. Total GPU Power : 239.4112584181589 W\n",
            "[codecarbon INFO @ 23:52:18] 0.011596 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:25] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:25] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 23:52:25] Energy consumed for all GPUs : 0.009155 kWh. Total GPU Power : 237.3874864015236 W\n",
            "[codecarbon INFO @ 23:52:25] 0.012508 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:33] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:33] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 23:52:33] Energy consumed for all GPUs : 0.009571 kWh. Total GPU Power : 238.31883679011577 W\n",
            "[codecarbon INFO @ 23:52:33] 0.012924 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:40] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:40] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 23:52:40] Energy consumed for all GPUs : 0.010152 kWh. Total GPU Power : 239.19698855091417 W\n",
            "[codecarbon INFO @ 23:52:40] 0.013839 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:48] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:48] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 23:52:48] Energy consumed for all GPUs : 0.010527 kWh. Total GPU Power : 229.50726895120937 W\n",
            "[codecarbon INFO @ 23:52:48] 0.014215 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:55] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:55] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 23:52:55] Energy consumed for all GPUs : 0.011027 kWh. Total GPU Power : 210.08602102699746 W\n",
            "[codecarbon INFO @ 23:52:55] 0.015050 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:58] Energy consumed for RAM : 0.001842 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:58] Delta energy consumed for CPU with constant : 0.000113 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:58] Energy consumed for All CPU : 0.002061 kWh\n",
            "[codecarbon INFO @ 23:52:58] Energy consumed for all GPUs : 0.011010 kWh. Total GPU Power : 181.177087208187 W\n",
            "[codecarbon INFO @ 23:52:58] 0.014913 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:52:58] Energy consumed for RAM : 0.001927 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:52:58] Delta energy consumed for CPU with constant : 0.000031 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:52:58] Energy consumed for All CPU : 0.002155 kWh\n",
            "[codecarbon INFO @ 23:52:58] Energy consumed for all GPUs : 0.011131 kWh. Total GPU Power : 140.81992131074054 W\n",
            "[codecarbon INFO @ 23:52:58] 0.015213 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "📈 FINE-TUNING RESULTS SUMMARY FOR 25.0% DATASET:\n",
            "================================================================================\n",
            "  Training Method: Full Fine-Tuning\n",
            "  Model: DistilBERT\n",
            "\n",
            "🔧 Model Parameters:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 66,364,418\n",
            "  Trainable Percentage: 100.00%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.4567\n",
            "  Exact Match: 0.3873\n",
            "  Eval Loss: 1.7510\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.015213 kWh\n",
            "  CPU Energy: 0.002155 kWh (14.2%)\n",
            "  GPU Energy: 0.011131 kWh (73.2%)\n",
            "  RAM Energy: 0.001927 kWh (12.7%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 140.82 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 221.32 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.007162 kg\n",
            "  Emissions Rate: 0.000039206 kg/s\n",
            "  Duration: 0.05 hours\n",
            "  Training Time (Trainer): 0.05 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: Singapore (SGP)\n",
            "  Region: \n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "CPU times: user 3min 48s, sys: 3.58 s, total: 3min 51s\n",
            "Wall time: 3min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Considering 50% of data for training the model\n",
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 2: FULL FINE-TUNING WITH 50.0% TRAINING DATASET\")\n",
        "print(\"=\"*80)\n",
        "result2 = run_experiment(\n",
        "        size_fraction=0.5,\n",
        "        train_data=squad[\"train\"],\n",
        "        eval_data=tokenized_validation,\n",
        "        tokenizer=tokenizer,\n",
        "        preprocess_fn=preprocess_function,\n",
        "        compute_metrics_fn=compute_metrics,\n",
        "        model_name=\"distilbert-base-uncased\"\n",
        "    )\n",
        "results_summary.append(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c8a010a060c4c3195700a6fe866ba85",
            "eecdfe0ff63745f2af457dd87f7e1168",
            "cb40ce7b2ba64cecba14ecc2027f6123",
            "a30589d4263a4650ba0cf0346c7fe8e7",
            "1b5ba670b05048449fa2da78065575ec",
            "a25d94ac51014319ad86f7d121bf41a4",
            "767570f67f95496aa0ed105802d67c98",
            "3da34873570847d19e1bdc563aea1310",
            "6701dfd3e14741fe8a6d7e2e3520baeb",
            "43022dc1790442a884bc22360b2e6801",
            "7f70d009680e4e3e8b2da7da9ee54748"
          ]
        },
        "id": "WKjvgrwCnscn",
        "outputId": "250476f9-005d-4b99-a73f-2cb83756b8ec",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 2: FULL FINE-TUNING WITH 50.0% TRAINING DATASET\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Training with 50.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 65159 training samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/65159 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c8a010a060c4c3195700a6fe866ba85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1941336186.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "[codecarbon WARNING @ 23:53:49] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 23:53:49] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 23:53:49] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 23:53:50] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 23:53:50] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 23:53:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 23:53:50] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 23:53:50] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 23:53:50] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 23:53:50] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 23:53:50] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 23:53:50]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 23:53:50]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 23:53:50]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 23:53:50]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 23:53:50]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 23:53:50]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 23:53:50]   GPU count: 1\n",
            "[codecarbon INFO @ 23:53:50]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 23:53:50] Emissions data (if any) will be saved to file /content/results_distilbert_50pct/emissions.csv\n",
            "[codecarbon WARNING @ 23:53:50] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 23:53:50] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 23:53:50] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 23:53:51] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 23:53:51] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 23:53:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 23:53:51] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 23:53:51] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 23:53:51] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 23:53:51] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 23:53:51] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 23:53:51]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 23:53:51]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 23:53:51]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 23:53:51]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 23:53:51]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 23:53:51]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 23:53:51]   GPU count: 1\n",
            "[codecarbon INFO @ 23:53:51]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 23:53:52] Emissions data (if any) will be saved to file /content/results_distilbert_50pct/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ Training model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8224' max='8224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8224/8224 05:23, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.232200</td>\n",
              "      <td>1.464187</td>\n",
              "      <td>0.452448</td>\n",
              "      <td>0.531636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.918600</td>\n",
              "      <td>1.443919</td>\n",
              "      <td>0.491182</td>\n",
              "      <td>0.569894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 23:54:07] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:07] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 23:54:07] Energy consumed for all GPUs : 0.000941 kWh. Total GPU Power : 225.6992692944859 W\n",
            "[codecarbon INFO @ 23:54:07] 0.001276 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:54:07] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:07] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 23:54:07] Energy consumed for all GPUs : 0.000960 kWh. Total GPU Power : 230.18669540727703 W\n",
            "[codecarbon INFO @ 23:54:07] 0.001295 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:54:22] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:22] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 23:54:22] Energy consumed for all GPUs : 0.001920 kWh. Total GPU Power : 234.98662961420357 W\n",
            "[codecarbon INFO @ 23:54:22] 0.002591 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:54:22] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:22] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 23:54:22] Energy consumed for all GPUs : 0.001938 kWh. Total GPU Power : 234.95537329006237 W\n",
            "[codecarbon INFO @ 23:54:22] 0.002609 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:54:37] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:37] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 23:54:37] Energy consumed for all GPUs : 0.002915 kWh. Total GPU Power : 238.86520817333798 W\n",
            "[codecarbon INFO @ 23:54:37] 0.003921 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:54:37] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:37] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 23:54:37] Energy consumed for all GPUs : 0.002941 kWh. Total GPU Power : 240.60162994616059 W\n",
            "[codecarbon INFO @ 23:54:37] 0.003947 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:54:52] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:52] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 23:54:52] Energy consumed for all GPUs : 0.003918 kWh. Total GPU Power : 240.9380489604508 W\n",
            "[codecarbon INFO @ 23:54:52] 0.005260 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:54:52] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:54:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:54:52] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 23:54:52] Energy consumed for all GPUs : 0.003937 kWh. Total GPU Power : 239.28662227130005 W\n",
            "[codecarbon INFO @ 23:54:52] 0.005279 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:07] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:07] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 23:55:07] Energy consumed for all GPUs : 0.004916 kWh. Total GPU Power : 239.41773892323266 W\n",
            "[codecarbon INFO @ 23:55:07] 0.006592 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:07] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:07] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 23:55:07] Energy consumed for all GPUs : 0.004935 kWh. Total GPU Power : 239.5763695685227 W\n",
            "[codecarbon INFO @ 23:55:07] 0.006611 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:22] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:22] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 23:55:22] Energy consumed for all GPUs : 0.005913 kWh. Total GPU Power : 239.34888432939553 W\n",
            "[codecarbon INFO @ 23:55:22] 0.007925 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:22] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:22] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 23:55:22] Energy consumed for all GPUs : 0.005938 kWh. Total GPU Power : 240.83724270320562 W\n",
            "[codecarbon INFO @ 23:55:22] 0.007950 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:37] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:37] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 23:55:37] Energy consumed for all GPUs : 0.006916 kWh. Total GPU Power : 240.76338457773002 W\n",
            "[codecarbon INFO @ 23:55:37] 0.009263 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:37] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:37] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 23:55:37] Energy consumed for all GPUs : 0.006941 kWh. Total GPU Power : 240.7926414247721 W\n",
            "[codecarbon INFO @ 23:55:37] 0.009288 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:52] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:52] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 23:55:52] Energy consumed for all GPUs : 0.007922 kWh. Total GPU Power : 241.5994452879223 W\n",
            "[codecarbon INFO @ 23:55:52] 0.010605 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:52] 0.041597 g.CO2eq/s mean an estimation of 1,311.8170529914307 kg.CO2eq/year\n",
            "[codecarbon INFO @ 23:55:52] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:55:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:55:52] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 23:55:52] Energy consumed for all GPUs : 0.007941 kWh. Total GPU Power : 239.8637260857135 W\n",
            "[codecarbon INFO @ 23:55:52] 0.010623 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:55:52] 0.041670 g.CO2eq/s mean an estimation of 1,314.102627049618 kg.CO2eq/year\n",
            "[codecarbon INFO @ 23:56:07] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:07] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 23:56:07] Energy consumed for all GPUs : 0.008920 kWh. Total GPU Power : 239.65365067990237 W\n",
            "[codecarbon INFO @ 23:56:07] 0.011938 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:56:07] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:07] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 23:56:07] Energy consumed for all GPUs : 0.008946 kWh. Total GPU Power : 241.30643545183887 W\n",
            "[codecarbon INFO @ 23:56:07] 0.011964 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:56:22] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:22] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 23:56:22] Energy consumed for all GPUs : 0.009902 kWh. Total GPU Power : 235.50600504391116 W\n",
            "[codecarbon INFO @ 23:56:22] 0.013254 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:56:22] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:22] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 23:56:22] Energy consumed for all GPUs : 0.009920 kWh. Total GPU Power : 233.8835635129118 W\n",
            "[codecarbon INFO @ 23:56:22] 0.013273 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:56:37] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:37] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 23:56:37] Energy consumed for all GPUs : 0.010725 kWh. Total GPU Power : 197.7142773764056 W\n",
            "[codecarbon INFO @ 23:56:37] 0.014413 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:56:37] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:37] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 23:56:37] Energy consumed for all GPUs : 0.010744 kWh. Total GPU Power : 197.62777220709276 W\n",
            "[codecarbon INFO @ 23:56:37] 0.014432 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:56:52] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:52] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 23:56:52] Energy consumed for all GPUs : 0.011720 kWh. Total GPU Power : 238.96504889810683 W\n",
            "[codecarbon INFO @ 23:56:52] 0.015744 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:56:52] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:56:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:56:52] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 23:56:52] Energy consumed for all GPUs : 0.011739 kWh. Total GPU Power : 238.89668554236187 W\n",
            "[codecarbon INFO @ 23:56:52] 0.015762 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:07] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:07] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 23:57:07] Energy consumed for all GPUs : 0.012718 kWh. Total GPU Power : 239.39871995762067 W\n",
            "[codecarbon INFO @ 23:57:07] 0.017076 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:07] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:07] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 23:57:07] Energy consumed for all GPUs : 0.012743 kWh. Total GPU Power : 241.00802016459616 W\n",
            "[codecarbon INFO @ 23:57:07] 0.017101 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:22] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:22] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 23:57:22] Energy consumed for all GPUs : 0.013717 kWh. Total GPU Power : 239.83554313663433 W\n",
            "[codecarbon INFO @ 23:57:22] 0.018411 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:22] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:22] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 23:57:22] Energy consumed for all GPUs : 0.013735 kWh. Total GPU Power : 238.3006335732902 W\n",
            "[codecarbon INFO @ 23:57:22] 0.018429 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:37] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:37] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 23:57:37] Energy consumed for all GPUs : 0.014714 kWh. Total GPU Power : 239.24453810034618 W\n",
            "[codecarbon INFO @ 23:57:37] 0.019743 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:37] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:37] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 23:57:37] Energy consumed for all GPUs : 0.014733 kWh. Total GPU Power : 239.35321098041305 W\n",
            "[codecarbon INFO @ 23:57:37] 0.019762 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:52] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:52] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 23:57:52] Energy consumed for all GPUs : 0.015709 kWh. Total GPU Power : 238.96959773486046 W\n",
            "[codecarbon INFO @ 23:57:52] 0.021074 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:52] 0.041067 g.CO2eq/s mean an estimation of 1,295.0855852540587 kg.CO2eq/year\n",
            "[codecarbon INFO @ 23:57:52] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:57:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:57:52] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 23:57:52] Energy consumed for all GPUs : 0.015734 kWh. Total GPU Power : 240.35367477313133 W\n",
            "[codecarbon INFO @ 23:57:52] 0.021098 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:57:52] 0.041094 g.CO2eq/s mean an estimation of 1,295.934794863087 kg.CO2eq/year\n",
            "[codecarbon INFO @ 23:58:07] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:07] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 23:58:07] Energy consumed for all GPUs : 0.016699 kWh. Total GPU Power : 237.68919571536244 W\n",
            "[codecarbon INFO @ 23:58:07] 0.022399 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:58:07] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:07] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 23:58:07] Energy consumed for all GPUs : 0.016718 kWh. Total GPU Power : 236.31832541368684 W\n",
            "[codecarbon INFO @ 23:58:07] 0.022418 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:58:22] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:22] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 23:58:22] Energy consumed for all GPUs : 0.017673 kWh. Total GPU Power : 233.70999120372878 W\n",
            "[codecarbon INFO @ 23:58:22] 0.023708 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:58:22] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:22] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 23:58:22] Energy consumed for all GPUs : 0.017691 kWh. Total GPU Power : 233.6483799293105 W\n",
            "[codecarbon INFO @ 23:58:22] 0.023727 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:58:37] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:37] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 23:58:37] Energy consumed for all GPUs : 0.018667 kWh. Total GPU Power : 238.59397920748705 W\n",
            "[codecarbon INFO @ 23:58:37] 0.025037 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:58:37] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:37] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 23:58:37] Energy consumed for all GPUs : 0.018692 kWh. Total GPU Power : 240.3087472035983 W\n",
            "[codecarbon INFO @ 23:58:37] 0.025063 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:58:52] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:52] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 23:58:52] Energy consumed for all GPUs : 0.019662 kWh. Total GPU Power : 239.00294705652553 W\n",
            "[codecarbon INFO @ 23:58:52] 0.026368 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:58:52] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:58:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:58:52] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 23:58:52] Energy consumed for all GPUs : 0.019688 kWh. Total GPU Power : 238.95636239012114 W\n",
            "[codecarbon INFO @ 23:58:52] 0.026394 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:59:07] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:59:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:59:07] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 23:59:07] Energy consumed for all GPUs : 0.020610 kWh. Total GPU Power : 227.56007852355168 W\n",
            "[codecarbon INFO @ 23:59:07] 0.027651 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:59:07] Energy consumed for RAM : 0.003324 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:59:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:59:07] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 23:59:07] Energy consumed for all GPUs : 0.020624 kWh. Total GPU Power : 224.69250743549762 W\n",
            "[codecarbon INFO @ 23:59:07] 0.027665 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:59:16] Energy consumed for RAM : 0.003414 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:59:16] Delta energy consumed for CPU with constant : 0.000102 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:59:16] Energy consumed for All CPU : 0.003819 kWh\n",
            "[codecarbon INFO @ 23:59:16] Energy consumed for all GPUs : 0.021016 kWh. Total GPU Power : 163.50994331456607 W\n",
            "[codecarbon INFO @ 23:59:16] 0.028250 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 23:59:16] Energy consumed for RAM : 0.003419 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 23:59:16] Delta energy consumed for CPU with constant : 0.000107 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 23:59:16] Energy consumed for All CPU : 0.003824 kWh\n",
            "[codecarbon INFO @ 23:59:16] Energy consumed for all GPUs : 0.021023 kWh. Total GPU Power : 164.04468589871385 W\n",
            "[codecarbon INFO @ 23:59:16] 0.028267 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "📈 FINE-TUNING RESULTS SUMMARY FOR 50.0% DATASET:\n",
            "================================================================================\n",
            "  Training Method: Full Fine-Tuning\n",
            "  Model: DistilBERT\n",
            "\n",
            "🔧 Model Parameters:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 66,364,418\n",
            "  Trainable Percentage: 100.00%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.5699\n",
            "  Exact Match: 0.4912\n",
            "  Eval Loss: 1.4439\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.028267 kWh\n",
            "  CPU Energy: 0.003824 kWh (13.5%)\n",
            "  GPU Energy: 0.021023 kWh (74.4%)\n",
            "  RAM Energy: 0.003419 kWh (12.1%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 164.04 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 244.54 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.013308 kg\n",
            "  Emissions Rate: 0.000041058 kg/s\n",
            "  Duration: 0.09 hours\n",
            "  Training Time (Trainer): 0.09 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: Singapore (SGP)\n",
            "  Region: \n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "CPU times: user 7min 1s, sys: 3.94 s, total: 7min 5s\n",
            "Wall time: 6min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Considering 80% of data for training the model\n",
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 3: FULL FINE-TUNING WITH 80.0% TRAINING DATASET\")\n",
        "print(\"=\"*80)\n",
        "result3 = run_experiment(\n",
        "        size_fraction=0.8,\n",
        "        train_data=squad[\"train\"],\n",
        "        eval_data=tokenized_validation,\n",
        "        tokenizer=tokenizer,\n",
        "        preprocess_fn=preprocess_function,\n",
        "        compute_metrics_fn=compute_metrics,\n",
        "        model_name=\"distilbert-base-uncased\"\n",
        "    )\n",
        "results_summary.append(result3)"
      ],
      "metadata": {
        "id": "imZIy0CEn_Pe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eaf6795b6099430da00ac3b06e29dc4b",
            "21662eede9974b028dd4478a0a1df75b",
            "97136229767543fdac6d8bcbe5299064",
            "14b736215075420e90ef1a9284fd68f6",
            "4631bb1b4a6140c4b669f224dc957f0a",
            "aeacdd781e0b46b5b5a84e9f313a49a1",
            "6a9339acff5b4cc09e99f362285e6bfd",
            "e40e3430dc524054a56077e71afe32e4",
            "b2d574e0bad747bc89835a4e6345b60a",
            "17723bc2382241429202140a0504b74e",
            "71a756333ec74067b186292d031e22c5"
          ]
        },
        "collapsed": true,
        "outputId": "d6a2b210-5106-4a8f-c0f2-54546d4aa4b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 3: FULL FINE-TUNING WITH 80.0% TRAINING DATASET\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/104255 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaf6795b6099430da00ac3b06e29dc4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1941336186.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "[codecarbon WARNING @ 00:00:31] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:00:31] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:00:31] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:00:32] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:00:32] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:00:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:00:32] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:00:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:00:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:00:32] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:00:32] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:00:32]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:00:32]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:00:32]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:00:32]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:00:32]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:00:32]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:00:32]   GPU count: 1\n",
            "[codecarbon INFO @ 00:00:32]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:00:32] Emissions data (if any) will be saved to file /content/results_distilbert_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 00:00:32] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:00:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:00:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:00:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:00:33] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:00:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:00:33] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:00:33] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:00:33] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:00:33] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:00:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:00:33]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:00:33]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:00:33]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:00:33]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:00:33]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:00:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:00:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:00:33]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:00:33] Emissions data (if any) will be saved to file /content/results_distilbert_80pct/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ Training model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:22, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.258200</td>\n",
              "      <td>1.223363</td>\n",
              "      <td>0.522416</td>\n",
              "      <td>0.594509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.895300</td>\n",
              "      <td>1.300501</td>\n",
              "      <td>0.531564</td>\n",
              "      <td>0.610566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:00:48] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:00:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:00:48] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:00:48] Energy consumed for all GPUs : 0.000940 kWh. Total GPU Power : 225.44832774736338 W\n",
            "[codecarbon INFO @ 00:00:48] 0.001276 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:00:49] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:00:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:00:49] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:00:49] Energy consumed for all GPUs : 0.000958 kWh. Total GPU Power : 229.75635691186548 W\n",
            "[codecarbon INFO @ 00:00:49] 0.001293 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:03] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:03] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:01:03] Energy consumed for all GPUs : 0.001924 kWh. Total GPU Power : 236.13990084418606 W\n",
            "[codecarbon INFO @ 00:01:03] 0.002594 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:04] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:04] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:01:04] Energy consumed for all GPUs : 0.001943 kWh. Total GPU Power : 236.33243441832096 W\n",
            "[codecarbon INFO @ 00:01:04] 0.002613 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:18] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:18] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:01:18] Energy consumed for all GPUs : 0.002919 kWh. Total GPU Power : 238.84483172885552 W\n",
            "[codecarbon INFO @ 00:01:18] 0.003925 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:19] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:19] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:01:19] Energy consumed for all GPUs : 0.002944 kWh. Total GPU Power : 240.482548153869 W\n",
            "[codecarbon INFO @ 00:01:19] 0.003951 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:33] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:33] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:01:33] Energy consumed for all GPUs : 0.003921 kWh. Total GPU Power : 240.67181447246105 W\n",
            "[codecarbon INFO @ 00:01:33] 0.005263 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:34] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:34] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:01:34] Energy consumed for all GPUs : 0.003947 kWh. Total GPU Power : 240.72330211613212 W\n",
            "[codecarbon INFO @ 00:01:34] 0.005289 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:48] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:48] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:01:48] Energy consumed for all GPUs : 0.004926 kWh. Total GPU Power : 241.2808297238928 W\n",
            "[codecarbon INFO @ 00:01:48] 0.006603 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:01:49] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:01:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:01:49] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:01:49] Energy consumed for all GPUs : 0.004946 kWh. Total GPU Power : 239.66008610560232 W\n",
            "[codecarbon INFO @ 00:01:49] 0.006622 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:03] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:03] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:02:03] Energy consumed for all GPUs : 0.005925 kWh. Total GPU Power : 239.63687732311746 W\n",
            "[codecarbon INFO @ 00:02:03] 0.007936 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:04] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:04] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:02:04] Energy consumed for all GPUs : 0.005950 kWh. Total GPU Power : 241.06474513727457 W\n",
            "[codecarbon INFO @ 00:02:04] 0.007962 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:18] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:18] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:02:18] Energy consumed for all GPUs : 0.006926 kWh. Total GPU Power : 240.43714862048193 W\n",
            "[codecarbon INFO @ 00:02:18] 0.009274 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:19] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:19] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:02:19] Energy consumed for all GPUs : 0.006946 kWh. Total GPU Power : 239.04495998916028 W\n",
            "[codecarbon INFO @ 00:02:19] 0.009293 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:33] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:33] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:02:33] Energy consumed for all GPUs : 0.007928 kWh. Total GPU Power : 240.37196755169413 W\n",
            "[codecarbon INFO @ 00:02:33] 0.010610 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:33] 0.041618 g.CO2eq/s mean an estimation of 1,312.453313106433 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:02:34] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:34] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:02:34] Energy consumed for all GPUs : 0.007947 kWh. Total GPU Power : 240.32180014651664 W\n",
            "[codecarbon INFO @ 00:02:34] 0.010629 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:34] 0.041693 g.CO2eq/s mean an estimation of 1,314.815660638816 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:02:48] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:48] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:02:49] Energy consumed for all GPUs : 0.008929 kWh. Total GPU Power : 240.347620479232 W\n",
            "[codecarbon INFO @ 00:02:49] 0.011947 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:02:49] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:02:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:02:49] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:02:49] Energy consumed for all GPUs : 0.008954 kWh. Total GPU Power : 241.91889739218317 W\n",
            "[codecarbon INFO @ 00:02:49] 0.011972 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:03] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:03] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 00:03:03] Energy consumed for all GPUs : 0.009928 kWh. Total GPU Power : 239.950876735881 W\n",
            "[codecarbon INFO @ 00:03:03] 0.013281 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:04] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:04] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 00:03:04] Energy consumed for all GPUs : 0.009954 kWh. Total GPU Power : 239.91982852223617 W\n",
            "[codecarbon INFO @ 00:03:04] 0.013307 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:18] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:18] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 00:03:18] Energy consumed for all GPUs : 0.010934 kWh. Total GPU Power : 241.45782081924617 W\n",
            "[codecarbon INFO @ 00:03:18] 0.014622 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:19] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:19] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 00:03:19] Energy consumed for all GPUs : 0.010953 kWh. Total GPU Power : 239.90827714910816 W\n",
            "[codecarbon INFO @ 00:03:19] 0.014642 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:33] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:34] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 00:03:34] Energy consumed for all GPUs : 0.011933 kWh. Total GPU Power : 239.61393834443854 W\n",
            "[codecarbon INFO @ 00:03:34] 0.015956 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:34] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:34] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 00:03:34] Energy consumed for all GPUs : 0.011951 kWh. Total GPU Power : 239.5411206388537 W\n",
            "[codecarbon INFO @ 00:03:34] 0.015974 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:48] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:48] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 00:03:49] Energy consumed for all GPUs : 0.012933 kWh. Total GPU Power : 240.17693622833156 W\n",
            "[codecarbon INFO @ 00:03:49] 0.017292 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:03:49] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:03:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:03:49] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 00:03:49] Energy consumed for all GPUs : 0.012959 kWh. Total GPU Power : 242.0753958614444 W\n",
            "[codecarbon INFO @ 00:03:49] 0.017318 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:03] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:03] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 00:04:04] Energy consumed for all GPUs : 0.013935 kWh. Total GPU Power : 240.480074934853 W\n",
            "[codecarbon INFO @ 00:04:04] 0.018629 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:04] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:04] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 00:04:04] Energy consumed for all GPUs : 0.013954 kWh. Total GPU Power : 238.80321161135362 W\n",
            "[codecarbon INFO @ 00:04:04] 0.018648 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:18] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:19] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 00:04:19] Energy consumed for all GPUs : 0.014939 kWh. Total GPU Power : 241.03032715217668 W\n",
            "[codecarbon INFO @ 00:04:19] 0.019968 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:19] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:19] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 00:04:19] Energy consumed for all GPUs : 0.014958 kWh. Total GPU Power : 241.04306199256027 W\n",
            "[codecarbon INFO @ 00:04:19] 0.019987 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:33] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:34] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:04:34] Energy consumed for all GPUs : 0.015918 kWh. Total GPU Power : 235.04741158395908 W\n",
            "[codecarbon INFO @ 00:04:34] 0.021283 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:34] 0.041864 g.CO2eq/s mean an estimation of 1,320.2209960526025 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:04:34] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:34] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:04:34] Energy consumed for all GPUs : 0.015937 kWh. Total GPU Power : 234.96160966744094 W\n",
            "[codecarbon INFO @ 00:04:34] 0.021301 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:34] 0.041868 g.CO2eq/s mean an estimation of 1,320.3519388454913 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:04:48] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:49] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 00:04:49] Energy consumed for all GPUs : 0.016696 kWh. Total GPU Power : 186.82383025973988 W\n",
            "[codecarbon INFO @ 00:04:49] 0.022396 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:04:49] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:04:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:04:49] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 00:04:49] Energy consumed for all GPUs : 0.016721 kWh. Total GPU Power : 188.35382627380918 W\n",
            "[codecarbon INFO @ 00:04:49] 0.022421 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:03] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:04] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 00:05:04] Energy consumed for all GPUs : 0.017693 kWh. Total GPU Power : 239.15041010387196 W\n",
            "[codecarbon INFO @ 00:05:04] 0.023728 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:04] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:04] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 00:05:04] Energy consumed for all GPUs : 0.017711 kWh. Total GPU Power : 237.68801098174302 W\n",
            "[codecarbon INFO @ 00:05:04] 0.023747 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:18] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:19] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 00:05:19] Energy consumed for all GPUs : 0.018689 kWh. Total GPU Power : 239.29081561492603 W\n",
            "[codecarbon INFO @ 00:05:19] 0.025059 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:19] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:19] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 00:05:19] Energy consumed for all GPUs : 0.018708 kWh. Total GPU Power : 239.3505777345108 W\n",
            "[codecarbon INFO @ 00:05:19] 0.025078 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:34] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:34] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 00:05:34] Energy consumed for all GPUs : 0.019684 kWh. Total GPU Power : 238.85908861089905 W\n",
            "[codecarbon INFO @ 00:05:34] 0.026389 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:34] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:34] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 00:05:34] Energy consumed for all GPUs : 0.019710 kWh. Total GPU Power : 240.54539451512892 W\n",
            "[codecarbon INFO @ 00:05:34] 0.026415 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:49] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:49] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 00:05:49] Energy consumed for all GPUs : 0.020688 kWh. Total GPU Power : 240.90422823930194 W\n",
            "[codecarbon INFO @ 00:05:49] 0.027728 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:05:49] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:05:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:05:49] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 00:05:49] Energy consumed for all GPUs : 0.020707 kWh. Total GPU Power : 239.22111525650058 W\n",
            "[codecarbon INFO @ 00:05:49] 0.027747 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:04] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:04] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 00:06:04] Energy consumed for all GPUs : 0.021682 kWh. Total GPU Power : 238.649503282365 W\n",
            "[codecarbon INFO @ 00:06:04] 0.029058 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:04] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:04] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 00:06:04] Energy consumed for all GPUs : 0.021700 kWh. Total GPU Power : 238.54859603688985 W\n",
            "[codecarbon INFO @ 00:06:04] 0.029076 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:19] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:19] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 00:06:19] Energy consumed for all GPUs : 0.022670 kWh. Total GPU Power : 237.19143873964833 W\n",
            "[codecarbon INFO @ 00:06:19] 0.030381 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:19] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:19] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 00:06:19] Energy consumed for all GPUs : 0.022695 kWh. Total GPU Power : 238.7336618638843 W\n",
            "[codecarbon INFO @ 00:06:19] 0.030406 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:34] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:34] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 00:06:34] Energy consumed for all GPUs : 0.023668 kWh. Total GPU Power : 239.76166194147325 W\n",
            "[codecarbon INFO @ 00:06:34] 0.031715 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:34] 0.040926 g.CO2eq/s mean an estimation of 1,290.6386548393525 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:06:34] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:34] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 00:06:34] Energy consumed for all GPUs : 0.023687 kWh. Total GPU Power : 238.0413327362976 W\n",
            "[codecarbon INFO @ 00:06:34] 0.031733 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:34] 0.040923 g.CO2eq/s mean an estimation of 1,290.5365091147146 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:06:49] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:49] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 00:06:49] Energy consumed for all GPUs : 0.024658 kWh. Total GPU Power : 237.56729866981044 W\n",
            "[codecarbon INFO @ 00:06:49] 0.033039 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:06:49] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:06:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:06:49] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 00:06:49] Energy consumed for all GPUs : 0.024677 kWh. Total GPU Power : 237.71699134483646 W\n",
            "[codecarbon INFO @ 00:06:49] 0.033059 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:04] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:04] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 00:07:04] Energy consumed for all GPUs : 0.025651 kWh. Total GPU Power : 238.2754877320716 W\n",
            "[codecarbon INFO @ 00:07:04] 0.034368 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:04] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:04] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 00:07:04] Energy consumed for all GPUs : 0.025676 kWh. Total GPU Power : 239.89708039910124 W\n",
            "[codecarbon INFO @ 00:07:04] 0.034393 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:19] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:19] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 00:07:19] Energy consumed for all GPUs : 0.026647 kWh. Total GPU Power : 239.17328933348688 W\n",
            "[codecarbon INFO @ 00:07:19] 0.035699 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:19] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:19] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 00:07:19] Energy consumed for all GPUs : 0.026666 kWh. Total GPU Power : 237.74641677923023 W\n",
            "[codecarbon INFO @ 00:07:19] 0.035718 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:34] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:34] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 00:07:34] Energy consumed for all GPUs : 0.027640 kWh. Total GPU Power : 238.15234152688168 W\n",
            "[codecarbon INFO @ 00:07:34] 0.037027 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:34] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:34] Energy consumed for All CPU : 0.004956 kWh\n",
            "[codecarbon INFO @ 00:07:34] Energy consumed for all GPUs : 0.027658 kWh. Total GPU Power : 238.01207206849114 W\n",
            "[codecarbon INFO @ 00:07:34] 0.037046 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:49] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:49] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 00:07:49] Energy consumed for all GPUs : 0.028630 kWh. Total GPU Power : 237.6950952413945 W\n",
            "[codecarbon INFO @ 00:07:49] 0.038353 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:07:49] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:07:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:07:49] Energy consumed for All CPU : 0.005133 kWh\n",
            "[codecarbon INFO @ 00:07:49] Energy consumed for all GPUs : 0.028655 kWh. Total GPU Power : 239.24335673547625 W\n",
            "[codecarbon INFO @ 00:07:49] 0.038377 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:04] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:04] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 00:08:04] Energy consumed for all GPUs : 0.029633 kWh. Total GPU Power : 240.80783647255387 W\n",
            "[codecarbon INFO @ 00:08:04] 0.039691 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:04] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:04] Energy consumed for All CPU : 0.005310 kWh\n",
            "[codecarbon INFO @ 00:08:04] Energy consumed for all GPUs : 0.029652 kWh. Total GPU Power : 239.41614533167777 W\n",
            "[codecarbon INFO @ 00:08:04] 0.039710 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:19] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:19] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 00:08:19] Energy consumed for all GPUs : 0.030629 kWh. Total GPU Power : 239.20787598366775 W\n",
            "[codecarbon INFO @ 00:08:19] 0.041022 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:19] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:19] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 00:08:19] Energy consumed for all GPUs : 0.030648 kWh. Total GPU Power : 239.0998461848113 W\n",
            "[codecarbon INFO @ 00:08:19] 0.041041 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:34] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:34] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 00:08:34] Energy consumed for all GPUs : 0.031625 kWh. Total GPU Power : 239.00885191395756 W\n",
            "[codecarbon INFO @ 00:08:34] 0.042353 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:34] 0.041733 g.CO2eq/s mean an estimation of 1,316.0952358764694 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:08:34] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:34] Energy consumed for All CPU : 0.005664 kWh\n",
            "[codecarbon INFO @ 00:08:34] Energy consumed for all GPUs : 0.031644 kWh. Total GPU Power : 239.03445264623917 W\n",
            "[codecarbon INFO @ 00:08:34] 0.042372 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:34] 0.041734 g.CO2eq/s mean an estimation of 1,316.1343724414796 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:08:49] Energy consumed for RAM : 0.005222 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:49] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 00:08:49] Energy consumed for all GPUs : 0.032556 kWh. Total GPU Power : 223.56186571445403 W\n",
            "[codecarbon INFO @ 00:08:49] 0.043620 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:49] Energy consumed for RAM : 0.005222 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:49] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 00:08:49] Energy consumed for all GPUs : 0.032574 kWh. Total GPU Power : 223.22957012698643 W\n",
            "[codecarbon INFO @ 00:08:49] 0.043638 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:57] Energy consumed for RAM : 0.005305 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:57] Delta energy consumed for CPU with constant : 0.000092 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:57] Energy consumed for All CPU : 0.005934 kWh\n",
            "[codecarbon INFO @ 00:08:57] Energy consumed for all GPUs : 0.032950 kWh. Total GPU Power : 173.52413167380286 W\n",
            "[codecarbon INFO @ 00:08:57] 0.044189 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:08:57] Energy consumed for RAM : 0.005309 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:08:57] Delta energy consumed for CPU with constant : 0.000098 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:08:57] Energy consumed for All CPU : 0.005939 kWh\n",
            "[codecarbon INFO @ 00:08:57] Energy consumed for all GPUs : 0.032958 kWh. Total GPU Power : 175.13493587037695 W\n",
            "[codecarbon INFO @ 00:08:57] 0.044206 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "📈 FINE-TUNING RESULTS SUMMARY FOR 80.0% DATASET:\n",
            "================================================================================\n",
            "  Training Method: Full Fine-Tuning\n",
            "  Model: DistilBERT\n",
            "\n",
            "🔧 Model Parameters:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 66,364,418\n",
            "  Trainable Percentage: 100.00%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.6106\n",
            "  Exact Match: 0.5316\n",
            "  Eval Loss: 1.3005\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.044206 kWh\n",
            "  CPU Energy: 0.005939 kWh (13.4%)\n",
            "  GPU Energy: 0.032958 kWh (74.6%)\n",
            "  RAM Energy: 0.005309 kWh (12.0%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 175.13 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 255.63 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.020812 kg\n",
            "  Emissions Rate: 0.000041348 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: Singapore (SGP)\n",
            "  Region: \n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "CPU times: user 10min 56s, sys: 5.73 s, total: 11min 1s\n",
            "Wall time: 9min 41s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###STEP 4.1: Results and Analysis"
      ],
      "metadata": {
        "id": "EZQ5cC8fqzIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summary DataFrame\n",
        "results_df = pd.DataFrame(results_summary)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivXHD_NMnssg",
        "outputId": "28c1956b-dbf9-41fd-c8f9-5dcbe17bfa70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📊 FINAL RESULTS SUMMARY\n",
            "============================================================\n",
            " training_method model_name  dataset_size%  train_samples  valid_samples  trainable_params  total_params  trainable_percentage  f1_score  exact_match  eval_loss  training_time_hours  emissions_rate_kg_per_s  emissions_kg           timestamp  duration_seconds  duration_hours  energy_consumed_kwh  cpu_energy_kwh  gpu_energy_kwh  ram_energy_kwh  cpu_power_w  gpu_power_w  ram_power_w country_name country_iso_code region cloud_provider cloud_region on_cloud                                   os python_version  cpu_count                      cpu_model  gpu_count                 gpu_model  ram_total_size_gb  pue codecarbon_version\n",
            "Full Fine-Tuning DistilBERT             25          32579          12134          66364418      66364418                 100.0  0.456665     0.387341   1.750965             0.050625                 0.000039      0.007162 2025-11-26T23:52:58        182.677884        0.050744             0.015213        0.002155        0.011131        0.001927         42.5   140.819921         38.0    Singapore              SGP                                           N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.1.1\n",
            "Full Fine-Tuning DistilBERT             50          65159          12134          66364418      66364418                 100.0  0.569894     0.491182   1.443919             0.089906                 0.000041      0.013308 2025-11-26T23:59:16        324.118881        0.090033             0.028267        0.003824        0.021023        0.003419         42.5   164.044686         38.0    Singapore              SGP                                           N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.1.1\n",
            "Full Fine-Tuning DistilBERT             80         104255          12134          66364418      66364418                 100.0  0.610566     0.531564   1.300501             0.139686                 0.000041      0.020812 2025-11-27T00:08:57        503.329622        0.139814             0.044206        0.005939        0.032958        0.005309         42.5   175.134936         38.0    Singapore              SGP                                           N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"/content/drive/MyDrive/distilbert_dataset_size_results.csv\", index=False)\n",
        "print(\"\\n✅ Results saved to Google Drive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "630R99pens8p",
        "outputId": "eeae925d-bc02-4470-b87f-df6d56f23bd1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Results saved to Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "full_ft_results = pd.read_csv(\"/content/drive/MyDrive/distilbert_dataset_size_results.csv\")\n",
        "\n",
        "print(\"📊 Data loaded successfully!\")\n",
        "print(f\"Total experiments: {len(full_ft_results)}\")\n",
        "print(\"\\nExperiments:\")\n",
        "print(full_ft_results[['train_samples', 'dataset_size%', 'f1_score', 'emissions_kg']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwRzBhAotdh",
        "outputId": "af71b5c3-1a9b-4bc9-879b-519b48f202c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Data loaded successfully!\n",
            "Total experiments: 3\n",
            "\n",
            "Experiments:\n",
            "   train_samples  dataset_size%  f1_score  emissions_kg\n",
            "0          32579             25  0.456665      0.007162\n",
            "1          65159             50  0.569894      0.013308\n",
            "2         104255             80  0.610566      0.020812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT 1: Energy Consumption vs Dataset Size (Stacked Area)\n",
        "df_sorted = full_ft_results.sort_values('train_samples')\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    name='CPU Energy',\n",
        "    x=df_sorted['dataset_size%'],\n",
        "    y=df_sorted['cpu_energy_kwh'],\n",
        "    marker_color='#FF6B6B',\n",
        "    hovertemplate='<b>CPU Energy</b><br>%{y:.6f} kWh<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    name='GPU Energy',\n",
        "    x=df_sorted['dataset_size%'],\n",
        "    y=df_sorted['gpu_energy_kwh'],\n",
        "    marker_color='#4ECDC4',\n",
        "    hovertemplate='<b>GPU Energy</b><br>%{y:.6f} kWh<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    name='RAM Energy',\n",
        "    x=df_sorted['dataset_size%'],\n",
        "    y=df_sorted['ram_energy_kwh'],\n",
        "    marker_color='#95E1D3',\n",
        "    hovertemplate='<b>RAM Energy</b><br>%{y:.6f} kWh<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=dict(text=\"Energy Consumption Scaling with Dataset Size\", font=dict(size=18)),\n",
        "    xaxis_title='Dataset Size (%)',\n",
        "    yaxis_title='Energy Consumption (kWh)',\n",
        "    barmode='stack',\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "fig.write_html(\"/content/drive/MyDrive/full_ft_energy_scaling.html\")\n",
        "print(\"\\n✅ Plot 1 saved: full_ft_energy_scaling.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "gRFN8qeNo3OR",
        "outputId": "0e30626e-3eec-494b-8e60-e208154a2afc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"bd450d41-d9a8-45f5-a482-062bdfbd7aa3\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bd450d41-d9a8-45f5-a482-062bdfbd7aa3\")) {                    Plotly.newPlot(                        \"bd450d41-d9a8-45f5-a482-062bdfbd7aa3\",                        [{\"hovertemplate\":\"\\u003cb\\u003eCPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CPU Energy\",\"x\":[25,50,80],\"y\":[0.002155498404659,0.0038244515247027,0.0059390585840291],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eGPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#4ECDC4\"},\"name\":\"GPU Energy\",\"x\":[25,50,80],\"y\":[0.01113057418223,0.02102344042985,0.032957887199622],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eRAM Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#95E1D3\"},\"name\":\"RAM Energy\",\"x\":[25,50,80],\"y\":[0.0019270497012994,0.0034191279731922,0.0053094970826672],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":18},\"text\":\"Energy Consumption Scaling with Dataset Size\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Dataset Size (%)\"}},\"yaxis\":{\"title\":{\"text\":\"Energy Consumption (kWh)\"}},\"barmode\":\"stack\",\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bd450d41-d9a8-45f5-a482-062bdfbd7aa3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Plot 1 saved: full_ft_energy_scaling.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT 2: Performance & Emissions Growth (Dual Y-axis)\n",
        "df_sorted = full_ft_results.sort_values('train_samples')\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# F1 Score line\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted['dataset_size%'],\n",
        "        y=df_sorted['f1_score'],\n",
        "        name='F1 Score',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#4ECDC4', width=3),\n",
        "        marker=dict(size=12, line=dict(width=2, color='white')),\n",
        "        hovertemplate='<b>F1 Score</b>: %{y:.4f}<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# Exact Match line\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted['dataset_size%'],\n",
        "        y=df_sorted['exact_match'],\n",
        "        name='Exact Match',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#95E1D3', width=3, dash='dash'),\n",
        "        marker=dict(size=10),\n",
        "        hovertemplate='<b>Exact Match</b>: %{y:.4f}<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# CO2 Emissions bar\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=df_sorted['dataset_size%'],\n",
        "        y=df_sorted['emissions_kg'],\n",
        "        name='CO₂ Emissions',\n",
        "        marker_color='#FF6B6B',\n",
        "        opacity=0.6,\n",
        "        hovertemplate='<b>CO₂</b>: %{y:.6f} kg<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=True\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Dataset Size (%)\")\n",
        "fig.update_yaxes(title_text=\"Performance Score\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"CO₂ Emissions (kg)\", secondary_y=True)\n",
        "\n",
        "fig.update_layout(\n",
        "    title=dict(text=\"Performance vs Carbon Emissions by Dataset Size\", font=dict(size=18)),\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "fig.write_html(\"/content/drive/MyDrive/full_ft_performance_emissions.html\")\n",
        "print(\"\\n✅ Plot 2 saved: full_ft_performance_emissions.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "yYHMfPECo3e7",
        "outputId": "5da6f8ea-279c-43b6-ed2c-cc0e7545d961"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6c0abc69-4a7c-4e57-a47f-3c5de10b1864\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6c0abc69-4a7c-4e57-a47f-3c5de10b1864\")) {                    Plotly.newPlot(                        \"6c0abc69-4a7c-4e57-a47f-3c5de10b1864\",                        [{\"hovertemplate\":\"\\u003cb\\u003eF1 Score\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#4ECDC4\",\"width\":3},\"marker\":{\"line\":{\"color\":\"white\",\"width\":2},\"size\":12},\"mode\":\"lines+markers\",\"name\":\"F1 Score\",\"x\":[25,50,80],\"y\":[0.4566648040092304,0.5698938079501877,0.6105658734435491],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eExact Match\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#95E1D3\",\"dash\":\"dash\",\"width\":3},\"marker\":{\"size\":10},\"mode\":\"lines+markers\",\"name\":\"Exact Match\",\"x\":[25,50,80],\"y\":[0.3873413548706115,0.4911818031976265,0.5315641997692434],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eCO₂\\u003c\\u002fb\\u003e: %{y:.6f} kg\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CO₂ Emissions\",\"opacity\":0.6,\"x\":[25,50,80],\"y\":[0.0071620793502002,0.0133076324426435,0.0208116417919339],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Dataset Size (%)\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Performance Score\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"CO₂ Emissions (kg)\"}},\"title\":{\"font\":{\"size\":18},\"text\":\"Performance vs Carbon Emissions by Dataset Size\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6c0abc69-4a7c-4e57-a47f-3c5de10b1864');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Plot 2 saved: full_ft_performance_emissions.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaEO8Qv3o8hl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0V-JV8Oro8zj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Strategy 2: LoRA (Low-Rank Adaptation) fine-tuning (Model DistilBERT)"
      ],
      "metadata": {
        "id": "_4XfW7zCt480"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import PEFT for LoRA\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel"
      ],
      "metadata": {
        "id": "hDRdOCsVuUIr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5: Creating And Training LoRA Model"
      ],
      "metadata": {
        "id": "exzVOf5BpGqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lora_model(model_name=\"distilbert-base-uncased\", r=8, lora_alpha=16, lora_dropout=0.1):\n",
        "    # Load base model\n",
        "    base_model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "    # Configure LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        task_type=TaskType.QUESTION_ANS,  # Task type for QA\n",
        "        r=r,                               # Rank of update matrices\n",
        "        lora_alpha=lora_alpha,             # Scaling factor\n",
        "        lora_dropout=lora_dropout,         # Dropout probability\n",
        "        target_modules=[\"q_lin\", \"v_lin\"], # Which layers to apply LoRA to\n",
        "        bias=\"none\",                       # Don't train biases\n",
        "        inference_mode=False,              # Training mode\n",
        "    )\n",
        "\n",
        "    # Apply LoRA to model\n",
        "    lora_model = get_peft_model(base_model, lora_config)\n",
        "\n",
        "    # Print trainable parameters\n",
        "    lora_model.print_trainable_parameters()\n",
        "\n",
        "    return lora_model"
      ],
      "metadata": {
        "id": "LvqhQvzvpBt3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lora_model(tokenized_train, tokenized_eval, tokenizer, compute_metrics_fn,\n",
        "                     size_fraction, lora_rank=8):\n",
        "\n",
        "    # Create LoRA model\n",
        "    print(f\"\\n🔧 Creating LoRA model (rank={lora_rank})...\")\n",
        "    lora_model = create_lora_model(\n",
        "        model_name=\"distilbert-base-uncased\",\n",
        "        r=lora_rank,\n",
        "        lora_alpha=lora_rank * 2,  # Common practice: alpha = 2*r\n",
        "        lora_dropout=0.1\n",
        "    )\n",
        "\n",
        "    # Setup output directory\n",
        "    output_dir = f\"results_distilbert_lora_r{lora_rank}_{int(size_fraction*100)}pct\"\n",
        "\n",
        "    # Training arguments (can use higher learning rate for LoRA)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=3e-4,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=2,\n",
        "        weight_decay=0.01,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        push_to_hub=False,\n",
        "        logging_steps=100,\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=lora_model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        compute_metrics=compute_metrics_fn\n",
        "    )\n",
        "\n",
        "    # Start carbon tracking\n",
        "    tracker = EmissionsTracker(\n",
        "        project_name=f\"DistilBERT_LoRA_r{lora_rank}_{int(size_fraction*100)}pct\",\n",
        "        output_dir=output_dir,\n",
        "        save_to_file=True,\n",
        "        log_level=\"info\"\n",
        "    )\n",
        "    tracker.start()\n",
        "\n",
        "    # Train\n",
        "    print(\"🏋️ Training LoRA model...\")\n",
        "    train_results = trainer.train()\n",
        "\n",
        "    # Stop tracking and get detailed emissions data\n",
        "    emissions_kg = tracker.stop()\n",
        "\n",
        "    # Get full emissions data object\n",
        "    emissions_data = tracker.final_emissions_data\n",
        "\n",
        "    return trainer, train_results, emissions_data, output_dir, lora_model"
      ],
      "metadata": {
        "id": "2D4pyEJ9uUbt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "neFHBVv8pLfq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F75_XSD6pLs7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##STEP 6: Evaluating The LoRA Model On Different Rank Sizes\n",
        "\n",
        "> We will be training our model on various ranks from our SQuAD dataset.\n",
        ">\n",
        "> Training Data Rank Variation: [4, 8, 16]"
      ],
      "metadata": {
        "id": "El007ewSpM-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_save_lora(trainer, train_results, emissions_data, output_dir,\n",
        "                           size_fraction, num_samples, lora_model):\n",
        "    \"\"\"Evaluate LoRA model and save results with detailed emissions.\"\"\"\n",
        "    print(\"📊 Evaluating LoRA model...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Count trainable parameters\n",
        "    trainable_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in lora_model.parameters())\n",
        "    trainable_percentage = 100 * trainable_params / total_params\n",
        "\n",
        "    # Extract emissions data from EmissionsData object\n",
        "    result_entry = {\n",
        "        \"training_method\": \"LoRA\",\n",
        "        \"model_name\": \"DistilBERT\",\n",
        "        \"lora_rank\": lora_model.peft_config['default'].r,\n",
        "        \"train_samples\": num_samples,\n",
        "        \"valid_samples\": len(tokenized_validation),\n",
        "        \"trainable_params\": trainable_params,\n",
        "        \"total_params\": total_params,\n",
        "        \"trainable_percentage\": trainable_percentage,\n",
        "\n",
        "        # Performance metrics\n",
        "        \"f1_score\": eval_results[\"eval_f1\"],\n",
        "        \"exact_match\": eval_results[\"eval_exact_match\"],\n",
        "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
        "        \"training_time_hours\": train_results.metrics[\"train_runtime\"] / 3600,\n",
        "\n",
        "        # Emissions data (direct access to EmissionsData attributes)\n",
        "        \"emissions_rate_kg_per_s\": emissions_data.emissions_rate,\n",
        "        \"emissions_kg\": emissions_data.emissions,\n",
        "        \"timestamp\": emissions_data.timestamp,\n",
        "        \"duration_seconds\": emissions_data.duration,\n",
        "        \"duration_hours\": emissions_data.duration / 3600,\n",
        "\n",
        "        # Energy consumption\n",
        "        \"energy_consumed_kwh\": emissions_data.energy_consumed,\n",
        "        \"cpu_energy_kwh\": emissions_data.cpu_energy,\n",
        "        \"gpu_energy_kwh\": emissions_data.gpu_energy,\n",
        "        \"ram_energy_kwh\": emissions_data.ram_energy,\n",
        "\n",
        "        # Power draw\n",
        "        \"cpu_power_w\": emissions_data.cpu_power,\n",
        "        \"gpu_power_w\": emissions_data.gpu_power,\n",
        "        \"ram_power_w\": emissions_data.ram_power,\n",
        "\n",
        "        # Location and system info\n",
        "        \"country_name\": emissions_data.country_name,\n",
        "        \"country_iso_code\": emissions_data.country_iso_code,\n",
        "        \"region\": emissions_data.region,\n",
        "        \"cloud_provider\": emissions_data.cloud_provider,\n",
        "        \"cloud_region\": emissions_data.cloud_region,\n",
        "        \"on_cloud\": emissions_data.on_cloud,\n",
        "\n",
        "        # System specifications\n",
        "        \"os\": emissions_data.os,\n",
        "        \"python_version\": emissions_data.python_version,\n",
        "        \"cpu_count\": emissions_data.cpu_count,\n",
        "        \"cpu_model\": emissions_data.cpu_model,\n",
        "        \"gpu_count\": emissions_data.gpu_count,\n",
        "        \"gpu_model\": emissions_data.gpu_model,\n",
        "        \"ram_total_size_gb\": emissions_data.ram_total_size,\n",
        "\n",
        "        # Additional metrics\n",
        "        \"pue\": emissions_data.pue,  # Power Usage Effectiveness\n",
        "        \"codecarbon_version\": emissions_data.codecarbon_version,\n",
        "    }\n",
        "\n",
        "    # Print detailed summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"📈 LoRA RESULTS SUMMARY (Rank {result_entry['lora_rank']})\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    print(f\"\\n🔧 Model Configuration:\")\n",
        "    print(f\"  Training Method: LoRA\")\n",
        "    print(f\"  LoRA Rank: {result_entry['lora_rank']}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,} ({trainable_percentage:.2f}%)\")\n",
        "    print(f\"  Total Parameters: {total_params:,}\")\n",
        "    print(f\"  Dataset Size: {size_fraction*100}%\")\n",
        "\n",
        "    print(f\"\\n🎯 Performance Metrics:\")\n",
        "    print(f\"  F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"  Exact Match: {eval_results['eval_exact_match']:.4f}\")\n",
        "    print(f\"  Eval Loss: {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\n⚡ Energy Consumption:\")\n",
        "    print(f\"  Total Energy: {emissions_data.energy_consumed:.6f} kWh\")\n",
        "    print(f\"  CPU Energy: {emissions_data.cpu_energy:.6f} kWh ({emissions_data.cpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  GPU Energy: {emissions_data.gpu_energy:.6f} kWh ({emissions_data.gpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  RAM Energy: {emissions_data.ram_energy:.6f} kWh ({emissions_data.ram_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n🔌 Average Power Draw:\")\n",
        "    print(f\"  CPU Power: {emissions_data.cpu_power:.2f} W\")\n",
        "    print(f\"  GPU Power: {emissions_data.gpu_power:.2f} W\")\n",
        "    print(f\"  RAM Power: {emissions_data.ram_power:.2f} W\")\n",
        "    print(f\"  Total Power: {emissions_data.cpu_power + emissions_data.gpu_power + emissions_data.ram_power:.2f} W\")\n",
        "\n",
        "    print(f\"\\n🌱 Carbon Footprint:\")\n",
        "    print(f\"  Total CO2 Emissions: {emissions_data.emissions:.6f} kg\")\n",
        "    print(f\"  Emissions Rate: {emissions_data.emissions_rate:.9f} kg/s\")\n",
        "    print(f\"  Duration: {emissions_data.duration/3600:.2f} hours\")\n",
        "    print(f\"  Training Time (Trainer): {train_results.metrics['train_runtime']/3600:.2f} hours\")\n",
        "\n",
        "    print(f\"\\n📍 Location & Infrastructure:\")\n",
        "    print(f\"  Country: {emissions_data.country_name} ({emissions_data.country_iso_code})\")\n",
        "    print(f\"  Region: {emissions_data.region}\")\n",
        "    print(f\"  On Cloud: {emissions_data.on_cloud}\")\n",
        "    print(f\"  PUE (Power Usage Effectiveness): {emissions_data.pue}\")\n",
        "\n",
        "    print(f\"\\n💻 System Specifications:\")\n",
        "    print(f\"  OS: {emissions_data.os}\")\n",
        "    print(f\"  CPU: {emissions_data.cpu_model} ({emissions_data.cpu_count} cores)\")\n",
        "    if emissions_data.gpu_count and emissions_data.gpu_model:\n",
        "        print(f\"  GPU: {emissions_data.gpu_model} (Count: {emissions_data.gpu_count})\")\n",
        "    else:\n",
        "        print(f\"  GPU: None detected\")\n",
        "    print(f\"  RAM: {emissions_data.ram_total_size:.2f} GB\")\n",
        "    print(f\"  Python: {emissions_data.python_version}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "\n",
        "    # Save LoRA adapters\n",
        "    lora_model.save_pretrained(f\"{output_dir}/lora_adapters\")\n",
        "    tokenizer.save_pretrained(f\"{output_dir}/lora_adapters\")\n",
        "    print(f\"✅ LoRA adapters saved to {output_dir}/lora_adapters\")\n",
        "\n",
        "    # Clean up\n",
        "    del trainer.model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result_entry\n"
      ],
      "metadata": {
        "id": "YWrdJgkupRD4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_lora_experiment(size_fraction, train_data, eval_data, tokenizer, preprocess_fn, compute_metrics_fn, lora_rank):\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🚀 LoRA Training with {size_fraction*100}% of training data\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Step 1: Prepare dataset\n",
        "    tokenized_train, num_samples = prepare_dataset(train_data, size_fraction, preprocess_fn)\n",
        "\n",
        "    # Step 2: Train LoRA model\n",
        "    trainer, train_results, emissions_data, output_dir, lora_model = train_lora_model(\n",
        "        tokenized_train, eval_data, tokenizer, compute_metrics_fn,\n",
        "        size_fraction, lora_rank\n",
        "    )\n",
        "\n",
        "    # Step 3: Evaluate and save\n",
        "    result_entry = evaluate_and_save_lora(trainer, train_results, emissions_data, output_dir, size_fraction, num_samples, lora_model)\n",
        "\n",
        "    return result_entry"
      ],
      "metadata": {
        "id": "fFLJ0VF2pRP3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_lora = []"
      ],
      "metadata": {
        "id": "A8NIZe_NpRhl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 1: LoRA with Rank 4\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_r4 = run_lora_experiment(\n",
        "    size_fraction=0.8,  # 80% of training data\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    lora_rank=4\n",
        ")\n",
        "result_lora.append(result_r4)"
      ],
      "metadata": {
        "id": "RAdCCXunpczt",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af0a1a20-1bcd-43fe-b15a-4c60ef039569"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 1: LoRA with Rank 4\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 LoRA Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n",
            "\n",
            "🔧 Creating LoRA model (rank=4)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2477820024.py:35: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 00:09:16] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:09:16] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:09:16] [setup] CPU Tracking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 75,266 || all params: 66,439,684 || trainable%: 0.1133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:09:17] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:09:17] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:09:17] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:09:17] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:09:17] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:09:17] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:09:17] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:09:17] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:09:17]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:09:17]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:09:17]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:09:17]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:09:17]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:09:17]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:09:17]   GPU count: 1\n",
            "[codecarbon INFO @ 00:09:17]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:09:18] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r4_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 00:09:18] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:09:18] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:09:18] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:09:19] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:09:19] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:09:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:09:19] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:09:19] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:09:19] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:09:19] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:09:19] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:09:19]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:09:19]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:09:19]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:09:19]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:09:19]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:09:19]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:09:19]   GPU count: 1\n",
            "[codecarbon INFO @ 00:09:19]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon WARNING @ 00:09:19] Unable to access geographical location through primary API. Will resort to using the backup API - Exception : HTTPSConnectionPool(host='get.geojs.io', port=443): Read timed out. (read timeout=0.5) - url=https://get.geojs.io/v1/ip/geo.json\n",
            "[codecarbon WARNING @ 00:09:20] Unable to access geographical location. Using 'Canada' as the default value - Exception : 'country' - url=https://get.geojs.io/v1/ip/geo.json\n",
            "[codecarbon INFO @ 00:09:20] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r4_80pct/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ Training LoRA model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:22, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.729400</td>\n",
              "      <td>1.488260</td>\n",
              "      <td>0.409016</td>\n",
              "      <td>0.464123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.566200</td>\n",
              "      <td>1.418027</td>\n",
              "      <td>0.429866</td>\n",
              "      <td>0.493001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:09:35] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:09:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:09:35] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:09:35] Energy consumed for all GPUs : 0.000807 kWh. Total GPU Power : 193.50014278005946 W\n",
            "[codecarbon INFO @ 00:09:35] 0.001142 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:09:35] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:09:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:09:35] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:09:35] Energy consumed for all GPUs : 0.000827 kWh. Total GPU Power : 198.34912140633375 W\n",
            "[codecarbon INFO @ 00:09:35] 0.001162 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:09:50] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:09:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:09:50] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:09:50] Energy consumed for all GPUs : 0.001650 kWh. Total GPU Power : 202.42115023041242 W\n",
            "[codecarbon INFO @ 00:09:50] 0.002321 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:09:50] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:09:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:09:50] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:09:50] Energy consumed for all GPUs : 0.001664 kWh. Total GPU Power : 201.014000146173 W\n",
            "[codecarbon INFO @ 00:09:50] 0.002335 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:05] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:05] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:10:05] Energy consumed for all GPUs : 0.002491 kWh. Total GPU Power : 201.94305465147835 W\n",
            "[codecarbon INFO @ 00:10:05] 0.003497 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:05] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:05] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:10:05] Energy consumed for all GPUs : 0.002512 kWh. Total GPU Power : 203.39516699822093 W\n",
            "[codecarbon INFO @ 00:10:05] 0.003518 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:20] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:20] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:10:20] Energy consumed for all GPUs : 0.003336 kWh. Total GPU Power : 202.80728992282397 W\n",
            "[codecarbon INFO @ 00:10:20] 0.004677 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:20] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:20] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:10:20] Energy consumed for all GPUs : 0.003357 kWh. Total GPU Power : 202.8513027435355 W\n",
            "[codecarbon INFO @ 00:10:20] 0.004698 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:35] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:35] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:10:35] Energy consumed for all GPUs : 0.004188 kWh. Total GPU Power : 204.50526831511678 W\n",
            "[codecarbon INFO @ 00:10:35] 0.005865 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:35] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:35] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:10:35] Energy consumed for all GPUs : 0.004203 kWh. Total GPU Power : 203.08562359812035 W\n",
            "[codecarbon INFO @ 00:10:35] 0.005879 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:50] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:50] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:10:50] Energy consumed for all GPUs : 0.005031 kWh. Total GPU Power : 202.33405219705833 W\n",
            "[codecarbon INFO @ 00:10:50] 0.007043 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:10:50] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:10:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:10:50] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:10:50] Energy consumed for all GPUs : 0.005051 kWh. Total GPU Power : 203.61572777443786 W\n",
            "[codecarbon INFO @ 00:10:50] 0.007063 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:05] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:05] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:11:05] Energy consumed for all GPUs : 0.005882 kWh. Total GPU Power : 204.33813806181843 W\n",
            "[codecarbon INFO @ 00:11:05] 0.008229 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:05] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:05] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:11:05] Energy consumed for all GPUs : 0.005903 kWh. Total GPU Power : 204.49655095825335 W\n",
            "[codecarbon INFO @ 00:11:05] 0.008250 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:20] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:20] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:11:20] Energy consumed for all GPUs : 0.006734 kWh. Total GPU Power : 204.4099532513343 W\n",
            "[codecarbon INFO @ 00:11:20] 0.009416 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:20] 0.000309 g.CO2eq/s mean an estimation of 9.74155336924287 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:11:20] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:20] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:11:20] Energy consumed for all GPUs : 0.006752 kWh. Total GPU Power : 204.0045471124044 W\n",
            "[codecarbon INFO @ 00:11:20] 0.009435 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:20] 0.037008 g.CO2eq/s mean an estimation of 1,167.0973988096905 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:11:35] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:35] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:11:35] Energy consumed for all GPUs : 0.007592 kWh. Total GPU Power : 206.14034111729728 W\n",
            "[codecarbon INFO @ 00:11:35] 0.010610 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:35] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:35] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:11:35] Energy consumed for all GPUs : 0.007613 kWh. Total GPU Power : 206.4683511805657 W\n",
            "[codecarbon INFO @ 00:11:35] 0.010630 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:50] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:50] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 00:11:50] Energy consumed for all GPUs : 0.008444 kWh. Total GPU Power : 204.44845732913782 W\n",
            "[codecarbon INFO @ 00:11:50] 0.011797 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:11:50] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:11:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:11:50] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 00:11:50] Energy consumed for all GPUs : 0.008465 kWh. Total GPU Power : 204.4387393528557 W\n",
            "[codecarbon INFO @ 00:11:50] 0.011818 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:05] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:05] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 00:12:05] Energy consumed for all GPUs : 0.009301 kWh. Total GPU Power : 205.66973343341107 W\n",
            "[codecarbon INFO @ 00:12:05] 0.012989 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:05] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:05] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 00:12:05] Energy consumed for all GPUs : 0.009321 kWh. Total GPU Power : 205.65674448959174 W\n",
            "[codecarbon INFO @ 00:12:05] 0.013010 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:20] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:20] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 00:12:20] Energy consumed for all GPUs : 0.010158 kWh. Total GPU Power : 205.8797674354841 W\n",
            "[codecarbon INFO @ 00:12:20] 0.014182 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:20] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:20] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 00:12:20] Energy consumed for all GPUs : 0.010179 kWh. Total GPU Power : 205.8532548005399 W\n",
            "[codecarbon INFO @ 00:12:20] 0.014202 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:35] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:35] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 00:12:35] Energy consumed for all GPUs : 0.011012 kWh. Total GPU Power : 204.90099826825434 W\n",
            "[codecarbon INFO @ 00:12:35] 0.015370 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:35] Energy consumed for RAM : 0.002058 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:35] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 00:12:35] Energy consumed for all GPUs : 0.011032 kWh. Total GPU Power : 204.7650957980764 W\n",
            "[codecarbon INFO @ 00:12:35] 0.015391 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:50] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:50] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 00:12:50] Energy consumed for all GPUs : 0.011856 kWh. Total GPU Power : 202.77151779373247 W\n",
            "[codecarbon INFO @ 00:12:50] 0.016550 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:12:50] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:12:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:50] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 00:12:50] Energy consumed for all GPUs : 0.011877 kWh. Total GPU Power : 202.92565901999242 W\n",
            "[codecarbon INFO @ 00:12:50] 0.016571 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:05] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:05] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 00:13:05] Energy consumed for all GPUs : 0.012711 kWh. Total GPU Power : 205.22759791597258 W\n",
            "[codecarbon INFO @ 00:13:05] 0.017740 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:05] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:05] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 00:13:05] Energy consumed for all GPUs : 0.012732 kWh. Total GPU Power : 205.12109759997819 W\n",
            "[codecarbon INFO @ 00:13:05] 0.017761 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:20] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:20] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:13:20] Energy consumed for all GPUs : 0.013529 kWh. Total GPU Power : 196.22895762850843 W\n",
            "[codecarbon INFO @ 00:13:20] 0.018893 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:20] 0.000311 g.CO2eq/s mean an estimation of 9.806273111097358 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:13:20] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:20] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:13:20] Energy consumed for all GPUs : 0.013543 kWh. Total GPU Power : 194.80259447774512 W\n",
            "[codecarbon INFO @ 00:13:20] 0.018908 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:20] 0.037160 g.CO2eq/s mean an estimation of 1,171.8827593319893 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:13:35] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:35] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 00:13:35] Energy consumed for all GPUs : 0.014234 kWh. Total GPU Power : 169.42968740957394 W\n",
            "[codecarbon INFO @ 00:13:35] 0.019934 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:35] Energy consumed for RAM : 0.002691 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:35] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 00:13:35] Energy consumed for all GPUs : 0.014255 kWh. Total GPU Power : 170.7744196808405 W\n",
            "[codecarbon INFO @ 00:13:35] 0.019955 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:50] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:50] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 00:13:50] Energy consumed for all GPUs : 0.015077 kWh. Total GPU Power : 202.17596050952574 W\n",
            "[codecarbon INFO @ 00:13:50] 0.021112 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:13:50] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:13:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:50] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 00:13:50] Energy consumed for all GPUs : 0.015096 kWh. Total GPU Power : 202.06257809671865 W\n",
            "[codecarbon INFO @ 00:13:50] 0.021131 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:05] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:05] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 00:14:05] Energy consumed for all GPUs : 0.015912 kWh. Total GPU Power : 200.44177195708932 W\n",
            "[codecarbon INFO @ 00:14:05] 0.022282 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:05] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:05] Energy consumed for All CPU : 0.003364 kWh\n",
            "[codecarbon INFO @ 00:14:05] Energy consumed for all GPUs : 0.015932 kWh. Total GPU Power : 200.5729941740471 W\n",
            "[codecarbon INFO @ 00:14:05] 0.022303 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:20] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:20] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 00:14:20] Energy consumed for all GPUs : 0.016750 kWh. Total GPU Power : 201.1651474925915 W\n",
            "[codecarbon INFO @ 00:14:20] 0.023455 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:20] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:20] Energy consumed for All CPU : 0.003541 kWh\n",
            "[codecarbon INFO @ 00:14:20] Energy consumed for all GPUs : 0.016770 kWh. Total GPU Power : 201.25667327553262 W\n",
            "[codecarbon INFO @ 00:14:20] 0.023476 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:35] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:35] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 00:14:35] Energy consumed for all GPUs : 0.017590 kWh. Total GPU Power : 201.67650170261945 W\n",
            "[codecarbon INFO @ 00:14:35] 0.024631 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:35] Energy consumed for RAM : 0.003324 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:35] Energy consumed for All CPU : 0.003718 kWh\n",
            "[codecarbon INFO @ 00:14:35] Energy consumed for all GPUs : 0.017610 kWh. Total GPU Power : 201.5225631164941 W\n",
            "[codecarbon INFO @ 00:14:35] 0.024651 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:50] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:50] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 00:14:50] Energy consumed for all GPUs : 0.018427 kWh. Total GPU Power : 200.95063559914112 W\n",
            "[codecarbon INFO @ 00:14:50] 0.025803 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:14:50] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:14:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:50] Energy consumed for All CPU : 0.003895 kWh\n",
            "[codecarbon INFO @ 00:14:50] Energy consumed for all GPUs : 0.018447 kWh. Total GPU Power : 201.08224938586605 W\n",
            "[codecarbon INFO @ 00:14:50] 0.025824 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:05] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:05] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 00:15:05] Energy consumed for all GPUs : 0.019265 kWh. Total GPU Power : 201.22733156885997 W\n",
            "[codecarbon INFO @ 00:15:05] 0.026977 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:05] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:05] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 00:15:05] Energy consumed for all GPUs : 0.019285 kWh. Total GPU Power : 201.30052666045518 W\n",
            "[codecarbon INFO @ 00:15:05] 0.026997 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:20] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:20] Energy consumed for All CPU : 0.004249 kWh\n",
            "[codecarbon INFO @ 00:15:20] Energy consumed for all GPUs : 0.020103 kWh. Total GPU Power : 200.98350225320334 W\n",
            "[codecarbon INFO @ 00:15:20] 0.028149 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:20] 0.000304 g.CO2eq/s mean an estimation of 9.576935545969404 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:15:20] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:20] Energy consumed for All CPU : 0.004249 kWh\n",
            "[codecarbon INFO @ 00:15:20] Energy consumed for all GPUs : 0.020123 kWh. Total GPU Power : 200.86366406358422 W\n",
            "[codecarbon INFO @ 00:15:20] 0.028169 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:20] 0.036330 g.CO2eq/s mean an estimation of 1,145.7015716887172 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:15:35] Energy consumed for RAM : 0.003957 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:35] Energy consumed for All CPU : 0.004426 kWh\n",
            "[codecarbon INFO @ 00:15:35] Energy consumed for all GPUs : 0.020946 kWh. Total GPU Power : 202.39087831085493 W\n",
            "[codecarbon INFO @ 00:15:35] 0.029328 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:35] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:35] Energy consumed for All CPU : 0.004426 kWh\n",
            "[codecarbon INFO @ 00:15:35] Energy consumed for all GPUs : 0.020966 kWh. Total GPU Power : 202.39640902710934 W\n",
            "[codecarbon INFO @ 00:15:35] 0.029348 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:50] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:50] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 00:15:50] Energy consumed for all GPUs : 0.021784 kWh. Total GPU Power : 201.3190087240628 W\n",
            "[codecarbon INFO @ 00:15:50] 0.030502 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:15:50] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:15:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:50] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 00:15:50] Energy consumed for all GPUs : 0.021804 kWh. Total GPU Power : 201.29031025459912 W\n",
            "[codecarbon INFO @ 00:15:50] 0.030521 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:05] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:05] Energy consumed for All CPU : 0.004780 kWh\n",
            "[codecarbon INFO @ 00:16:05] Energy consumed for all GPUs : 0.022621 kWh. Total GPU Power : 200.80015901823333 W\n",
            "[codecarbon INFO @ 00:16:05] 0.031673 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:05] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:05] Energy consumed for All CPU : 0.004780 kWh\n",
            "[codecarbon INFO @ 00:16:05] Energy consumed for all GPUs : 0.022641 kWh. Total GPU Power : 200.79062497531595 W\n",
            "[codecarbon INFO @ 00:16:05] 0.031694 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for all GPUs : 0.023463 kWh. Total GPU Power : 202.15377749849125 W\n",
            "[codecarbon INFO @ 00:16:20] 0.032851 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for all GPUs : 0.023483 kWh. Total GPU Power : 202.10645644393492 W\n",
            "[codecarbon INFO @ 00:16:20] 0.032871 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:35] Energy consumed for RAM : 0.004590 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:35] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 00:16:35] Energy consumed for all GPUs : 0.024296 kWh. Total GPU Power : 200.12526782590794 W\n",
            "[codecarbon INFO @ 00:16:35] 0.034020 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:35] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:35] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 00:16:35] Energy consumed for all GPUs : 0.024317 kWh. Total GPU Power : 200.22104983418023 W\n",
            "[codecarbon INFO @ 00:16:35] 0.034040 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:50] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:50] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 00:16:50] Energy consumed for all GPUs : 0.025130 kWh. Total GPU Power : 200.00046889607017 W\n",
            "[codecarbon INFO @ 00:16:50] 0.035188 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:16:50] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:16:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:50] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 00:16:50] Energy consumed for all GPUs : 0.025149 kWh. Total GPU Power : 199.8239040053948 W\n",
            "[codecarbon INFO @ 00:16:50] 0.035208 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for all GPUs : 0.025967 kWh. Total GPU Power : 200.91460966539833 W\n",
            "[codecarbon INFO @ 00:17:05] 0.036360 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for all GPUs : 0.025987 kWh. Total GPU Power : 200.96857799643385 W\n",
            "[codecarbon INFO @ 00:17:05] 0.036381 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:20] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:20] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 00:17:20] Energy consumed for all GPUs : 0.026799 kWh. Total GPU Power : 199.7013588629397 W\n",
            "[codecarbon INFO @ 00:17:20] 0.037528 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:20] 0.000308 g.CO2eq/s mean an estimation of 9.703241579701027 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:17:20] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:20] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 00:17:20] Energy consumed for all GPUs : 0.026818 kWh. Total GPU Power : 199.6779777752555 W\n",
            "[codecarbon INFO @ 00:17:20] 0.037548 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:20] 0.036788 g.CO2eq/s mean an estimation of 1,160.1521392520144 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:17:35] Energy consumed for RAM : 0.005223 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:35] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 00:17:35] Energy consumed for all GPUs : 0.027576 kWh. Total GPU Power : 186.47593071478138 W\n",
            "[codecarbon INFO @ 00:17:35] 0.038640 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:35] Energy consumed for RAM : 0.005223 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:35] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 00:17:35] Energy consumed for all GPUs : 0.027591 kWh. Total GPU Power : 185.46568451895402 W\n",
            "[codecarbon INFO @ 00:17:35] 0.038655 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:42] Energy consumed for RAM : 0.005299 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:42] Delta energy consumed for CPU with constant : 0.000086 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:42] Energy consumed for All CPU : 0.005928 kWh\n",
            "[codecarbon INFO @ 00:17:42] Energy consumed for all GPUs : 0.027916 kWh. Total GPU Power : 160.58434410937818 W\n",
            "[codecarbon INFO @ 00:17:42] 0.039144 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:17:42] Energy consumed for RAM : 0.005305 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:17:42] Delta energy consumed for CPU with constant : 0.000092 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:42] Energy consumed for All CPU : 0.005934 kWh\n",
            "[codecarbon INFO @ 00:17:42] Energy consumed for all GPUs : 0.027924 kWh. Total GPU Power : 160.665770280664 W\n",
            "[codecarbon INFO @ 00:17:42] 0.039163 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating LoRA model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 LoRA RESULTS SUMMARY (Rank 4)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: LoRA\n",
            "  LoRA Rank: 4\n",
            "  Trainable Parameters: 75,266 (0.11%)\n",
            "  Total Parameters: 66,439,684\n",
            "  Dataset Size: 80.0%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.4930\n",
            "  Exact Match: 0.4299\n",
            "  Eval Loss: 1.4180\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.039163 kWh\n",
            "  CPU Energy: 0.005934 kWh (15.2%)\n",
            "  GPU Energy: 0.027924 kWh (71.3%)\n",
            "  RAM Energy: 0.005305 kWh (13.5%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 160.67 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 241.17 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.000154 kg\n",
            "  Emissions Rate: 0.000000307 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: Canada (CAN)\n",
            "  Region: quebec\n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "✅ LoRA adapters saved to results_distilbert_lora_r4_80pct/lora_adapters\n",
            "CPU times: user 8min 35s, sys: 2.36 s, total: 8min 37s\n",
            "Wall time: 8min 41s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 2: LoRA with Rank 8\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_r8 = run_lora_experiment(\n",
        "    size_fraction=0.8,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    lora_rank=8\n",
        ")\n",
        "result_lora.append(result_r8)"
      ],
      "metadata": {
        "id": "MYk1vM8kpdCB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c997b44-ed0e-424f-b2e1-9d7038804a9c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 2: LoRA with Rank 8\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 LoRA Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n",
            "\n",
            "🔧 Creating LoRA model (rank=8)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2477820024.py:35: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 00:17:58] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:17:58] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:17:58] [setup] CPU Tracking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 148,994 || all params: 66,513,412 || trainable%: 0.2240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:17:59] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:17:59] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:17:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:17:59] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:17:59] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:17:59] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:17:59] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:17:59] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:17:59]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:17:59]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:17:59]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:17:59]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:17:59]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:17:59]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:17:59]   GPU count: 1\n",
            "[codecarbon INFO @ 00:17:59]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:17:59] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r8_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 00:17:59] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:17:59] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:17:59] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:18:00] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:18:00] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:18:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:18:00] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:18:00] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:18:00] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:18:00] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:18:00] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:18:00]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:18:00]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:18:00]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:18:00]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:18:00]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:18:00]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:18:00]   GPU count: 1\n",
            "[codecarbon INFO @ 00:18:00]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:18:00] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r8_80pct/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ Training LoRA model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.642400</td>\n",
              "      <td>1.425772</td>\n",
              "      <td>0.420142</td>\n",
              "      <td>0.481818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.457100</td>\n",
              "      <td>1.372708</td>\n",
              "      <td>0.443547</td>\n",
              "      <td>0.513852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:15] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:18:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:15] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:18:15] Energy consumed for all GPUs : 0.000798 kWh. Total GPU Power : 191.46208970183798 W\n",
            "[codecarbon INFO @ 00:18:15] 0.001134 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:18:16] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:18:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:16] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:18:16] Energy consumed for all GPUs : 0.000811 kWh. Total GPU Power : 194.66031736276844 W\n",
            "[codecarbon INFO @ 00:18:16] 0.001147 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:18:30] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:18:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:30] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:18:30] Energy consumed for all GPUs : 0.001636 kWh. Total GPU Power : 201.04047975038716 W\n",
            "[codecarbon INFO @ 00:18:30] 0.002306 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:18:31] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:18:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:31] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:18:31] Energy consumed for all GPUs : 0.001656 kWh. Total GPU Power : 202.64248716718788 W\n",
            "[codecarbon INFO @ 00:18:31] 0.002326 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:18:45] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:18:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:45] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:18:45] Energy consumed for all GPUs : 0.002475 kWh. Total GPU Power : 201.40411780964934 W\n",
            "[codecarbon INFO @ 00:18:45] 0.003481 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:18:46] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:18:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:46] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:18:46] Energy consumed for all GPUs : 0.002494 kWh. Total GPU Power : 201.35163092571096 W\n",
            "[codecarbon INFO @ 00:18:46] 0.003500 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:00] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:00] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:19:00] Energy consumed for all GPUs : 0.003313 kWh. Total GPU Power : 201.31736239199134 W\n",
            "[codecarbon INFO @ 00:19:00] 0.004654 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:01] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:01] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:19:01] Energy consumed for all GPUs : 0.003333 kWh. Total GPU Power : 201.21663798593283 W\n",
            "[codecarbon INFO @ 00:19:01] 0.004674 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:15] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:15] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:19:15] Energy consumed for all GPUs : 0.004160 kWh. Total GPU Power : 203.157596535041 W\n",
            "[codecarbon INFO @ 00:19:15] 0.005836 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:16] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:16] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:19:16] Energy consumed for all GPUs : 0.004180 kWh. Total GPU Power : 203.47101757127297 W\n",
            "[codecarbon INFO @ 00:19:16] 0.005856 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:30] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:30] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:19:30] Energy consumed for all GPUs : 0.004998 kWh. Total GPU Power : 201.24719833144567 W\n",
            "[codecarbon INFO @ 00:19:30] 0.007010 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:31] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:31] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:19:31] Energy consumed for all GPUs : 0.005018 kWh. Total GPU Power : 201.00869588231652 W\n",
            "[codecarbon INFO @ 00:19:31] 0.007030 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:45] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:45] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:19:45] Energy consumed for all GPUs : 0.005841 kWh. Total GPU Power : 202.35435470472052 W\n",
            "[codecarbon INFO @ 00:19:45] 0.008189 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:19:46] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:19:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:46] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:19:46] Energy consumed for all GPUs : 0.005856 kWh. Total GPU Power : 201.2412299406715 W\n",
            "[codecarbon INFO @ 00:19:46] 0.008203 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:00] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:00] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:20:00] Energy consumed for all GPUs : 0.006681 kWh. Total GPU Power : 201.48512799657559 W\n",
            "[codecarbon INFO @ 00:20:00] 0.009363 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:00] 0.036725 g.CO2eq/s mean an estimation of 1,158.1506398471563 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:20:01] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:01] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:20:01] Energy consumed for all GPUs : 0.006701 kWh. Total GPU Power : 202.825191395087 W\n",
            "[codecarbon INFO @ 00:20:01] 0.009383 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:01] 0.036805 g.CO2eq/s mean an estimation of 1,160.6858516847997 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:20:15] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:15] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:20:15] Energy consumed for all GPUs : 0.007518 kWh. Total GPU Power : 201.06565033392002 W\n",
            "[codecarbon INFO @ 00:20:15] 0.010536 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:16] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:16] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:20:16] Energy consumed for all GPUs : 0.007538 kWh. Total GPU Power : 200.90971763714845 W\n",
            "[codecarbon INFO @ 00:20:16] 0.010555 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:30] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:30] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 00:20:30] Energy consumed for all GPUs : 0.008361 kWh. Total GPU Power : 202.2326067495251 W\n",
            "[codecarbon INFO @ 00:20:30] 0.011714 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:31] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:31] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 00:20:31] Energy consumed for all GPUs : 0.008375 kWh. Total GPU Power : 201.09547724893477 W\n",
            "[codecarbon INFO @ 00:20:31] 0.011728 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:45] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:45] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 00:20:45] Energy consumed for all GPUs : 0.009195 kWh. Total GPU Power : 200.42049527440747 W\n",
            "[codecarbon INFO @ 00:20:45] 0.012883 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:20:46] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:20:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:46] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 00:20:46] Energy consumed for all GPUs : 0.009209 kWh. Total GPU Power : 200.24646050510984 W\n",
            "[codecarbon INFO @ 00:20:46] 0.012898 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:00] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:00] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 00:21:00] Energy consumed for all GPUs : 0.010035 kWh. Total GPU Power : 201.64318442151642 W\n",
            "[codecarbon INFO @ 00:21:00] 0.014059 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:01] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:01] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 00:21:01] Energy consumed for all GPUs : 0.010055 kWh. Total GPU Power : 203.05683336850697 W\n",
            "[codecarbon INFO @ 00:21:01] 0.014079 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:15] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:15] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 00:21:15] Energy consumed for all GPUs : 0.010872 kWh. Total GPU Power : 200.9156414954555 W\n",
            "[codecarbon INFO @ 00:21:15] 0.015231 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:16] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:16] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 00:21:16] Energy consumed for all GPUs : 0.010893 kWh. Total GPU Power : 201.05089288223047 W\n",
            "[codecarbon INFO @ 00:21:16] 0.015251 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:30] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:30] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 00:21:30] Energy consumed for all GPUs : 0.011715 kWh. Total GPU Power : 202.18874109473953 W\n",
            "[codecarbon INFO @ 00:21:30] 0.016409 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:31] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:31] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 00:21:31] Energy consumed for all GPUs : 0.011729 kWh. Total GPU Power : 200.6985763991137 W\n",
            "[codecarbon INFO @ 00:21:31] 0.016423 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:45] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:45] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 00:21:45] Energy consumed for all GPUs : 0.012558 kWh. Total GPU Power : 202.6349696051754 W\n",
            "[codecarbon INFO @ 00:21:45] 0.017587 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:21:46] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:21:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:46] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 00:21:46] Energy consumed for all GPUs : 0.012579 kWh. Total GPU Power : 204.06112403712825 W\n",
            "[codecarbon INFO @ 00:21:46] 0.017608 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:00] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:00] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:22:00] Energy consumed for all GPUs : 0.013367 kWh. Total GPU Power : 193.97006864222584 W\n",
            "[codecarbon INFO @ 00:22:00] 0.018731 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:00] 0.036749 g.CO2eq/s mean an estimation of 1,158.9032851136149 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:22:01] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:01] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:22:01] Energy consumed for all GPUs : 0.013380 kWh. Total GPU Power : 192.2330288837133 W\n",
            "[codecarbon INFO @ 00:22:01] 0.018744 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:01] 0.036724 g.CO2eq/s mean an estimation of 1,158.1357425020747 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:22:15] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:15] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 00:22:15] Energy consumed for all GPUs : 0.014045 kWh. Total GPU Power : 162.87615720745544 W\n",
            "[codecarbon INFO @ 00:22:15] 0.019745 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:16] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:16] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 00:22:16] Energy consumed for all GPUs : 0.014059 kWh. Total GPU Power : 163.1496775922938 W\n",
            "[codecarbon INFO @ 00:22:16] 0.019759 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:30] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:30] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 00:22:30] Energy consumed for all GPUs : 0.014879 kWh. Total GPU Power : 200.09739662257084 W\n",
            "[codecarbon INFO @ 00:22:30] 0.020913 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:31] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:31] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 00:22:31] Energy consumed for all GPUs : 0.014893 kWh. Total GPU Power : 200.17807908764692 W\n",
            "[codecarbon INFO @ 00:22:31] 0.020928 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:45] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:45] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 00:22:45] Energy consumed for all GPUs : 0.015715 kWh. Total GPU Power : 200.74733184878278 W\n",
            "[codecarbon INFO @ 00:22:45] 0.022085 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:22:46] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:22:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:46] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 00:22:46] Energy consumed for all GPUs : 0.015736 kWh. Total GPU Power : 202.2273720437313 W\n",
            "[codecarbon INFO @ 00:22:46] 0.022106 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:00] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:00] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 00:23:00] Energy consumed for all GPUs : 0.016560 kWh. Total GPU Power : 202.78220607873322 W\n",
            "[codecarbon INFO @ 00:23:00] 0.023265 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:01] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:01] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 00:23:01] Energy consumed for all GPUs : 0.016575 kWh. Total GPU Power : 201.35442674020598 W\n",
            "[codecarbon INFO @ 00:23:01] 0.023280 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:15] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:15] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 00:23:15] Energy consumed for all GPUs : 0.017395 kWh. Total GPU Power : 200.49327230535349 W\n",
            "[codecarbon INFO @ 00:23:15] 0.024436 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:16] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:16] Energy consumed for All CPU : 0.003718 kWh\n",
            "[codecarbon INFO @ 00:23:16] Energy consumed for all GPUs : 0.017414 kWh. Total GPU Power : 201.4161221917151 W\n",
            "[codecarbon INFO @ 00:23:16] 0.024455 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:30] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:30] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 00:23:30] Energy consumed for all GPUs : 0.018234 kWh. Total GPU Power : 201.38819644509178 W\n",
            "[codecarbon INFO @ 00:23:30] 0.025610 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:31] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:31] Energy consumed for All CPU : 0.003895 kWh\n",
            "[codecarbon INFO @ 00:23:31] Energy consumed for all GPUs : 0.018253 kWh. Total GPU Power : 201.4902883027089 W\n",
            "[codecarbon INFO @ 00:23:31] 0.025629 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:45] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:45] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 00:23:45] Energy consumed for all GPUs : 0.019077 kWh. Total GPU Power : 202.49743498894605 W\n",
            "[codecarbon INFO @ 00:23:45] 0.026789 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:23:46] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:23:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:46] Energy consumed for All CPU : 0.004072 kWh\n",
            "[codecarbon INFO @ 00:23:46] Energy consumed for all GPUs : 0.019092 kWh. Total GPU Power : 201.13352446838795 W\n",
            "[codecarbon INFO @ 00:23:46] 0.026803 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:00] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:00] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 00:24:00] Energy consumed for all GPUs : 0.019914 kWh. Total GPU Power : 200.91425100824938 W\n",
            "[codecarbon INFO @ 00:24:00] 0.027961 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:00] 0.036208 g.CO2eq/s mean an estimation of 1,141.8631414304323 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:24:01] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:01] Energy consumed for All CPU : 0.004249 kWh\n",
            "[codecarbon INFO @ 00:24:01] Energy consumed for all GPUs : 0.019934 kWh. Total GPU Power : 202.36403922464362 W\n",
            "[codecarbon INFO @ 00:24:01] 0.027981 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:01] 0.036233 g.CO2eq/s mean an estimation of 1,142.653091464983 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:24:15] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:15] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 00:24:15] Energy consumed for all GPUs : 0.020749 kWh. Total GPU Power : 200.33040025602844 W\n",
            "[codecarbon INFO @ 00:24:15] 0.029131 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:16] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:16] Energy consumed for All CPU : 0.004426 kWh\n",
            "[codecarbon INFO @ 00:24:16] Energy consumed for all GPUs : 0.020769 kWh. Total GPU Power : 200.5295041564012 W\n",
            "[codecarbon INFO @ 00:24:16] 0.029151 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:30] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:30] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 00:24:30] Energy consumed for all GPUs : 0.021592 kWh. Total GPU Power : 202.29628758554875 W\n",
            "[codecarbon INFO @ 00:24:30] 0.030309 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:31] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:31] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 00:24:31] Energy consumed for all GPUs : 0.021606 kWh. Total GPU Power : 200.7974501334667 W\n",
            "[codecarbon INFO @ 00:24:31] 0.030323 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:45] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:45] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 00:24:45] Energy consumed for all GPUs : 0.022426 kWh. Total GPU Power : 200.3228597577819 W\n",
            "[codecarbon INFO @ 00:24:45] 0.031479 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:24:46] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:24:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:46] Energy consumed for All CPU : 0.004780 kWh\n",
            "[codecarbon INFO @ 00:24:46] Energy consumed for all GPUs : 0.022446 kWh. Total GPU Power : 201.60803411056423 W\n",
            "[codecarbon INFO @ 00:24:46] 0.031498 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:00] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:00] Energy consumed for All CPU : 0.004956 kWh\n",
            "[codecarbon INFO @ 00:25:00] Energy consumed for all GPUs : 0.023261 kWh. Total GPU Power : 200.37703876517685 W\n",
            "[codecarbon INFO @ 00:25:00] 0.032649 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:01] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:01] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 00:25:01] Energy consumed for all GPUs : 0.023281 kWh. Total GPU Power : 200.5194821782199 W\n",
            "[codecarbon INFO @ 00:25:01] 0.032669 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:15] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:15] Energy consumed for All CPU : 0.005133 kWh\n",
            "[codecarbon INFO @ 00:25:15] Energy consumed for all GPUs : 0.024100 kWh. Total GPU Power : 201.54663392813097 W\n",
            "[codecarbon INFO @ 00:25:15] 0.033823 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:16] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:16] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 00:25:16] Energy consumed for all GPUs : 0.024120 kWh. Total GPU Power : 201.46698688735907 W\n",
            "[codecarbon INFO @ 00:25:16] 0.033843 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:30] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:30] Energy consumed for All CPU : 0.005310 kWh\n",
            "[codecarbon INFO @ 00:25:30] Energy consumed for all GPUs : 0.024945 kWh. Total GPU Power : 202.77986865777 W\n",
            "[codecarbon INFO @ 00:25:30] 0.035003 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:31] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:31] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:31] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 00:25:31] Energy consumed for all GPUs : 0.024960 kWh. Total GPU Power : 201.50966442977239 W\n",
            "[codecarbon INFO @ 00:25:31] 0.035018 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:45] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:45] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 00:25:45] Energy consumed for all GPUs : 0.025779 kWh. Total GPU Power : 200.28996436352153 W\n",
            "[codecarbon INFO @ 00:25:45] 0.036173 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:25:46] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:25:46] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:46] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 00:25:46] Energy consumed for all GPUs : 0.025799 kWh. Total GPU Power : 201.547183605413 W\n",
            "[codecarbon INFO @ 00:25:46] 0.036193 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:26:00] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:00] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 00:26:00] Energy consumed for all GPUs : 0.026615 kWh. Total GPU Power : 200.69747032659006 W\n",
            "[codecarbon INFO @ 00:26:00] 0.037344 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:26:00] 0.036810 g.CO2eq/s mean an estimation of 1,160.8354756066365 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:26:01] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:01] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:01] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 00:26:01] Energy consumed for all GPUs : 0.026635 kWh. Total GPU Power : 200.70840497301478 W\n",
            "[codecarbon INFO @ 00:26:01] 0.037364 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:26:01] 0.036811 g.CO2eq/s mean an estimation of 1,160.8817777941167 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:26:15] Energy consumed for RAM : 0.005222 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:15] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 00:26:15] Energy consumed for all GPUs : 0.027409 kWh. Total GPU Power : 190.53595977969218 W\n",
            "[codecarbon INFO @ 00:26:15] 0.038474 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:26:16] Energy consumed for RAM : 0.005222 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:16] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:16] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 00:26:16] Energy consumed for all GPUs : 0.027420 kWh. Total GPU Power : 188.390970103983 W\n",
            "[codecarbon INFO @ 00:26:16] 0.038484 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:26:22] Energy consumed for RAM : 0.005289 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:22] Delta energy consumed for CPU with constant : 0.000074 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:22] Energy consumed for All CPU : 0.005916 kWh\n",
            "[codecarbon INFO @ 00:26:22] Energy consumed for all GPUs : 0.027691 kWh. Total GPU Power : 155.24773242195596 W\n",
            "[codecarbon INFO @ 00:26:22] 0.038896 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:26:22] Energy consumed for RAM : 0.005294 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:22] Delta energy consumed for CPU with constant : 0.000080 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:22] Energy consumed for All CPU : 0.005921 kWh\n",
            "[codecarbon INFO @ 00:26:22] Energy consumed for all GPUs : 0.027699 kWh. Total GPU Power : 154.19096901623988 W\n",
            "[codecarbon INFO @ 00:26:22] 0.038914 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating LoRA model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 LoRA RESULTS SUMMARY (Rank 8)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: LoRA\n",
            "  LoRA Rank: 8\n",
            "  Trainable Parameters: 148,994 (0.22%)\n",
            "  Total Parameters: 66,513,412\n",
            "  Dataset Size: 80.0%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.5139\n",
            "  Exact Match: 0.4435\n",
            "  Eval Loss: 1.3727\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.038914 kWh\n",
            "  CPU Energy: 0.005921 kWh (15.2%)\n",
            "  GPU Energy: 0.027699 kWh (71.2%)\n",
            "  RAM Energy: 0.005294 kWh (13.6%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 154.19 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 234.69 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.018320 kg\n",
            "  Emissions Rate: 0.000036507 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: Singapore (SGP)\n",
            "  Region: \n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "✅ LoRA adapters saved to results_distilbert_lora_r8_80pct/lora_adapters\n",
            "CPU times: user 8min 34s, sys: 2.33 s, total: 8min 36s\n",
            "Wall time: 8min 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 3: LoRA with Rank 16\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_r16 = run_lora_experiment(\n",
        "    size_fraction=0.8,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    lora_rank=16\n",
        ")\n",
        "result_lora.append(result_r16)"
      ],
      "metadata": {
        "id": "LMG3E0GHpdPV",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ff9edcc-9d48-42d0-f862-d0884827d179"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 3: LoRA with Rank 16\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 LoRA Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n",
            "\n",
            "🔧 Creating LoRA model (rank=16)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2477820024.py:35: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 00:26:37] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:26:37] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:26:37] [setup] CPU Tracking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 296,450 || all params: 66,660,868 || trainable%: 0.4447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:26:38] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:26:38] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:26:38] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:26:38] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:26:38] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:26:38] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:26:38] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:26:38] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:26:38]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:26:38]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:26:38]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:26:38]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:26:38]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:26:38]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:26:38]   GPU count: 1\n",
            "[codecarbon INFO @ 00:26:38]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:26:39] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r16_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 00:26:39] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:26:39] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:26:39] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:26:40] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:26:40] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:26:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:26:40] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:26:40] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:26:40] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:26:40] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:26:40] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:26:40]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:26:40]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:26:40]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:26:40]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:26:40]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:26:40]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:26:40]   GPU count: 1\n",
            "[codecarbon INFO @ 00:26:40]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:26:40] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r16_80pct/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ Training LoRA model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:23, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.561300</td>\n",
              "      <td>1.358693</td>\n",
              "      <td>0.455744</td>\n",
              "      <td>0.520520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.373700</td>\n",
              "      <td>1.307133</td>\n",
              "      <td>0.474122</td>\n",
              "      <td>0.544429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:55] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:55] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:26:55] Energy consumed for all GPUs : 0.000807 kWh. Total GPU Power : 193.65026793701367 W\n",
            "[codecarbon INFO @ 00:26:55] 0.001143 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:26:56] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:26:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:56] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:26:56] Energy consumed for all GPUs : 0.000830 kWh. Total GPU Power : 198.91683448305255 W\n",
            "[codecarbon INFO @ 00:26:56] 0.001165 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:10] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:10] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:27:10] Energy consumed for all GPUs : 0.001643 kWh. Total GPU Power : 200.7403999711286 W\n",
            "[codecarbon INFO @ 00:27:10] 0.002314 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:11] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:11] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:27:11] Energy consumed for all GPUs : 0.001665 kWh. Total GPU Power : 200.5679228430607 W\n",
            "[codecarbon INFO @ 00:27:11] 0.002336 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:25] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:25] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:27:25] Energy consumed for all GPUs : 0.002486 kWh. Total GPU Power : 202.37088959917205 W\n",
            "[codecarbon INFO @ 00:27:25] 0.003492 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:26] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:26] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:27:26] Energy consumed for all GPUs : 0.002508 kWh. Total GPU Power : 202.3337798186598 W\n",
            "[codecarbon INFO @ 00:27:26] 0.003515 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:40] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:40] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:27:40] Energy consumed for all GPUs : 0.003323 kWh. Total GPU Power : 200.89072420280039 W\n",
            "[codecarbon INFO @ 00:27:40] 0.004665 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:41] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:41] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:27:41] Energy consumed for all GPUs : 0.003345 kWh. Total GPU Power : 200.82728066830998 W\n",
            "[codecarbon INFO @ 00:27:41] 0.004686 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:55] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:55] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:27:55] Energy consumed for all GPUs : 0.004160 kWh. Total GPU Power : 200.9488458312299 W\n",
            "[codecarbon INFO @ 00:27:55] 0.005837 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:27:56] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:27:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:56] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:27:56] Energy consumed for all GPUs : 0.004182 kWh. Total GPU Power : 201.0056139822363 W\n",
            "[codecarbon INFO @ 00:27:56] 0.005859 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:10] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:10] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:28:10] Energy consumed for all GPUs : 0.005004 kWh. Total GPU Power : 202.65856691183305 W\n",
            "[codecarbon INFO @ 00:28:10] 0.007016 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:11] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:11] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:28:11] Energy consumed for all GPUs : 0.005020 kWh. Total GPU Power : 201.22550712349482 W\n",
            "[codecarbon INFO @ 00:28:11] 0.007032 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:25] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:25] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:28:25] Energy consumed for all GPUs : 0.005842 kWh. Total GPU Power : 200.98933885545796 W\n",
            "[codecarbon INFO @ 00:28:25] 0.008189 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:26] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:26] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:28:26] Energy consumed for all GPUs : 0.005863 kWh. Total GPU Power : 202.39140677710213 W\n",
            "[codecarbon INFO @ 00:28:26] 0.008211 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:40] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:40] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:28:40] Energy consumed for all GPUs : 0.006682 kWh. Total GPU Power : 201.5796679528484 W\n",
            "[codecarbon INFO @ 00:28:40] 0.009364 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:40] 0.036732 g.CO2eq/s mean an estimation of 1,158.3692192200913 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:28:41] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:41] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:28:41] Energy consumed for all GPUs : 0.006703 kWh. Total GPU Power : 201.54980754330717 W\n",
            "[codecarbon INFO @ 00:28:41] 0.009386 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:41] 0.036813 g.CO2eq/s mean an estimation of 1,160.943355851141 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:28:55] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:55] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:28:55] Energy consumed for all GPUs : 0.007529 kWh. Total GPU Power : 203.42106503195856 W\n",
            "[codecarbon INFO @ 00:28:55] 0.010547 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:28:56] Energy consumed for RAM : 0.001425 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:28:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:56] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 00:28:56] Energy consumed for all GPUs : 0.007545 kWh. Total GPU Power : 202.07259839042786 W\n",
            "[codecarbon INFO @ 00:28:56] 0.010563 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:10] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:10] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 00:29:10] Energy consumed for all GPUs : 0.008369 kWh. Total GPU Power : 201.60952889635527 W\n",
            "[codecarbon INFO @ 00:29:10] 0.011723 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:11] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:11] Energy consumed for All CPU : 0.001771 kWh\n",
            "[codecarbon INFO @ 00:29:11] Energy consumed for all GPUs : 0.008391 kWh. Total GPU Power : 202.8598192140241 W\n",
            "[codecarbon INFO @ 00:29:11] 0.011744 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:25] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:25] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 00:29:25] Energy consumed for all GPUs : 0.009196 kWh. Total GPU Power : 198.3752664691649 W\n",
            "[codecarbon INFO @ 00:29:25] 0.012884 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:26] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:26] Energy consumed for All CPU : 0.001948 kWh\n",
            "[codecarbon INFO @ 00:29:26] Energy consumed for all GPUs : 0.009217 kWh. Total GPU Power : 198.41795130137066 W\n",
            "[codecarbon INFO @ 00:29:26] 0.012906 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:40] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:40] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 00:29:40] Energy consumed for all GPUs : 0.010031 kWh. Total GPU Power : 200.49841990849072 W\n",
            "[codecarbon INFO @ 00:29:40] 0.014054 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:41] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:41] Energy consumed for All CPU : 0.002125 kWh\n",
            "[codecarbon INFO @ 00:29:41] Energy consumed for all GPUs : 0.010047 kWh. Total GPU Power : 199.21771501054323 W\n",
            "[codecarbon INFO @ 00:29:41] 0.014071 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:55] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:55] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 00:29:55] Energy consumed for all GPUs : 0.010867 kWh. Total GPU Power : 200.7782128470249 W\n",
            "[codecarbon INFO @ 00:29:55] 0.015225 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:29:56] Energy consumed for RAM : 0.002058 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:29:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:56] Energy consumed for All CPU : 0.002302 kWh\n",
            "[codecarbon INFO @ 00:29:56] Energy consumed for all GPUs : 0.010888 kWh. Total GPU Power : 201.95306022182643 W\n",
            "[codecarbon INFO @ 00:29:56] 0.015248 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:10] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:10] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 00:30:10] Energy consumed for all GPUs : 0.011697 kWh. Total GPU Power : 199.35307449099795 W\n",
            "[codecarbon INFO @ 00:30:10] 0.016391 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:11] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:11] Energy consumed for All CPU : 0.002479 kWh\n",
            "[codecarbon INFO @ 00:30:11] Energy consumed for all GPUs : 0.011719 kWh. Total GPU Power : 199.30793324977674 W\n",
            "[codecarbon INFO @ 00:30:11] 0.016413 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:25] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:25] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 00:30:25] Energy consumed for all GPUs : 0.012528 kWh. Total GPU Power : 199.48399742323042 W\n",
            "[codecarbon INFO @ 00:30:25] 0.017557 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:26] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:26] Energy consumed for All CPU : 0.002656 kWh\n",
            "[codecarbon INFO @ 00:30:26] Energy consumed for all GPUs : 0.012549 kWh. Total GPU Power : 199.47602759472372 W\n",
            "[codecarbon INFO @ 00:30:26] 0.017579 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:40] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:40] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:30:40] Energy consumed for all GPUs : 0.013347 kWh. Total GPU Power : 196.42650133877612 W\n",
            "[codecarbon INFO @ 00:30:40] 0.018711 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:40] 0.036667 g.CO2eq/s mean an estimation of 1,156.3261139813383 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:30:41] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:41] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 00:30:41] Energy consumed for all GPUs : 0.013362 kWh. Total GPU Power : 195.25402191072305 W\n",
            "[codecarbon INFO @ 00:30:41] 0.018727 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:41] 0.036643 g.CO2eq/s mean an estimation of 1,155.585314940515 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:30:55] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:55] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 00:30:55] Energy consumed for all GPUs : 0.014027 kWh. Total GPU Power : 163.269952586689 W\n",
            "[codecarbon INFO @ 00:30:55] 0.019726 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:30:56] Energy consumed for RAM : 0.002691 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:30:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:56] Energy consumed for All CPU : 0.003010 kWh\n",
            "[codecarbon INFO @ 00:30:56] Energy consumed for all GPUs : 0.014048 kWh. Total GPU Power : 164.59817722461156 W\n",
            "[codecarbon INFO @ 00:30:56] 0.019749 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:10] Energy consumed for RAM : 0.002848 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:10] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 00:31:10] Energy consumed for all GPUs : 0.014861 kWh. Total GPU Power : 200.37814686333186 W\n",
            "[codecarbon INFO @ 00:31:10] 0.020896 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:11] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:11] Energy consumed for All CPU : 0.003187 kWh\n",
            "[codecarbon INFO @ 00:31:11] Energy consumed for all GPUs : 0.014883 kWh. Total GPU Power : 200.42878144200898 W\n",
            "[codecarbon INFO @ 00:31:11] 0.020919 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:25] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:25] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 00:31:25] Energy consumed for all GPUs : 0.015702 kWh. Total GPU Power : 201.79126600425013 W\n",
            "[codecarbon INFO @ 00:31:25] 0.022072 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:26] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:26] Energy consumed for All CPU : 0.003364 kWh\n",
            "[codecarbon INFO @ 00:31:26] Energy consumed for all GPUs : 0.015724 kWh. Total GPU Power : 201.73194856024077 W\n",
            "[codecarbon INFO @ 00:31:26] 0.022094 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:40] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:40] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 00:31:40] Energy consumed for all GPUs : 0.016533 kWh. Total GPU Power : 199.56707968395008 W\n",
            "[codecarbon INFO @ 00:31:40] 0.023239 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:41] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:41] Energy consumed for All CPU : 0.003541 kWh\n",
            "[codecarbon INFO @ 00:31:41] Energy consumed for all GPUs : 0.016555 kWh. Total GPU Power : 199.52528687434793 W\n",
            "[codecarbon INFO @ 00:31:41] 0.023260 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:55] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:55] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 00:31:55] Energy consumed for all GPUs : 0.017364 kWh. Total GPU Power : 199.4075235520926 W\n",
            "[codecarbon INFO @ 00:31:55] 0.024405 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:31:56] Energy consumed for RAM : 0.003324 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:31:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:56] Energy consumed for All CPU : 0.003718 kWh\n",
            "[codecarbon INFO @ 00:31:56] Energy consumed for all GPUs : 0.017385 kWh. Total GPU Power : 199.34112092127134 W\n",
            "[codecarbon INFO @ 00:31:56] 0.024427 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:10] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:10] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 00:32:10] Energy consumed for all GPUs : 0.018207 kWh. Total GPU Power : 202.28821658388503 W\n",
            "[codecarbon INFO @ 00:32:10] 0.025583 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:11] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:11] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 00:32:11] Energy consumed for all GPUs : 0.018223 kWh. Total GPU Power : 201.2466026320673 W\n",
            "[codecarbon INFO @ 00:32:11] 0.025599 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:25] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:25] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 00:32:25] Energy consumed for all GPUs : 0.019044 kWh. Total GPU Power : 200.8339592172442 W\n",
            "[codecarbon INFO @ 00:32:25] 0.026755 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:26] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:26] Energy consumed for All CPU : 0.004072 kWh\n",
            "[codecarbon INFO @ 00:32:26] Energy consumed for all GPUs : 0.019065 kWh. Total GPU Power : 202.0463445970593 W\n",
            "[codecarbon INFO @ 00:32:26] 0.026776 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:40] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:40] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 00:32:40] Energy consumed for all GPUs : 0.019877 kWh. Total GPU Power : 200.06077749083582 W\n",
            "[codecarbon INFO @ 00:32:40] 0.027923 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:40] 0.036141 g.CO2eq/s mean an estimation of 1,139.7352320935306 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:32:41] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:41] Energy consumed for All CPU : 0.004249 kWh\n",
            "[codecarbon INFO @ 00:32:41] Energy consumed for all GPUs : 0.019898 kWh. Total GPU Power : 200.09709059719287 W\n",
            "[codecarbon INFO @ 00:32:41] 0.027945 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:41] 0.036158 g.CO2eq/s mean an estimation of 1,140.267102545937 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:32:55] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:55] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 00:32:55] Energy consumed for all GPUs : 0.020711 kWh. Total GPU Power : 200.32611879066485 W\n",
            "[codecarbon INFO @ 00:32:55] 0.029093 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:32:56] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:32:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:56] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 00:32:56] Energy consumed for all GPUs : 0.020733 kWh. Total GPU Power : 200.4652282783523 W\n",
            "[codecarbon INFO @ 00:32:56] 0.029115 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:10] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:10] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 00:33:10] Energy consumed for all GPUs : 0.021547 kWh. Total GPU Power : 200.7502202917913 W\n",
            "[codecarbon INFO @ 00:33:10] 0.030264 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:11] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:11] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 00:33:11] Energy consumed for all GPUs : 0.021569 kWh. Total GPU Power : 200.52104234338748 W\n",
            "[codecarbon INFO @ 00:33:11] 0.030286 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:25] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:25] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 00:33:25] Energy consumed for all GPUs : 0.022382 kWh. Total GPU Power : 200.45310922791802 W\n",
            "[codecarbon INFO @ 00:33:25] 0.031434 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:26] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:26] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 00:33:26] Energy consumed for all GPUs : 0.022404 kWh. Total GPU Power : 200.44546371345015 W\n",
            "[codecarbon INFO @ 00:33:26] 0.031456 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:40] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:40] Energy consumed for All CPU : 0.004956 kWh\n",
            "[codecarbon INFO @ 00:33:40] Energy consumed for all GPUs : 0.023216 kWh. Total GPU Power : 200.1826356968077 W\n",
            "[codecarbon INFO @ 00:33:40] 0.032604 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:41] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:41] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 00:33:41] Energy consumed for all GPUs : 0.023238 kWh. Total GPU Power : 200.31406936441886 W\n",
            "[codecarbon INFO @ 00:33:41] 0.032626 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:55] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:55] Energy consumed for All CPU : 0.005133 kWh\n",
            "[codecarbon INFO @ 00:33:55] Energy consumed for all GPUs : 0.024051 kWh. Total GPU Power : 200.4892893848703 W\n",
            "[codecarbon INFO @ 00:33:55] 0.033774 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:33:56] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:33:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:56] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 00:33:56] Energy consumed for all GPUs : 0.024073 kWh. Total GPU Power : 200.4211117459817 W\n",
            "[codecarbon INFO @ 00:33:56] 0.033796 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:10] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:10] Energy consumed for All CPU : 0.005310 kWh\n",
            "[codecarbon INFO @ 00:34:10] Energy consumed for all GPUs : 0.024884 kWh. Total GPU Power : 199.99315844419505 W\n",
            "[codecarbon INFO @ 00:34:10] 0.034942 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:11] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:11] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 00:34:11] Energy consumed for all GPUs : 0.024906 kWh. Total GPU Power : 199.89569355644755 W\n",
            "[codecarbon INFO @ 00:34:11] 0.034964 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:25] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:25] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 00:34:25] Energy consumed for all GPUs : 0.025715 kWh. Total GPU Power : 199.34707168177033 W\n",
            "[codecarbon INFO @ 00:34:25] 0.036108 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:26] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:26] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 00:34:26] Energy consumed for all GPUs : 0.025736 kWh. Total GPU Power : 199.2995636626992 W\n",
            "[codecarbon INFO @ 00:34:26] 0.036129 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:40] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:40] Energy consumed for All CPU : 0.005664 kWh\n",
            "[codecarbon INFO @ 00:34:40] Energy consumed for all GPUs : 0.026552 kWh. Total GPU Power : 200.94296764032725 W\n",
            "[codecarbon INFO @ 00:34:40] 0.037280 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:40] 0.036705 g.CO2eq/s mean an estimation of 1,157.5259314027387 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:34:41] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:41] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 00:34:41] Energy consumed for all GPUs : 0.026573 kWh. Total GPU Power : 200.94768187304365 W\n",
            "[codecarbon INFO @ 00:34:41] 0.037302 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:41] 0.036707 g.CO2eq/s mean an estimation of 1,157.6024959003926 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:34:55] Energy consumed for RAM : 0.005222 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:55] Energy consumed for All CPU : 0.005841 kWh\n",
            "[codecarbon INFO @ 00:34:55] Energy consumed for all GPUs : 0.027325 kWh. Total GPU Power : 185.56492577317528 W\n",
            "[codecarbon INFO @ 00:34:55] 0.038389 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:34:56] Energy consumed for RAM : 0.005222 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:34:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:56] Energy consumed for All CPU : 0.005842 kWh\n",
            "[codecarbon INFO @ 00:34:56] Energy consumed for all GPUs : 0.027340 kWh. Total GPU Power : 184.12348863057406 W\n",
            "[codecarbon INFO @ 00:34:56] 0.038404 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:35:04] Energy consumed for RAM : 0.005313 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:35:04] Delta energy consumed for CPU with constant : 0.000101 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:04] Energy consumed for All CPU : 0.005943 kWh\n",
            "[codecarbon INFO @ 00:35:04] Energy consumed for all GPUs : 0.027706 kWh. Total GPU Power : 153.8867860664787 W\n",
            "[codecarbon INFO @ 00:35:04] 0.038961 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:35:04] Energy consumed for RAM : 0.005318 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:35:04] Delta energy consumed for CPU with constant : 0.000107 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:04] Energy consumed for All CPU : 0.005949 kWh\n",
            "[codecarbon INFO @ 00:35:04] Energy consumed for all GPUs : 0.027712 kWh. Total GPU Power : 153.5416776827425 W\n",
            "[codecarbon INFO @ 00:35:04] 0.038979 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating LoRA model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 LoRA RESULTS SUMMARY (Rank 16)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: LoRA\n",
            "  LoRA Rank: 16\n",
            "  Trainable Parameters: 296,450 (0.44%)\n",
            "  Total Parameters: 66,660,868\n",
            "  Dataset Size: 80.0%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.5444\n",
            "  Exact Match: 0.4741\n",
            "  Eval Loss: 1.3071\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.038979 kWh\n",
            "  CPU Energy: 0.005949 kWh (15.3%)\n",
            "  GPU Energy: 0.027712 kWh (71.1%)\n",
            "  RAM Energy: 0.005318 kWh (13.6%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 153.54 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 234.04 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.018351 kg\n",
            "  Emissions Rate: 0.000036400 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: Singapore (SGP)\n",
            "  Region: \n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "✅ LoRA adapters saved to results_distilbert_lora_r16_80pct/lora_adapters\n",
            "CPU times: user 8min 36s, sys: 2.35 s, total: 8min 38s\n",
            "Wall time: 8min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTmKr9Tcp7fg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###STEP 6.1: Results and Analysis"
      ],
      "metadata": {
        "id": "WxtPee6kp7Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_lora = pd.DataFrame(result_lora)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 LoRA RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(results_df_lora.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "results_df_lora.to_csv(\"/content/drive/MyDrive/distilbert_lora_results.csv\", index=False)\n",
        "print(\"\\n✅ LoRA results saved!\")"
      ],
      "metadata": {
        "id": "cppqVHWWp66A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8e8510-ace0-4652-d23c-c42b68f06b9b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📊 LoRA RESULTS SUMMARY\n",
            "============================================================\n",
            "training_method model_name  lora_rank  train_samples  valid_samples  trainable_params  total_params  trainable_percentage  f1_score  exact_match  eval_loss  training_time_hours  emissions_rate_kg_per_s  emissions_kg           timestamp  duration_seconds  duration_hours  energy_consumed_kwh  cpu_energy_kwh  gpu_energy_kwh  ram_energy_kwh  cpu_power_w  gpu_power_w  ram_power_w country_name country_iso_code region cloud_provider cloud_region on_cloud                                   os python_version  cpu_count                      cpu_model  gpu_count                 gpu_model  ram_total_size_gb  pue codecarbon_version\n",
            "           LoRA DistilBERT          4         104255          12134             75266      66439684              0.113285  0.493001     0.429866   1.418027             0.139547             3.066414e-07      0.000154 2025-11-27T00:17:43        502.861687        0.139684             0.039163        0.005934        0.027924        0.005305         42.5   160.665770         38.0       Canada              CAN quebec                                    N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.1.1\n",
            "           LoRA DistilBERT          8         104255          12134            148994      66513412              0.224006  0.513852     0.443547   1.372708             0.139261             3.650703e-05      0.018320 2025-11-27T00:26:22        501.828127        0.139397             0.038914        0.005921        0.027699        0.005294         42.5   154.190969         38.0    Singapore              SGP                                           N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.1.1\n",
            "           LoRA DistilBERT         16         104255          12134            296450      66660868              0.444714  0.544429     0.474122   1.307133             0.139900             3.640017e-05      0.018351 2025-11-27T00:35:04        504.134589        0.140037             0.038979        0.005949        0.027712        0.005318         42.5   153.541678         38.0    Singapore              SGP                                           N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.1.1\n",
            "\n",
            "✅ LoRA results saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📊 LoRA RANK COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_lora[['lora_rank', 'trainable_params', 'trainable_percentage', 'f1_score', 'exact_match', 'emissions_kg', 'training_time_hours']].to_string(index=False))"
      ],
      "metadata": {
        "id": "9YhfuQ9pqA9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c51e0f-7e93-434c-da85-fa832839acd8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 LoRA RANK COMPARISON\n",
            "================================================================================\n",
            " lora_rank  trainable_params  trainable_percentage  f1_score  exact_match  emissions_kg  training_time_hours\n",
            "         4             75266              0.113285  0.493001     0.429866      0.000154             0.139547\n",
            "         8            148994              0.224006  0.513852     0.443547      0.018320             0.139261\n",
            "        16            296450              0.444714  0.544429     0.474122      0.018351             0.139900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nq2WGsgCqGSZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare efficiency vs performance\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📈 EFFICIENCY ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "baseline = results_df_lora[results_df_lora['lora_rank'] == 8].iloc[0]  # Use rank 8 as baseline\n",
        "\n",
        "for _, row in results_df_lora.iterrows():\n",
        "    rank = row['lora_rank']\n",
        "    params_ratio = row['trainable_params'] / baseline['trainable_params']\n",
        "    f1_diff = row['f1_score'] - baseline['f1_score']\n",
        "    emissions_diff = row['emissions_kg'] - baseline['emissions_kg']\n",
        "\n",
        "    print(f\"\\nLoRA Rank {rank}:\")\n",
        "    print(f\"  Trainable Params: {row['trainable_params']:,} ({row['trainable_percentage']:.2f}%)\")\n",
        "    print(f\"  vs Rank 8: {params_ratio:.2f}x parameters\")\n",
        "    print(f\"  F1 Score: {row['f1_score']:.4f} ({f1_diff:+.4f} vs Rank 8)\")\n",
        "    print(f\"  Emissions: {row['emissions_kg']:.6f} kg ({emissions_diff:+.6f} vs Rank 8)\")\n",
        "    print(f\"  Training Time: {row['training_time_hours']:.2f} hours\")\n",
        "\n",
        "    # Efficiency metric: F1 per kg CO2\n",
        "    efficiency = row['f1_score'] / row['emissions_kg']\n",
        "    print(f\"  Efficiency (F1/kg CO2): {efficiency:.2f}\")"
      ],
      "metadata": {
        "id": "9IV69YyUqD-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ac7502-4000-4a08-859f-b6d33e09792b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 EFFICIENCY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "LoRA Rank 4:\n",
            "  Trainable Params: 75,266 (0.11%)\n",
            "  vs Rank 8: 0.51x parameters\n",
            "  F1 Score: 0.4930 (-0.0209 vs Rank 8)\n",
            "  Emissions: 0.000154 kg (-0.018166 vs Rank 8)\n",
            "  Training Time: 0.14 hours\n",
            "  Efficiency (F1/kg CO2): 3197.19\n",
            "\n",
            "LoRA Rank 8:\n",
            "  Trainable Params: 148,994 (0.22%)\n",
            "  vs Rank 8: 1.00x parameters\n",
            "  F1 Score: 0.5139 (+0.0000 vs Rank 8)\n",
            "  Emissions: 0.018320 kg (+0.000000 vs Rank 8)\n",
            "  Training Time: 0.14 hours\n",
            "  Efficiency (F1/kg CO2): 28.05\n",
            "\n",
            "LoRA Rank 16:\n",
            "  Trainable Params: 296,450 (0.44%)\n",
            "  vs Rank 8: 1.99x parameters\n",
            "  F1 Score: 0.5444 (+0.0306 vs Rank 8)\n",
            "  Emissions: 0.018351 kg (+0.000030 vs Rank 8)\n",
            "  Training Time: 0.14 hours\n",
            "  Efficiency (F1/kg CO2): 29.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT 1: LoRA Energy Consumption by Rank\n",
        "print(\"\\n📊 Creating LoRA Energy Plot...\")\n",
        "\n",
        "df_sorted_lora = results_df_lora.sort_values('lora_rank')\n",
        "\n",
        "fig_lora_energy = go.Figure()\n",
        "\n",
        "fig_lora_energy.add_trace(go.Bar(\n",
        "    name='CPU Energy',\n",
        "    x=df_sorted_lora['lora_rank'],\n",
        "    y=df_sorted_lora['cpu_energy_kwh'],\n",
        "    marker_color='#FF6B6B',\n",
        "    hovertemplate='<b>CPU Energy</b><br>%{y:.6f} kWh<br>Rank: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_lora_energy.add_trace(go.Bar(\n",
        "    name='GPU Energy',\n",
        "    x=df_sorted_lora['lora_rank'],\n",
        "    y=df_sorted_lora['gpu_energy_kwh'],\n",
        "    marker_color='#4ECDC4',\n",
        "    hovertemplate='<b>GPU Energy</b><br>%{y:.6f} kWh<br>Rank: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_lora_energy.add_trace(go.Bar(\n",
        "    name='RAM Energy',\n",
        "    x=df_sorted_lora['lora_rank'],\n",
        "    y=df_sorted_lora['ram_energy_kwh'],\n",
        "    marker_color='#95E1D3',\n",
        "    hovertemplate='<b>RAM Energy</b><br>%{y:.6f} kWh<br>Rank: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_lora_energy.update_layout(\n",
        "    title=dict(text=\"LoRA: Energy Consumption by Rank\", font=dict(size=18)),\n",
        "    xaxis_title='LoRA Rank',\n",
        "    yaxis_title='Energy Consumption (kWh)',\n",
        "    barmode='stack',\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig_lora_energy.show()\n",
        "fig_lora_energy.write_html(\"/content/drive/MyDrive/lora_energy_by_rank.html\")\n",
        "print(\"✅ LoRA Energy Plot saved: lora_energy_by_rank.html\")"
      ],
      "metadata": {
        "id": "oJj_TKSrXFI-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "e1ee4979-3faf-4258-8af8-aa73e6aa4f0c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Creating LoRA Energy Plot...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3b3a3e51-2edd-4b6b-9f50-18ae45d8768a\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3b3a3e51-2edd-4b6b-9f50-18ae45d8768a\")) {                    Plotly.newPlot(                        \"3b3a3e51-2edd-4b6b-9f50-18ae45d8768a\",                        [{\"hovertemplate\":\"\\u003cb\\u003eCPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CPU Energy\",\"x\":[4,8,16],\"y\":[0.005933829868718061,0.005921414530611813,0.005948634559279851],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eGPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#4ECDC4\"},\"name\":\"GPU Energy\",\"x\":[4,8,16],\"y\":[0.027924101228152004,0.027699179937103996,0.02771215494748397],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eRAM Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#95E1D3\"},\"name\":\"RAM Energy\",\"x\":[4,8,16],\"y\":[0.005304955604848898,0.005293842290053893,0.005318066757114438],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":18},\"text\":\"LoRA: Energy Consumption by Rank\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"LoRA Rank\"}},\"yaxis\":{\"title\":{\"text\":\"Energy Consumption (kWh)\"}},\"barmode\":\"stack\",\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3b3a3e51-2edd-4b6b-9f50-18ae45d8768a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LoRA Energy Plot saved: lora_energy_by_rank.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT 2: LoRA Performance & Emissions by Rank (Dual Y-axis)\n",
        "print(\"\\n📊 Creating LoRA Performance vs Emissions Plot...\")\n",
        "\n",
        "df_sorted_lora = results_df_lora.sort_values('lora_rank')\n",
        "\n",
        "fig_lora_perf = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# F1 Score line\n",
        "fig_lora_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_lora['lora_rank'],\n",
        "        y=df_sorted_lora['f1_score'],\n",
        "        name='F1 Score',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#4ECDC4', width=3),\n",
        "        marker=dict(size=12, line=dict(width=2, color='white')),\n",
        "        hovertemplate='<b>F1 Score</b>: %{y:.4f}<br>Rank: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# Exact Match line\n",
        "fig_lora_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_lora['lora_rank'],\n",
        "        y=df_sorted_lora['exact_match'],\n",
        "        name='Exact Match',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#95E1D3', width=3, dash='dash'),\n",
        "        marker=dict(size=10),\n",
        "        hovertemplate='<b>Exact Match</b>: %{y:.4f}<br>Rank: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# CO2 Emissions bar\n",
        "fig_lora_perf.add_trace(\n",
        "    go.Bar(\n",
        "        x=df_sorted_lora['lora_rank'],\n",
        "        y=df_sorted_lora['emissions_kg'],\n",
        "        name='CO₂ Emissions',\n",
        "        marker_color='#FF6B6B',\n",
        "        opacity=0.6,\n",
        "        hovertemplate='<b>CO₂</b>: %{y:.6f} kg<br>Rank: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=True\n",
        ")\n",
        "\n",
        "fig_lora_perf.update_xaxes(title_text=\"LoRA Rank\")\n",
        "fig_lora_perf.update_yaxes(title_text=\"Performance Score\", secondary_y=False)\n",
        "fig_lora_perf.update_yaxes(title_text=\"CO₂ Emissions (kg)\", secondary_y=True)\n",
        "\n",
        "fig_lora_perf.update_layout(\n",
        "    title=dict(text=\"LoRA: Performance vs Carbon Emissions by Rank\", font=dict(size=18)),\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_lora_perf.show()\n",
        "fig_lora_perf.write_html(\"/content/drive/MyDrive/lora_performance_emissions.html\")\n",
        "print(\"✅ LoRA Performance Plot saved: lora_performance_emissions.html\")"
      ],
      "metadata": {
        "id": "lyGfA29KXE1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "2a2f574c-52ac-4be3-9862-97b60bc8654b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Creating LoRA Performance vs Emissions Plot...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"96459b54-b741-4c06-a56a-e5408704475a\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"96459b54-b741-4c06-a56a-e5408704475a\")) {                    Plotly.newPlot(                        \"96459b54-b741-4c06-a56a-e5408704475a\",                        [{\"hovertemplate\":\"\\u003cb\\u003eF1 Score\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#4ECDC4\",\"width\":3},\"marker\":{\"line\":{\"color\":\"white\",\"width\":2},\"size\":12},\"mode\":\"lines+markers\",\"name\":\"F1 Score\",\"x\":[4,8,16],\"y\":[0.49300094633396396,0.5138520641562151,0.5444293190519564],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eExact Match\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#95E1D3\",\"dash\":\"dash\",\"width\":3},\"marker\":{\"size\":10},\"mode\":\"lines+markers\",\"name\":\"Exact Match\",\"x\":[4,8,16],\"y\":[0.429866490852151,0.4435470578539641,0.47412230097247404],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eCO₂\\u003c\\u002fb\\u003e: %{y:.6f} kg\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CO₂ Emissions\",\"opacity\":0.6,\"x\":[4,8,16],\"y\":[0.0001541981888110753,0.018320255280133087,0.018350582888477397],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"LoRA Rank\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Performance Score\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"CO₂ Emissions (kg)\"}},\"title\":{\"font\":{\"size\":18},\"text\":\"LoRA: Performance vs Carbon Emissions by Rank\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('96459b54-b741-4c06-a56a-e5408704475a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LoRA Performance Plot saved: lora_performance_emissions.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7h3wrMix97lS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Strategy 3: Few-shot Learning With Frozen Backbone\n",
        "\n",
        "## STEP 7: Creating And Training Few-shot Model"
      ],
      "metadata": {
        "id": "s1ESW0WEuWLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_frozen_model(model_name=\"distilbert-base-uncased\"):\n",
        "    #Create model with frozen backbone (only QA head is trainable).\n",
        "    # Load base model\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "    # Freeze ALL parameters first\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze ONLY the QA head (classifier layer)\n",
        "    # For DistilBERT: qa_outputs layer\n",
        "    for param in model.qa_outputs.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Count parameters\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    print(f\"\\n🔒 Model Configuration:\")\n",
        "    print(f\"  Total Parameters: {total_params:,}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"  Frozen Parameters: {total_params - trainable_params:,}\")\n",
        "    print(f\"  Trainable Percentage: {100 * trainable_params / total_params:.4f}%\")\n",
        "\n",
        "    return model, trainable_params, total_params\n"
      ],
      "metadata": {
        "id": "8TtNcPqRuvP5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_fewshot_dataset(train_data, num_shots, preprocess_fn):\n",
        "    # Select only num_shots examples\n",
        "    train_subset = train_data.select(range(num_shots))\n",
        "\n",
        "    print(f\"🔄 Creating few-shot dataset with {num_shots} examples...\")\n",
        "    tokenized_train = train_subset.map(\n",
        "        preprocess_fn,\n",
        "        batched=True,\n",
        "        remove_columns=train_subset.column_names\n",
        "    )\n",
        "\n",
        "    # After tokenization with sliding window, we get more samples\n",
        "    actual_samples = len(tokenized_train)\n",
        "    print(f\"  Original examples: {num_shots}\")\n",
        "    print(f\"  After tokenization (with sliding window): {actual_samples} samples\")\n",
        "\n",
        "    return tokenized_train, num_shots  # Return original num_shots for tracking\n"
      ],
      "metadata": {
        "id": "XYukCtgAuvgQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fewshot_model(tokenized_train, tokenized_eval, tokenizer, compute_metrics_fn, num_shots, model_name=\"distilbert-base-uncased\"):\n",
        "    # Create frozen model\n",
        "    model, trainable_params, total_params = create_frozen_model(model_name)\n",
        "\n",
        "    # Setup output directory\n",
        "    output_dir = f\"results_distilbert_fewshot_{num_shots}shots\"\n",
        "\n",
        "    # Training arguments - DIFFERENT from full fine-tuning\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=5e-4,  # Higher LR since we're only training the head\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=10,  # More epochs for few-shot\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        push_to_hub=False,\n",
        "        logging_steps=50,\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        compute_metrics=compute_metrics_fn\n",
        "    )\n",
        "\n",
        "    # Start carbon tracking\n",
        "    tracker = EmissionsTracker(\n",
        "        project_name=f\"DistilBERT_FewShot_{num_shots}shots\",\n",
        "        output_dir=output_dir,\n",
        "        save_to_file=True,\n",
        "        log_level=\"info\"\n",
        "    )\n",
        "    tracker.start()\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\n🏋️ Training few-shot model ({num_shots} examples)...\")\n",
        "    train_results = trainer.train()\n",
        "\n",
        "    # Stop tracking and get detailed emissions data\n",
        "    emissions_kg = tracker.stop()\n",
        "    emissions_data = tracker.final_emissions_data\n",
        "\n",
        "    return trainer, train_results, emissions_data, output_dir, model, trainable_params, total_params\n"
      ],
      "metadata": {
        "id": "LN-zQJ7HkfkB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDucSX0a3s2Q"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_I0ad6Qc3tHa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 8: Evaluating The Few-shot Model On Different Shot Sizes\n",
        "\n",
        ">We will be training our model on various shots from our SQuAD dataset.\n",
        ">\n",
        ">Training Few-shot Variation: [100, 500, 1000]"
      ],
      "metadata": {
        "id": "ozi7C-1p3IMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_save_fewshot(trainer, train_results, emissions_data, output_dir, num_shots, trainable_params, total_params):\n",
        "    print(\"📊 Evaluating few-shot model...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    trainable_percentage = 100 * trainable_params / total_params\n",
        "\n",
        "    # Compile results\n",
        "    result_entry = {\n",
        "        \"training_method\": \"Few-Shot (Frozen Backbone)\",\n",
        "        \"model_name\": \"DistilBERT\",\n",
        "        \"num_shots\": num_shots,\n",
        "        \"train_samples\": num_shots,\n",
        "        \"valid_samples\": len(tokenized_validation),\n",
        "        \"trainable_params\": trainable_params,\n",
        "        \"total_params\": total_params,\n",
        "        \"trainable_percentage\": trainable_percentage,\n",
        "        # Performance\n",
        "        \"f1_score\": eval_results[\"eval_f1\"],\n",
        "        \"exact_match\": eval_results[\"eval_exact_match\"],\n",
        "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
        "        \"training_time_hours\": train_results.metrics[\"train_runtime\"] / 3600,\n",
        "        # Emissions\n",
        "        \"timestamp\": emissions_data.timestamp,\n",
        "        \"duration_seconds\": emissions_data.duration,\n",
        "        \"duration_hours\": emissions_data.duration / 3600,\n",
        "        \"emissions_kg\": emissions_data.emissions,\n",
        "        \"emissions_rate_kg_per_s\": emissions_data.emissions_rate,\n",
        "        # Energy\n",
        "        \"energy_consumed_kwh\": emissions_data.energy_consumed,\n",
        "        \"cpu_energy_kwh\": emissions_data.cpu_energy,\n",
        "        \"gpu_energy_kwh\": emissions_data.gpu_energy,\n",
        "        \"ram_energy_kwh\": emissions_data.ram_energy,\n",
        "        # Power\n",
        "        \"cpu_power_w\": emissions_data.cpu_power,\n",
        "        \"gpu_power_w\": emissions_data.gpu_power,\n",
        "        \"ram_power_w\": emissions_data.ram_power,\n",
        "        # Location\n",
        "        \"country_name\": emissions_data.country_name,\n",
        "        \"region\": emissions_data.region,\n",
        "        \"on_cloud\": emissions_data.on_cloud,\n",
        "        # System\n",
        "        \"cpu_model\": emissions_data.cpu_model,\n",
        "        \"cpu_count\": emissions_data.cpu_count,\n",
        "        \"gpu_model\": emissions_data.gpu_model,\n",
        "        \"gpu_count\": emissions_data.gpu_count,\n",
        "        \"ram_total_size_gb\": emissions_data.ram_total_size,\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"📈 FEW-SHOT LEARNING RESULTS ({num_shots} examples)\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"\\n🔧 Model Configuration:\")\n",
        "    print(f\"  Training Method: Few-Shot (Frozen Backbone)\")\n",
        "    print(f\"  Training Examples: {num_shots}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,} ({trainable_percentage:.4f}%)\")\n",
        "    print(f\"  Frozen Parameters: {total_params - trainable_params:,}\")\n",
        "\n",
        "    print(f\"\\n🎯 Performance:\")\n",
        "    print(f\"  F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"  Exact Match: {eval_results['eval_exact_match']:.4f}\")\n",
        "    print(f\"  Eval Loss: {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\n⚡ Energy:\")\n",
        "    print(f\"  Total: {emissions_data.energy_consumed:.6f} kWh\")\n",
        "    if emissions_data.energy_consumed > 0:\n",
        "        print(f\"  GPU: {emissions_data.gpu_energy:.6f} kWh ({emissions_data.gpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "        print(f\"  CPU: {emissions_data.cpu_energy:.6f} kWh ({emissions_data.cpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n🌱 Carbon:\")\n",
        "    print(f\"  CO₂ Emissions: {emissions_data.emissions:.6f} kg\")\n",
        "    print(f\"  Training Time: {train_results.metrics['train_runtime']/3600:.2f} hours\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Save model\n",
        "    trainer.save_model(f\"{output_dir}/final_model\")\n",
        "    print(f\"✅ Model saved to {output_dir}/final_model\")\n",
        "\n",
        "    # Clean up\n",
        "    del trainer.model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result_entry\n"
      ],
      "metadata": {
        "id": "gfC-Xe2l0j32"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fewshot_experiment(num_shots, train_data, eval_data, tokenizer, preprocess_fn, compute_metrics_fn, model_name=\"distilbert-base-uncased\"):\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🚀 Few-Shot Learning with {num_shots} examples\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Step 1: Prepare few-shot dataset\n",
        "    tokenized_train, num_shots = prepare_fewshot_dataset(train_data, num_shots, preprocess_fn)\n",
        "\n",
        "    # Step 2: Train with frozen backbone\n",
        "    trainer, train_results, emissions_data, output_dir, model, trainable_params, total_params = train_fewshot_model(\n",
        "        tokenized_train, eval_data, tokenizer, compute_metrics_fn,\n",
        "        num_shots, model_name\n",
        "    )\n",
        "\n",
        "    # Step 3: Evaluate and save\n",
        "    result_entry = evaluate_and_save_fewshot(\n",
        "        trainer, train_results, emissions_data, output_dir,\n",
        "        num_shots, trainable_params, total_params\n",
        "    )\n",
        "\n",
        "    return result_entry"
      ],
      "metadata": {
        "id": "KK7HslIr0kXH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_fewshot = []"
      ],
      "metadata": {
        "id": "JclbGt1g0kqH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 1: 100-shot Learning\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_100 = run_fewshot_experiment(\n",
        "    num_shots=100,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    model_name=\"distilbert-base-uncased\"\n",
        ")\n",
        "result_fewshot.append(result_100)"
      ],
      "metadata": {
        "id": "dE4Wnm061AL2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "88efe91a8c594cc0a8173aebd6f4a202",
            "e0668a656e8a4860926d9c765f562d5f",
            "fc10f017a65340a9be1781cc795d5154",
            "a34565b551624e6aaf8d3e1fdbaf44d1",
            "c61bc2d1a1cb4e458e7a166716fa0de7",
            "7a9ba6c0664249639d5658f5e4ea0063",
            "8c9d08bf2e984cafaa95df9e9c35f881",
            "3f45d8d2ad354547b4e0e943fb5b9ba8",
            "fce0237ba36446e29a881da3fb500fd4",
            "22a333fd6164483f90abedd81f798705",
            "279acfa7af22480fa46ba059e8ec34da"
          ]
        },
        "collapsed": true,
        "outputId": "f038e4ec-59a0-46e2-f921-96754c4dc6f8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 1: 100-shot Learning\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Few-Shot Learning with 100 examples\n",
            "============================================================\n",
            "🔄 Creating few-shot dataset with 100 examples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88efe91a8c594cc0a8173aebd6f4a202"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original examples: 100\n",
            "  After tokenization (with sliding window): 100 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1092708844.py:26: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 00:35:23] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:35:23] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:23] [setup] CPU Tracking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔒 Model Configuration:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 1,538\n",
            "  Frozen Parameters: 66,362,880\n",
            "  Trainable Percentage: 0.0023%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:35:24] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:35:24] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:35:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:35:24] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:35:24] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:24] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:24] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:35:24] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:35:24]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:35:24]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:35:24]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:35:24]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:35:24]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:35:24]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:35:24]   GPU count: 1\n",
            "[codecarbon INFO @ 00:35:24]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:35:25] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_100shots/emissions.csv\n",
            "[codecarbon WARNING @ 00:35:25] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:35:25] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:25] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:35:26] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:35:26] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:35:26] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:35:26] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:35:26] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:26] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:26] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:35:26] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:35:26]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:35:26]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:35:26]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:35:26]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:35:26]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:35:26]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:35:26]   GPU count: 1\n",
            "[codecarbon INFO @ 00:35:26]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:35:26] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_100shots/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏋️ Training few-shot model (100 examples)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 02:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.960748</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.006065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.925188</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.006769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.897899</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.006562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.877831</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.007620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.861616</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.007852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.847296</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>0.008439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.837134</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>0.008846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.605100</td>\n",
              "      <td>5.830018</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.009092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>5.605100</td>\n",
              "      <td>5.825410</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.009039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5.605100</td>\n",
              "      <td>5.823724</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.009082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:41] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:35:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:41] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:35:41] Energy consumed for all GPUs : 0.000742 kWh. Total GPU Power : 177.94508667622543 W\n",
            "[codecarbon INFO @ 00:35:41] 0.001077 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:35:42] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:35:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:42] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:35:42] Energy consumed for all GPUs : 0.000755 kWh. Total GPU Power : 181.03022404536688 W\n",
            "[codecarbon INFO @ 00:35:42] 0.001090 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:35:56] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:35:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:56] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:35:56] Energy consumed for all GPUs : 0.001514 kWh. Total GPU Power : 185.34209798538194 W\n",
            "[codecarbon INFO @ 00:35:56] 0.002185 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:35:57] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:35:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:57] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:35:57] Energy consumed for all GPUs : 0.001532 kWh. Total GPU Power : 186.5261043882488 W\n",
            "[codecarbon INFO @ 00:35:57] 0.002203 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:11] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:11] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:36:11] Energy consumed for all GPUs : 0.002263 kWh. Total GPU Power : 179.762482479748 W\n",
            "[codecarbon INFO @ 00:36:11] 0.003269 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:12] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:12] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:36:12] Energy consumed for all GPUs : 0.002280 kWh. Total GPU Power : 179.51269087757933 W\n",
            "[codecarbon INFO @ 00:36:12] 0.003286 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:26] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:26] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:36:26] Energy consumed for all GPUs : 0.003016 kWh. Total GPU Power : 180.89343152518575 W\n",
            "[codecarbon INFO @ 00:36:26] 0.004358 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:27] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:27] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:36:27] Energy consumed for all GPUs : 0.003035 kWh. Total GPU Power : 181.28391135989693 W\n",
            "[codecarbon INFO @ 00:36:27] 0.004376 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:41] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:41] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:36:41] Energy consumed for all GPUs : 0.003788 kWh. Total GPU Power : 185.30444406551948 W\n",
            "[codecarbon INFO @ 00:36:41] 0.005465 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:42] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:42] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:36:42] Energy consumed for all GPUs : 0.003807 kWh. Total GPU Power : 185.26129328563164 W\n",
            "[codecarbon INFO @ 00:36:42] 0.005484 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:56] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:56] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:36:56] Energy consumed for all GPUs : 0.004568 kWh. Total GPU Power : 187.0517300307854 W\n",
            "[codecarbon INFO @ 00:36:56] 0.006580 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:36:57] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:36:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:57] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:36:57] Energy consumed for all GPUs : 0.004584 kWh. Total GPU Power : 186.4850933775225 W\n",
            "[codecarbon INFO @ 00:36:57] 0.006596 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:37:11] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:37:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:11] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:37:11] Energy consumed for all GPUs : 0.005341 kWh. Total GPU Power : 185.6485234601595 W\n",
            "[codecarbon INFO @ 00:37:11] 0.007689 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:37:12] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:37:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:12] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:37:12] Energy consumed for all GPUs : 0.005360 kWh. Total GPU Power : 186.44210596034065 W\n",
            "[codecarbon INFO @ 00:37:12] 0.007708 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:37:26] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:37:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:26] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:37:26] Energy consumed for all GPUs : 0.006127 kWh. Total GPU Power : 188.53600979092732 W\n",
            "[codecarbon INFO @ 00:37:26] 0.008809 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:37:26] 0.034553 g.CO2eq/s mean an estimation of 1,089.6563530973033 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:37:27] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:37:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:27] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:37:27] Energy consumed for all GPUs : 0.006146 kWh. Total GPU Power : 188.50948973793305 W\n",
            "[codecarbon INFO @ 00:37:27] 0.008828 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:37:27] 0.034627 g.CO2eq/s mean an estimation of 1,091.9827778711076 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:37:28] Energy consumed for RAM : 0.001285 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:37:28] Delta energy consumed for CPU with constant : 0.000021 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:28] Energy consumed for All CPU : 0.001437 kWh\n",
            "[codecarbon INFO @ 00:37:28] Energy consumed for all GPUs : 0.006223 kWh. Total GPU Power : 158.5706406795515 W\n",
            "[codecarbon INFO @ 00:37:28] 0.008945 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:37:29] Energy consumed for RAM : 0.001290 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:37:29] Delta energy consumed for CPU with constant : 0.000027 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:29] Energy consumed for All CPU : 0.001443 kWh\n",
            "[codecarbon INFO @ 00:37:29] Energy consumed for all GPUs : 0.006231 kWh. Total GPU Power : 165.85497549418022 W\n",
            "[codecarbon INFO @ 00:37:29] 0.008964 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating few-shot model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT LEARNING RESULTS (100 examples)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: Few-Shot (Frozen Backbone)\n",
            "  Training Examples: 100\n",
            "  Trainable Parameters: 1,538 (0.0023%)\n",
            "  Frozen Parameters: 66,362,880\n",
            "\n",
            "🎯 Performance:\n",
            "  F1 Score: 0.0091\n",
            "  Exact Match: 0.0004\n",
            "  Eval Loss: 5.8300\n",
            "\n",
            "⚡ Energy:\n",
            "  Total: 0.008964 kWh\n",
            "  GPU: 0.006231 kWh (69.5%)\n",
            "  CPU: 0.001443 kWh (16.1%)\n",
            "\n",
            "🌱 Carbon:\n",
            "  CO₂ Emissions: 0.004220 kg\n",
            "  Training Time: 0.03 hours\n",
            "================================================================================\n",
            "✅ Model saved to results_distilbert_fewshot_100shots/final_model\n",
            "CPU times: user 2min 12s, sys: 2.81 s, total: 2min 15s\n",
            "Wall time: 2min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 2: 500-shot Learning\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_500 = run_fewshot_experiment(\n",
        "    num_shots=500,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    model_name=\"distilbert-base-uncased\"\n",
        ")\n",
        "result_fewshot.append(result_500)"
      ],
      "metadata": {
        "id": "7eBIzG071Aar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "306751b1f3564337a559fa3423af6302",
            "9ae32d6ba1aa454ca872584ab7cf6afa",
            "c734baa8c0d04df8acb6c794145b26c3",
            "cb385708c83a4e2ebfe9a993bff20575",
            "82bd9230e2b3445e8e52eadbd29663b9",
            "6693e8ee01fe465ab3ff85e79c6b2ec6",
            "6bc7e6fce43b4b618269e0b4a0abf9a4",
            "879d5389db9e43d5bbf4b73d1d05e494",
            "af38c074ff174a4dac67f1540065d35d",
            "0ea67afec5324f3a9e0268be7d2b7f95",
            "6cd133246f6547e39d3f3fb5d65bccf0"
          ]
        },
        "collapsed": true,
        "outputId": "ccd479e9-d25a-4b40-ac03-7d3d5dd45658"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 2: 500-shot Learning\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Few-Shot Learning with 500 examples\n",
            "============================================================\n",
            "🔄 Creating few-shot dataset with 500 examples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "306751b1f3564337a559fa3423af6302"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original examples: 500\n",
            "  After tokenization (with sliding window): 527 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1092708844.py:26: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 00:37:41] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:37:41] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:37:41] [setup] CPU Tracking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔒 Model Configuration:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 1,538\n",
            "  Frozen Parameters: 66,362,880\n",
            "  Trainable Percentage: 0.0023%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:37:43] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:37:43] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:37:43] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:37:43] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:37:43] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:37:43] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:37:43] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:37:43] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:37:43]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:37:43]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:37:43]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:37:43]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:37:43]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:37:43]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:37:43]   GPU count: 1\n",
            "[codecarbon INFO @ 00:37:43]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:37:43] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_500shots/emissions.csv\n",
            "[codecarbon WARNING @ 00:37:43] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:37:43] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:37:43] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:37:44] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:37:44] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:37:44] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:37:44] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:37:44] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:37:44] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:37:44] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:37:44] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:37:44]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:37:44]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:37:44]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:37:44]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:37:44]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:37:44]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:37:44]   GPU count: 1\n",
            "[codecarbon INFO @ 00:37:44]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:37:44] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_500shots/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏋️ Training few-shot model (500 examples)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [330/330 02:07, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.600938</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.012893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.614300</td>\n",
              "      <td>5.365770</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.013981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.614300</td>\n",
              "      <td>5.196386</td>\n",
              "      <td>0.000989</td>\n",
              "      <td>0.014842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.119000</td>\n",
              "      <td>5.050659</td>\n",
              "      <td>0.001731</td>\n",
              "      <td>0.015044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.839400</td>\n",
              "      <td>4.921439</td>\n",
              "      <td>0.002225</td>\n",
              "      <td>0.015549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.839400</td>\n",
              "      <td>4.848420</td>\n",
              "      <td>0.002720</td>\n",
              "      <td>0.015826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.660800</td>\n",
              "      <td>4.767348</td>\n",
              "      <td>0.005357</td>\n",
              "      <td>0.017459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.575200</td>\n",
              "      <td>4.723065</td>\n",
              "      <td>0.006840</td>\n",
              "      <td>0.018732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.575200</td>\n",
              "      <td>4.696511</td>\n",
              "      <td>0.007747</td>\n",
              "      <td>0.019596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.522800</td>\n",
              "      <td>4.687153</td>\n",
              "      <td>0.008241</td>\n",
              "      <td>0.019856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:59] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:37:59] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:59] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:37:59] Energy consumed for all GPUs : 0.000725 kWh. Total GPU Power : 173.83584727331458 W\n",
            "[codecarbon INFO @ 00:37:59] 0.001060 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:00] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:00] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:38:00] Energy consumed for all GPUs : 0.000743 kWh. Total GPU Power : 178.31685945278082 W\n",
            "[codecarbon INFO @ 00:38:00] 0.001079 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:14] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:14] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:14] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:38:14] Energy consumed for all GPUs : 0.001486 kWh. Total GPU Power : 182.55899773676873 W\n",
            "[codecarbon INFO @ 00:38:14] 0.002157 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:15] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:15] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:38:15] Energy consumed for all GPUs : 0.001506 kWh. Total GPU Power : 182.9450572606938 W\n",
            "[codecarbon INFO @ 00:38:15] 0.002176 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:29] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:29] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:29] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:38:29] Energy consumed for all GPUs : 0.002257 kWh. Total GPU Power : 185.17939024072027 W\n",
            "[codecarbon INFO @ 00:38:29] 0.003263 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:30] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:30] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:38:30] Energy consumed for all GPUs : 0.002271 kWh. Total GPU Power : 183.89993423132407 W\n",
            "[codecarbon INFO @ 00:38:30] 0.003278 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:44] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:44] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:44] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:38:44] Energy consumed for all GPUs : 0.003032 kWh. Total GPU Power : 186.02613679019802 W\n",
            "[codecarbon INFO @ 00:38:44] 0.004374 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:45] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:45] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:38:45] Energy consumed for all GPUs : 0.003052 kWh. Total GPU Power : 187.3386916775134 W\n",
            "[codecarbon INFO @ 00:38:45] 0.004394 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:38:59] Energy consumed for RAM : 0.000792 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:38:59] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:59] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:38:59] Energy consumed for all GPUs : 0.003797 kWh. Total GPU Power : 183.540018637338 W\n",
            "[codecarbon INFO @ 00:38:59] 0.005474 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:00] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:00] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:39:00] Energy consumed for all GPUs : 0.003817 kWh. Total GPU Power : 183.53364649431657 W\n",
            "[codecarbon INFO @ 00:39:00] 0.005494 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:14] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:14] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:14] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:39:14] Energy consumed for all GPUs : 0.004550 kWh. Total GPU Power : 180.76836900476277 W\n",
            "[codecarbon INFO @ 00:39:14] 0.006562 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:15] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:15] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:39:15] Energy consumed for all GPUs : 0.004561 kWh. Total GPU Power : 178.65331682151933 W\n",
            "[codecarbon INFO @ 00:39:15] 0.006573 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:29] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:29] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:29] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:39:29] Energy consumed for all GPUs : 0.005327 kWh. Total GPU Power : 186.54928510951547 W\n",
            "[codecarbon INFO @ 00:39:29] 0.007674 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:30] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:30] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:39:30] Energy consumed for all GPUs : 0.005348 kWh. Total GPU Power : 188.79653329401762 W\n",
            "[codecarbon INFO @ 00:39:30] 0.007695 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:44] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:44] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:44] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:39:44] Energy consumed for all GPUs : 0.006056 kWh. Total GPU Power : 175.0095966851881 W\n",
            "[codecarbon INFO @ 00:39:44] 0.008738 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:44] 0.034273 g.CO2eq/s mean an estimation of 1,080.8291607472788 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:39:45] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:45] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 00:39:45] Energy consumed for all GPUs : 0.006075 kWh. Total GPU Power : 174.69444803908908 W\n",
            "[codecarbon INFO @ 00:39:45] 0.008758 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:45] 0.034351 g.CO2eq/s mean an estimation of 1,083.3020976688756 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:39:53] Energy consumed for RAM : 0.001350 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:53] Delta energy consumed for CPU with constant : 0.000094 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:53] Energy consumed for All CPU : 0.001511 kWh\n",
            "[codecarbon INFO @ 00:39:53] Energy consumed for all GPUs : 0.006479 kWh. Total GPU Power : 182.15680722195148 W\n",
            "[codecarbon INFO @ 00:39:53] 0.009340 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:39:53] Energy consumed for RAM : 0.001356 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:39:53] Delta energy consumed for CPU with constant : 0.000100 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:53] Energy consumed for All CPU : 0.001516 kWh\n",
            "[codecarbon INFO @ 00:39:53] Energy consumed for all GPUs : 0.006485 kWh. Total GPU Power : 182.79363997382066 W\n",
            "[codecarbon INFO @ 00:39:53] 0.009357 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating few-shot model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT LEARNING RESULTS (500 examples)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: Few-Shot (Frozen Backbone)\n",
            "  Training Examples: 500\n",
            "  Trainable Parameters: 1,538 (0.0023%)\n",
            "  Frozen Parameters: 66,362,880\n",
            "\n",
            "🎯 Performance:\n",
            "  F1 Score: 0.0199\n",
            "  Exact Match: 0.0082\n",
            "  Eval Loss: 4.6872\n",
            "\n",
            "⚡ Energy:\n",
            "  Total: 0.009357 kWh\n",
            "  GPU: 0.006485 kWh (69.3%)\n",
            "  CPU: 0.001516 kWh (16.2%)\n",
            "\n",
            "🌱 Carbon:\n",
            "  CO₂ Emissions: 0.004405 kg\n",
            "  Training Time: 0.04 hours\n",
            "================================================================================\n",
            "✅ Model saved to results_distilbert_fewshot_500shots/final_model\n",
            "CPU times: user 2min 18s, sys: 3.16 s, total: 2min 21s\n",
            "Wall time: 2min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 3: 1000-shot Learning\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_1000 = run_fewshot_experiment(\n",
        "    num_shots=1000,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    model_name=\"distilbert-base-uncased\"\n",
        ")\n",
        "result_fewshot.append(result_1000)"
      ],
      "metadata": {
        "id": "xPgMm5Dp1AqU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1b726cb6d1f34b5285f21dd974154298",
            "75edfa5727ff439b917b0ad2fc91b75d",
            "8c790be895714c0aa177f6ae91ce43cd",
            "5b08f052392a4043a43237d0232d2e3b",
            "25cda5285e744aeca861305098c1d2f0",
            "3c05a83b2f91424b9839052ae62d24d7",
            "4d3e38536f024fbfbe22371ed3ba92b5",
            "2881985c9e8147fb9801ae9c8aef88a2",
            "753c5592207d44d287a242b0060cabbc",
            "be65b24ccb6f4ec8a96b4697cb88678c",
            "90e7b245816646938e904df131ef74ac"
          ]
        },
        "collapsed": true,
        "outputId": "5a05b912-d1a3-47db-d10c-ca1ab33cce58"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 3: 1000-shot Learning\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Few-Shot Learning with 1000 examples\n",
            "============================================================\n",
            "🔄 Creating few-shot dataset with 1000 examples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b726cb6d1f34b5285f21dd974154298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original examples: 1000\n",
            "  After tokenization (with sliding window): 1027 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1092708844.py:26: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 00:40:06] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:40:06] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:06] [setup] CPU Tracking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔒 Model Configuration:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 1,538\n",
            "  Frozen Parameters: 66,362,880\n",
            "  Trainable Percentage: 0.0023%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:40:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:40:07] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:40:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:40:07] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:40:07] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:07] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:07] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:40:07] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:07]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:07]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:40:07]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:40:07]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:40:07]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:40:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:40:07]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:07]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:40:07] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_1000shots/emissions.csv\n",
            "[codecarbon WARNING @ 00:40:07] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 00:40:07] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:07] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:40:08] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 00:40:08] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 00:40:08] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 00:40:08] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 00:40:08] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:08] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:08] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 00:40:08] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:08]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:08]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 00:40:08]   CodeCarbon version: 3.1.1\n",
            "[codecarbon INFO @ 00:40:08]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 00:40:08]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 00:40:08]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 00:40:08]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:08]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 00:40:09] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_1000shots/emissions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏋️ Training few-shot model (1000 examples)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='650' max='650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [650/650 02:13, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.640500</td>\n",
              "      <td>5.487395</td>\n",
              "      <td>0.001071</td>\n",
              "      <td>0.014791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.122300</td>\n",
              "      <td>5.161344</td>\n",
              "      <td>0.002225</td>\n",
              "      <td>0.016665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.808000</td>\n",
              "      <td>4.953194</td>\n",
              "      <td>0.003626</td>\n",
              "      <td>0.018421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.479300</td>\n",
              "      <td>4.815657</td>\n",
              "      <td>0.004533</td>\n",
              "      <td>0.019417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.401300</td>\n",
              "      <td>4.721910</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.020926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.297600</td>\n",
              "      <td>4.657375</td>\n",
              "      <td>0.005934</td>\n",
              "      <td>0.021714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.226000</td>\n",
              "      <td>4.601258</td>\n",
              "      <td>0.006099</td>\n",
              "      <td>0.021734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.170100</td>\n",
              "      <td>4.566637</td>\n",
              "      <td>0.006346</td>\n",
              "      <td>0.022027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.182700</td>\n",
              "      <td>4.545423</td>\n",
              "      <td>0.006428</td>\n",
              "      <td>0.022245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.120200</td>\n",
              "      <td>4.540926</td>\n",
              "      <td>0.006428</td>\n",
              "      <td>0.022166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:24] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:40:24] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:24] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:40:24] Energy consumed for all GPUs : 0.000725 kWh. Total GPU Power : 173.9445741044764 W\n",
            "[codecarbon INFO @ 00:40:24] 0.001061 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:40:24] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:40:24] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:24] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 00:40:24] Energy consumed for all GPUs : 0.000740 kWh. Total GPU Power : 177.43112896204045 W\n",
            "[codecarbon INFO @ 00:40:24] 0.001075 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:40:39] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:40:39] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:39] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:40:39] Energy consumed for all GPUs : 0.001477 kWh. Total GPU Power : 180.45131557102903 W\n",
            "[codecarbon INFO @ 00:40:39] 0.002148 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:40:39] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:40:39] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:39] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 00:40:39] Energy consumed for all GPUs : 0.001497 kWh. Total GPU Power : 181.62470058279663 W\n",
            "[codecarbon INFO @ 00:40:39] 0.002168 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:40:54] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:40:54] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:54] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:40:54] Energy consumed for all GPUs : 0.002242 kWh. Total GPU Power : 183.51928603080538 W\n",
            "[codecarbon INFO @ 00:40:54] 0.003248 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:40:54] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:40:54] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:54] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 00:40:54] Energy consumed for all GPUs : 0.002256 kWh. Total GPU Power : 182.25258919061073 W\n",
            "[codecarbon INFO @ 00:40:54] 0.003263 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:09] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:09] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:09] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:41:09] Energy consumed for all GPUs : 0.003001 kWh. Total GPU Power : 182.21494210099448 W\n",
            "[codecarbon INFO @ 00:41:09] 0.004342 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:09] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:09] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:09] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 00:41:09] Energy consumed for all GPUs : 0.003021 kWh. Total GPU Power : 183.52054672750353 W\n",
            "[codecarbon INFO @ 00:41:09] 0.004363 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:24] Energy consumed for RAM : 0.000792 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:24] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:24] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:41:24] Energy consumed for all GPUs : 0.003768 kWh. Total GPU Power : 184.14536470040773 W\n",
            "[codecarbon INFO @ 00:41:24] 0.005445 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:24] Energy consumed for RAM : 0.000792 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:24] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:24] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 00:41:24] Energy consumed for all GPUs : 0.003788 kWh. Total GPU Power : 184.13198533312476 W\n",
            "[codecarbon INFO @ 00:41:24] 0.005465 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:39] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:39] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:39] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:41:39] Energy consumed for all GPUs : 0.004522 kWh. Total GPU Power : 180.96053947325785 W\n",
            "[codecarbon INFO @ 00:41:39] 0.006534 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:39] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:39] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:39] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 00:41:39] Energy consumed for all GPUs : 0.004542 kWh. Total GPU Power : 180.88697273011115 W\n",
            "[codecarbon INFO @ 00:41:39] 0.006554 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:54] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:54] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:54] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 00:41:54] Energy consumed for all GPUs : 0.005285 kWh. Total GPU Power : 183.0944537616993 W\n",
            "[codecarbon INFO @ 00:41:54] 0.007632 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:41:54] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:41:54] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:54] Energy consumed for All CPU : 0.001240 kWh\n",
            "[codecarbon INFO @ 00:41:54] Energy consumed for all GPUs : 0.005305 kWh. Total GPU Power : 183.06937586001965 W\n",
            "[codecarbon INFO @ 00:41:54] 0.007652 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:42:09] Energy consumed for RAM : 0.001267 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:42:09] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:09] Energy consumed for All CPU : 0.001417 kWh\n",
            "[codecarbon INFO @ 00:42:09] Energy consumed for all GPUs : 0.006025 kWh. Total GPU Power : 177.24507584852017 W\n",
            "[codecarbon INFO @ 00:42:09] 0.008709 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:42:09] 0.034144 g.CO2eq/s mean an estimation of 1,076.7804133746674 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:42:09] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:42:09] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:09] Energy consumed for All CPU : 0.001417 kWh\n",
            "[codecarbon INFO @ 00:42:09] Energy consumed for all GPUs : 0.006033 kWh. Total GPU Power : 174.9603380342989 W\n",
            "[codecarbon INFO @ 00:42:09] 0.008717 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:42:09] 0.034184 g.CO2eq/s mean an estimation of 1,078.0212378819117 kg.CO2eq/year\n",
            "[codecarbon INFO @ 00:42:22] Energy consumed for RAM : 0.001406 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:42:22] Delta energy consumed for CPU with constant : 0.000156 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:22] Energy consumed for All CPU : 0.001572 kWh\n",
            "[codecarbon INFO @ 00:42:22] Energy consumed for all GPUs : 0.006705 kWh. Total GPU Power : 183.12898518103276 W\n",
            "[codecarbon INFO @ 00:42:22] 0.009683 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 00:42:22] Energy consumed for RAM : 0.001411 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 00:42:22] Delta energy consumed for CPU with constant : 0.000161 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:22] Energy consumed for All CPU : 0.001578 kWh\n",
            "[codecarbon INFO @ 00:42:22] Energy consumed for all GPUs : 0.006711 kWh. Total GPU Power : 180.79407773876747 W\n",
            "[codecarbon INFO @ 00:42:22] 0.009700 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluating few-shot model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT LEARNING RESULTS (1000 examples)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: Few-Shot (Frozen Backbone)\n",
            "  Training Examples: 1000\n",
            "  Trainable Parameters: 1,538 (0.0023%)\n",
            "  Frozen Parameters: 66,362,880\n",
            "\n",
            "🎯 Performance:\n",
            "  F1 Score: 0.0222\n",
            "  Exact Match: 0.0064\n",
            "  Eval Loss: 4.5454\n",
            "\n",
            "⚡ Energy:\n",
            "  Total: 0.009700 kWh\n",
            "  GPU: 0.006711 kWh (69.2%)\n",
            "  CPU: 0.001578 kWh (16.3%)\n",
            "\n",
            "🌱 Carbon:\n",
            "  CO₂ Emissions: 0.004567 kg\n",
            "  Training Time: 0.04 hours\n",
            "================================================================================\n",
            "✅ Model saved to results_distilbert_fewshot_1000shots/final_model\n",
            "CPU times: user 2min 25s, sys: 3 s, total: 2min 28s\n",
            "Wall time: 2min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73LUuhELBxn0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 8.1: Results and Analysis"
      ],
      "metadata": {
        "id": "SvyO3HSu6DJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_fewshot = pd.DataFrame(result_fewshot)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 FEW-SHOT LEARNING RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(results_df_fewshot[['num_shots', 'trainable_percentage', 'f1_score', 'exact_match', 'emissions_kg', 'training_time_hours']].to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "results_df_fewshot.to_csv(\"/content/drive/MyDrive/distilbert_fewshot_results.csv\", index=False)\n",
        "print(\"\\n✅ Few-shot results saved!\")\n"
      ],
      "metadata": {
        "id": "1CbzUJ-w1A4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a806d2ab-1c0f-48de-df87-d6e5f65b46ae"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📊 FEW-SHOT LEARNING RESULTS SUMMARY\n",
            "============================================================\n",
            " num_shots  trainable_percentage  f1_score  exact_match  emissions_kg  training_time_hours\n",
            "       100              0.002318  0.009092     0.000412      0.004220             0.033830\n",
            "       500              0.002318  0.019856     0.008241      0.004405             0.035559\n",
            "      1000              0.002318  0.022245     0.006428      0.004567             0.037006\n",
            "\n",
            "✅ Few-shot results saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FEW-SHOT EFFICIENCY ANALYSIS\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📈 FEW-SHOT EFFICIENCY ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Use 500-shot as baseline (middle ground)\n",
        "baseline = results_df_fewshot[results_df_fewshot['num_shots'] == 500].iloc[0]\n",
        "\n",
        "for _, row in results_df_fewshot.iterrows():\n",
        "    shots = row['num_shots']\n",
        "    samples_ratio = row['num_shots'] / baseline['num_shots']\n",
        "    f1_diff = row['f1_score'] - baseline['f1_score']\n",
        "    emissions_diff = row['emissions_kg'] - baseline['emissions_kg']\n",
        "    time_diff = row['training_time_hours'] - baseline['training_time_hours']\n",
        "\n",
        "    print(f\"\\n{shots}-Shot Learning:\")\n",
        "    print(f\"  Training Examples: {row['num_shots']:,}\")\n",
        "    print(f\"  Trainable Params: {row['trainable_params']:,} ({row['trainable_percentage']:.4f}%)\")\n",
        "    print(f\"  vs 500-shot: {samples_ratio:.2f}x training data\")\n",
        "    print(f\"  F1 Score: {row['f1_score']:.4f} ({f1_diff:+.4f} vs 500-shot)\")\n",
        "    print(f\"  Emissions: {row['emissions_kg']:.6f} kg ({emissions_diff:+.6f} vs 500-shot)\")\n",
        "    print(f\"  Training Time: {row['training_time_hours']:.2f} hours ({time_diff:+.2f} vs 500-shot)\")\n",
        "\n",
        "    # Efficiency metrics\n",
        "    efficiency_co2 = row['f1_score'] / row['emissions_kg'] if row['emissions_kg'] > 0 else 0\n",
        "    efficiency_time = row['f1_score'] / row['training_time_hours'] if row['training_time_hours'] > 0 else 0\n",
        "    efficiency_samples = row['f1_score'] / row['num_shots'] if row['num_shots'] > 0 else 0\n",
        "\n",
        "    print(f\"  Efficiency (F1/kg CO₂): {efficiency_co2:.2f}\")\n",
        "    print(f\"  Efficiency (F1/hour): {efficiency_time:.4f}\")\n",
        "    print(f\"  Efficiency (F1/sample): {efficiency_samples:.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LDevPRqz1U4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126c5868-e16e-4887-debb-2fd61a7fa03d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT EFFICIENCY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "100-Shot Learning:\n",
            "  Training Examples: 100\n",
            "  Trainable Params: 1,538 (0.0023%)\n",
            "  vs 500-shot: 0.20x training data\n",
            "  F1 Score: 0.0091 (-0.0108 vs 500-shot)\n",
            "  Emissions: 0.004220 kg (-0.000185 vs 500-shot)\n",
            "  Training Time: 0.03 hours (-0.00 vs 500-shot)\n",
            "  Efficiency (F1/kg CO₂): 2.15\n",
            "  Efficiency (F1/hour): 0.2688\n",
            "  Efficiency (F1/sample): 0.000091\n",
            "\n",
            "500-Shot Learning:\n",
            "  Training Examples: 500\n",
            "  Trainable Params: 1,538 (0.0023%)\n",
            "  vs 500-shot: 1.00x training data\n",
            "  F1 Score: 0.0199 (+0.0000 vs 500-shot)\n",
            "  Emissions: 0.004405 kg (+0.000000 vs 500-shot)\n",
            "  Training Time: 0.04 hours (+0.00 vs 500-shot)\n",
            "  Efficiency (F1/kg CO₂): 4.51\n",
            "  Efficiency (F1/hour): 0.5584\n",
            "  Efficiency (F1/sample): 0.000040\n",
            "\n",
            "1000-Shot Learning:\n",
            "  Training Examples: 1,000\n",
            "  Trainable Params: 1,538 (0.0023%)\n",
            "  vs 500-shot: 2.00x training data\n",
            "  F1 Score: 0.0222 (+0.0024 vs 500-shot)\n",
            "  Emissions: 0.004567 kg (+0.000161 vs 500-shot)\n",
            "  Training Time: 0.04 hours (+0.00 vs 500-shot)\n",
            "  Efficiency (F1/kg CO₂): 4.87\n",
            "  Efficiency (F1/hour): 0.6011\n",
            "  Efficiency (F1/sample): 0.000022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUoMqBkSBzII"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT 1: Few-Shot Energy Consumption by Shots\n",
        "print(\"\\n📊 Creating Few-Shot Energy Plot...\")\n",
        "\n",
        "df_sorted_fewshot = results_df_fewshot.sort_values('num_shots')\n",
        "\n",
        "fig_fewshot_energy = go.Figure()\n",
        "\n",
        "fig_fewshot_energy.add_trace(go.Bar(\n",
        "    name='CPU Energy',\n",
        "    x=df_sorted_fewshot['num_shots'],\n",
        "    y=df_sorted_fewshot['cpu_energy_kwh'],\n",
        "    marker_color='#FF6B6B',\n",
        "    hovertemplate='<b>CPU Energy</b><br>%{y:.6f} kWh<br>Shots: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fewshot_energy.add_trace(go.Bar(\n",
        "    name='GPU Energy',\n",
        "    x=df_sorted_fewshot['num_shots'],\n",
        "    y=df_sorted_fewshot['gpu_energy_kwh'],\n",
        "    marker_color='#4ECDC4',\n",
        "    hovertemplate='<b>GPU Energy</b><br>%{y:.6f} kWh<br>Shots: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fewshot_energy.add_trace(go.Bar(\n",
        "    name='RAM Energy',\n",
        "    x=df_sorted_fewshot['num_shots'],\n",
        "    y=df_sorted_fewshot['ram_energy_kwh'],\n",
        "    marker_color='#95E1D3',\n",
        "    hovertemplate='<b>RAM Energy</b><br>%{y:.6f} kWh<br>Shots: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fewshot_energy.update_layout(\n",
        "    title=dict(text=\"Few-Shot: Energy Consumption by Number of Examples\", font=dict(size=18)),\n",
        "    xaxis_title='Number of Training Examples',\n",
        "    yaxis_title='Energy Consumption (kWh)',\n",
        "    barmode='stack',\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig_fewshot_energy.show()\n",
        "fig_fewshot_energy.write_html(\"/content/drive/MyDrive/fewshot_energy_by_shots.html\")\n",
        "print(\"✅ Few-Shot Energy Plot saved: fewshot_energy_by_shots.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "txftDBXu_bNs",
        "outputId": "9b365c98-9171-4292-f372-02c82e3d7e47"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Creating Few-Shot Energy Plot...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"8c63e59b-b6df-4e51-9da2-fe632695f257\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8c63e59b-b6df-4e51-9da2-fe632695f257\")) {                    Plotly.newPlot(                        \"8c63e59b-b6df-4e51-9da2-fe632695f257\",                        [{\"hovertemplate\":\"\\u003cb\\u003eCPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CPU Energy\",\"x\":[100,500,1000],\"y\":[0.0014429883281743025,0.0015162368627819327,0.0015781211088743224],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eGPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#4ECDC4\"},\"name\":\"GPU Energy\",\"x\":[100,500,1000],\"y\":[0.0062306566511879935,0.006485484910606021,0.006711131480011984],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eRAM Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#95E1D3\"},\"name\":\"RAM Energy\",\"x\":[100,500,1000],\"y\":[0.001290030117904999,0.001355541099188325,0.0014108633159577839],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":18},\"text\":\"Few-Shot: Energy Consumption by Number of Examples\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Number of Training Examples\"}},\"yaxis\":{\"title\":{\"text\":\"Energy Consumption (kWh)\"}},\"barmode\":\"stack\",\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8c63e59b-b6df-4e51-9da2-fe632695f257');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Few-Shot Energy Plot saved: fewshot_energy_by_shots.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT 2: Few-Shot Performance & Emissions by Shots (Dual Y-axis)\n",
        "print(\"\\n📊 Creating Few-Shot Performance vs Emissions Plot...\")\n",
        "\n",
        "df_sorted_fewshot = results_df_fewshot.sort_values('num_shots')\n",
        "\n",
        "fig_fewshot_perf = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# F1 Score line\n",
        "fig_fewshot_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_fewshot['num_shots'],\n",
        "        y=df_sorted_fewshot['f1_score'],\n",
        "        name='F1 Score',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#4ECDC4', width=3),\n",
        "        marker=dict(size=12, line=dict(width=2, color='white')),\n",
        "        hovertemplate='<b>F1 Score</b>: %{y:.4f}<br>Shots: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# Exact Match line\n",
        "fig_fewshot_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_fewshot['num_shots'],\n",
        "        y=df_sorted_fewshot['exact_match'],\n",
        "        name='Exact Match',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#95E1D3', width=3, dash='dash'),\n",
        "        marker=dict(size=10),\n",
        "        hovertemplate='<b>Exact Match</b>: %{y:.4f}<br>Shots: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# CO2 Emissions bar\n",
        "fig_fewshot_perf.add_trace(\n",
        "    go.Bar(\n",
        "        x=df_sorted_fewshot['num_shots'],\n",
        "        y=df_sorted_fewshot['emissions_kg'],\n",
        "        name='CO₂ Emissions',\n",
        "        marker_color='#FF6B6B',\n",
        "        opacity=0.6,\n",
        "        hovertemplate='<b>CO₂</b>: %{y:.6f} kg<br>Shots: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=True\n",
        ")\n",
        "\n",
        "fig_fewshot_perf.update_xaxes(title_text=\"Number of Training Examples\")\n",
        "fig_fewshot_perf.update_yaxes(title_text=\"Performance Score\", secondary_y=False)\n",
        "fig_fewshot_perf.update_yaxes(title_text=\"CO₂ Emissions (kg)\", secondary_y=True)\n",
        "\n",
        "fig_fewshot_perf.update_layout(\n",
        "    title=dict(text=\"Few-Shot: Performance vs Carbon Emissions\", font=dict(size=18)),\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_fewshot_perf.show()\n",
        "fig_fewshot_perf.write_html(\"/content/drive/MyDrive/fewshot_performance_emissions.html\")\n",
        "print(\"✅ Few-Shot Performance Plot saved: fewshot_performance_emissions.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "nUufORA0_Nnr",
        "outputId": "81710860-b7a1-4d7d-dfc0-d3b08418142f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Creating Few-Shot Performance vs Emissions Plot...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7e42e150-5ac3-49f8-a996-d4a5b67b47f8\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7e42e150-5ac3-49f8-a996-d4a5b67b47f8\")) {                    Plotly.newPlot(                        \"7e42e150-5ac3-49f8-a996-d4a5b67b47f8\",                        [{\"hovertemplate\":\"\\u003cb\\u003eF1 Score\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#4ECDC4\",\"width\":3},\"marker\":{\"line\":{\"color\":\"white\",\"width\":2},\"size\":12},\"mode\":\"lines+markers\",\"name\":\"F1 Score\",\"x\":[100,500,1000],\"y\":[0.009092133016800978,0.019856270121913332,0.02224507210654906],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eExact Match\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#95E1D3\",\"dash\":\"dash\",\"width\":3},\"marker\":{\"size\":10},\"mode\":\"lines+markers\",\"name\":\"Exact Match\",\"x\":[100,500,1000],\"y\":[0.0004120652711389484,0.008241305422778969,0.006428218229767595],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eCO₂\\u003c\\u002fb\\u003e: %{y:.6f} kg\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CO₂ Emissions\",\"opacity\":0.6,\"x\":[100,500,1000],\"y\":[0.00421994585331679,0.004405240286940078,0.004566649666030215],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Number of Training Examples\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Performance Score\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"CO₂ Emissions (kg)\"}},\"title\":{\"font\":{\"size\":18},\"text\":\"Few-Shot: Performance vs Carbon Emissions\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7e42e150-5ac3-49f8-a996-d4a5b67b47f8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Few-Shot Performance Plot saved: fewshot_performance_emissions.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Ma05_hK_N6d"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FjF39hj_OJk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparing And Testing All The Models"
      ],
      "metadata": {
        "id": "DrtZG214KEs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model_path, examples, tokenizer_name=\"distilbert-base-uncased\"):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🧪 MODEL TESTING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "\n",
        "    # Auto-detect model type\n",
        "    is_lora = \"lora_adapters\" in model_path or \"lora\" in model_path.lower()\n",
        "\n",
        "    if is_lora:\n",
        "        method = \"LoRA\"\n",
        "        # Load base model + LoRA adapters\n",
        "        base_model = AutoModelForQuestionAnswering.from_pretrained(tokenizer_name)\n",
        "        model = PeftModel.from_pretrained(base_model, model_path)\n",
        "        print(f\"✅ Loaded LoRA model (base + adapters)\")\n",
        "    else:\n",
        "        # Detect if few-shot or full fine-tuning\n",
        "        method = \"Few-Shot\" if \"fewshot\" in model_path.lower() else \"Full Fine-tuning\"\n",
        "        model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "        print(f\"✅ Loaded {method} model\")\n",
        "\n",
        "    print(f\"📋 Method: {method}\")\n",
        "    print(f\"📂 Path: {model_path}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create pipeline\n",
        "    qa_pipeline = pipeline(\n",
        "        \"question-answering\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "\n",
        "    # Test all examples\n",
        "    results = []\n",
        "    for i, ex in enumerate(examples, 1):\n",
        "        # Get prediction\n",
        "        prediction = qa_pipeline(question=ex['question'], context=ex['context'])\n",
        "\n",
        "        # Store result\n",
        "        result = {\n",
        "            'example_num': i,\n",
        "            'method': method,\n",
        "            'question': ex['question'],\n",
        "            'context': ex['context'][:100] + \"...\" if len(ex['context']) > 100 else ex['context'],\n",
        "            'predicted_answer': prediction['answer'],\n",
        "            'expected_answer': ex.get('expected_answer', None),\n",
        "            'confidence': prediction['score'],\n",
        "            'start_position': prediction['start'],\n",
        "            'end_position': prediction['end']\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Print formatted output\n",
        "        print(f\"\\n📝 Example {i}\")\n",
        "        print(f\"Question: {ex['question']}\")\n",
        "        print(f\"Context: {ex['context'][:150]}{'...' if len(ex['context']) > 150 else ''}\")\n",
        "        print(f\"\\n✅ Predicted: '{prediction['answer']}'\")\n",
        "        print(f\"   Confidence: {prediction['score']:.2%}\")\n",
        "\n",
        "        # Check match with expected answer\n",
        "        if ex.get('expected_answer'):\n",
        "            expected = ex['expected_answer'].lower().strip()\n",
        "            predicted = prediction['answer'].lower().strip()\n",
        "            # Flexible matching: either one contains the other\n",
        "            match = (predicted in expected) or (expected in predicted)\n",
        "            print(f\"   Expected: '{ex['expected_answer']}'\")\n",
        "            print(f\"   Match: {'✓ YES' if match else '✗ NO'}\")\n",
        "\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "_srVGCAvKJgG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_examples = [\n",
        "    {\n",
        "        'question': \"What does Google Colab provide access to?\",\n",
        "        'context': \"Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\",\n",
        "        'expected_answer': \"GPUs and TPUs\"\n",
        "    },\n",
        "    {\n",
        "        'question': \"When was Python created?\",\n",
        "        'context': \"Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\",\n",
        "        'expected_answer': \"1991\"\n",
        "    },\n",
        "    {\n",
        "        'question': \"What is the capital of France?\",\n",
        "        'context': \"Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\",\n",
        "        'expected_answer': \"Paris\"\n",
        "    },\n",
        "    {\n",
        "        'question': \"Who invented the telephone?\",\n",
        "        'context': \"The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\",\n",
        "        'expected_answer': \"Alexander Graham Bell\"\n",
        "    },\n",
        "]\n"
      ],
      "metadata": {
        "id": "QNVIDnOiKSO-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/'))"
      ],
      "metadata": {
        "id": "hV9fzNuWKhYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb356340-c6c0-4889-f660-4f31fa0807f5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'results_distilbert_80pct', 'results_distilbert_lora_r8_80pct', 'wandb', 'results_distilbert_lora_r4_80pct', 'results_distilbert_lora_r16_80pct', 'drive', 'results_distilbert_50pct', 'results_distilbert_fewshot_1000shots', 'results_distilbert_25pct', 'results_distilbert_fewshot_500shots', 'results_distilbert_fewshot_100shots', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Full Fine-tuning\n",
        "print(\"🔷\" * 40)\n",
        "print(\"TESTING FULL FINE-TUNING MODEL\")\n",
        "print(\"🔷\" * 40)\n",
        "results_full_ft = test_model(\n",
        "    model_path=\"results_distilbert_80pct/final_model\",\n",
        "    examples=test_examples\n",
        ")"
      ],
      "metadata": {
        "id": "378CIAFrKiap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33a431b-130e-4e4e-9040-4a1305d02b0b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "TESTING FULL FINE-TUNING MODEL\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "\n",
            "================================================================================\n",
            "🧪 MODEL TESTING\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded Full Fine-tuning model\n",
            "📋 Method: Full Fine-tuning\n",
            "📂 Path: results_distilbert_80pct/final_model\n",
            "================================================================================\n",
            "\n",
            "📝 Example 1\n",
            "Question: What does Google Colab provide access to?\n",
            "Context: Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\n",
            "\n",
            "✅ Predicted: 'GPUs and TPUs'\n",
            "   Confidence: 72.54%\n",
            "   Expected: 'GPUs and TPUs'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 2\n",
            "Question: When was Python created?\n",
            "Context: Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\n",
            "\n",
            "✅ Predicted: '1991'\n",
            "   Confidence: 88.14%\n",
            "   Expected: '1991'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 3\n",
            "Question: What is the capital of France?\n",
            "Context: Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\n",
            "\n",
            "✅ Predicted: 'Paris'\n",
            "   Confidence: 99.18%\n",
            "   Expected: 'Paris'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 4\n",
            "Question: Who invented the telephone?\n",
            "Context: The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\n",
            "\n",
            "✅ Predicted: 'Alexander Graham Bell'\n",
            "   Confidence: 99.51%\n",
            "   Expected: 'Alexander Graham Bell'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Z6WRm03BQF_"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z2FjZyBABPOk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test LoRA\n",
        "print(\"\\n\" + \"🔷\" * 40)\n",
        "print(\"TESTING LORA MODEL\")\n",
        "print(\"🔷\" * 40)\n",
        "results_lora = test_model(\n",
        "    model_path=\"results_distilbert_lora_r8_80pct/lora_adapters\",\n",
        "    examples=test_examples\n",
        ")\n"
      ],
      "metadata": {
        "id": "0phY_mC_Ki4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeda4ee5-0a13-428b-ca72-fd27db66afcc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "TESTING LORA MODEL\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "\n",
            "================================================================================\n",
            "🧪 MODEL TESTING\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded LoRA model (base + adapters)\n",
            "📋 Method: LoRA\n",
            "📂 Path: results_distilbert_lora_r8_80pct/lora_adapters\n",
            "================================================================================\n",
            "\n",
            "📝 Example 1\n",
            "Question: What does Google Colab provide access to?\n",
            "Context: Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\n",
            "\n",
            "✅ Predicted: 'GPUs and TPUs'\n",
            "   Confidence: 19.71%\n",
            "   Expected: 'GPUs and TPUs'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 2\n",
            "Question: When was Python created?\n",
            "Context: Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\n",
            "\n",
            "✅ Predicted: '1991'\n",
            "   Confidence: 72.26%\n",
            "   Expected: '1991'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 3\n",
            "Question: What is the capital of France?\n",
            "Context: Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\n",
            "\n",
            "✅ Predicted: 'Paris'\n",
            "   Confidence: 76.93%\n",
            "   Expected: 'Paris'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 4\n",
            "Question: Who invented the telephone?\n",
            "Context: The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\n",
            "\n",
            "✅ Predicted: 'Alexander Graham Bell'\n",
            "   Confidence: 91.53%\n",
            "   Expected: 'Alexander Graham Bell'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpZLHLJbBRFB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HoMvBwJLBQ2t"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Few-Shot\n",
        "print(\"\\n\" + \"🔷\" * 40)\n",
        "print(\"TESTING FEW-SHOT MODEL\")\n",
        "print(\"🔷\" * 40)\n",
        "test_results_fewshot = test_model(\n",
        "    model_path=\"results_distilbert_fewshot_1000shots/final_model\",\n",
        "    examples=test_examples\n",
        ")\n"
      ],
      "metadata": {
        "id": "s3D_mKYRKjG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7f5347-1bb2-4d19-9a64-a1a40c14c152"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "TESTING FEW-SHOT MODEL\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "\n",
            "================================================================================\n",
            "🧪 MODEL TESTING\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded Few-Shot model\n",
            "📋 Method: Few-Shot\n",
            "📂 Path: results_distilbert_fewshot_1000shots/final_model\n",
            "================================================================================\n",
            "\n",
            "📝 Example 1\n",
            "Question: What does Google Colab provide access to?\n",
            "Context: Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\n",
            "\n",
            "✅ Predicted: 'Google Colab provides free access to GPUs'\n",
            "   Confidence: 3.72%\n",
            "   Expected: 'GPUs and TPUs'\n",
            "   Match: ✗ NO\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 2\n",
            "Question: When was Python created?\n",
            "Context: Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\n",
            "\n",
            "✅ Predicted: 'van Rossum'\n",
            "   Confidence: 3.33%\n",
            "   Expected: '1991'\n",
            "   Match: ✗ NO\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 3\n",
            "Question: What is the capital of France?\n",
            "Context: Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\n",
            "\n",
            "✅ Predicted: 'Paris'\n",
            "   Confidence: 4.59%\n",
            "   Expected: 'Paris'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 4\n",
            "Question: Who invented the telephone?\n",
            "Context: The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\n",
            "\n",
            "✅ Predicted: 'Alexander Graham Bell'\n",
            "   Confidence: 4.67%\n",
            "   Expected: 'Alexander Graham Bell'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = {\n",
        "    \"Full FT (80%)\": results_full_ft,\n",
        "    \"LoRA (r=8, 80%)\": results_lora,\n",
        "    \"Few-Shot (1000)\": test_results_fewshot\n",
        "}\n"
      ],
      "metadata": {
        "id": "Qohx_n_dKyeO"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison Function"
      ],
      "metadata": {
        "id": "kQQ204BfK75X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(results_dict):\n",
        "    \"\"\"\n",
        "    Compare predictions across different models.\n",
        "\n",
        "    Args:\n",
        "        results_dict: Dict like {\"Full FT\": results_full_ft, \"LoRA\": results_lora, ...}\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with comparison\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📊 MODEL COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    comparison_data = []\n",
        "\n",
        "    for model_name, results in results_dict.items():\n",
        "        for result in results:\n",
        "            comparison_data.append({\n",
        "                'Model': model_name,\n",
        "                'Question': result['question'][:50] + \"...\",\n",
        "                'Predicted': result['predicted_answer'],\n",
        "                'Expected': result.get('expected_answer', 'N/A'),\n",
        "                'Confidence': result['confidence']\n",
        "            })\n",
        "\n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "    # Group by question to see how different models answer\n",
        "    for question in comparison_df['Question'].unique():\n",
        "        print(f\"\\nQUESTION: {question}\")\n",
        "        question_results = comparison_df[comparison_df['Question'] == question]\n",
        "        for _, row in question_results.iterrows():\n",
        "            exp = str(row['Expected']).lower()\n",
        "            pred = str(row['Predicted']).lower()\n",
        "            match_indicator = \"✓\" if (pred in exp or exp in pred) and exp != 'n/a' else \"✗\"\n",
        "            print(f\"  {match_indicator} {row['Model']:20s}: {row['Predicted']:40s} ({row['Confidence']:.1%})\")\n",
        "        expected_val = question_results.iloc[0]['Expected']\n",
        "        if expected_val != 'N/A':\n",
        "            print(f\"Expected ANSWER: {expected_val}\")\n",
        "\n",
        "    return comparison_df"
      ],
      "metadata": {
        "id": "ZW6YIBkRK7ZD"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = compare_models(all_results)"
      ],
      "metadata": {
        "id": "q8ko9x4RLGRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3dc8d06-aecc-45b0-a03b-41864a8fba1d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 MODEL COMPARISON\n",
            "================================================================================\n",
            "\n",
            "QUESTION: What does Google Colab provide access to?...\n",
            "  ✓ Full FT (80%)       : GPUs and TPUs                            (72.5%)\n",
            "  ✓ LoRA (r=8, 80%)     : GPUs and TPUs                            (19.7%)\n",
            "  ✗ Few-Shot (1000)     : Google Colab provides free access to GPUs (3.7%)\n",
            "Expected ANSWER: GPUs and TPUs\n",
            "\n",
            "QUESTION: When was Python created?...\n",
            "  ✓ Full FT (80%)       : 1991                                     (88.1%)\n",
            "  ✓ LoRA (r=8, 80%)     : 1991                                     (72.3%)\n",
            "  ✗ Few-Shot (1000)     : van Rossum                               (3.3%)\n",
            "Expected ANSWER: 1991\n",
            "\n",
            "QUESTION: What is the capital of France?...\n",
            "  ✓ Full FT (80%)       : Paris                                    (99.2%)\n",
            "  ✓ LoRA (r=8, 80%)     : Paris                                    (76.9%)\n",
            "  ✓ Few-Shot (1000)     : Paris                                    (4.6%)\n",
            "Expected ANSWER: Paris\n",
            "\n",
            "QUESTION: Who invented the telephone?...\n",
            "  ✓ Full FT (80%)       : Alexander Graham Bell                    (99.5%)\n",
            "  ✓ LoRA (r=8, 80%)     : Alexander Graham Bell                    (91.5%)\n",
            "  ✓ Few-Shot (1000)     : Alexander Graham Bell                    (4.7%)\n",
            "Expected ANSWER: Alexander Graham Bell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save comparison results\n",
        "comparison_df.to_csv(\"/content/drive/MyDrive/model_comparison.csv\", index=False)"
      ],
      "metadata": {
        "id": "6-apjOn1LJOe"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xVCTSPqI5Fxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📊 COMPARISON: FULL FT vs LoRA vs FEW-SHOT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load previous results\n",
        "full_ft_results = pd.read_csv(\"/content/drive/MyDrive/distilbert_dataset_size_results.csv\")\n",
        "lora_results = pd.read_csv(\"/content/drive/MyDrive/distilbert_lora_results.csv\")\n",
        "results_fewshot = pd.read_csv(\"/content/drive/MyDrive/distilbert_fewshot_results.csv\")\n",
        "\n",
        "# Add method identifiers if not present\n",
        "if 'training_method' not in full_ft_results.columns:\n",
        "    full_ft_results['training_method'] = 'Full Fine-tuning'\n",
        "if 'training_method' not in lora_results.columns:\n",
        "    lora_results['training_method'] = 'LoRA'\n",
        "\n",
        "# Combine all results\n",
        "all_methods = pd.concat([full_ft_results, lora_results, results_fewshot], ignore_index=True)\n",
        "\n",
        "print(\"\\n🔍 Training Efficiency Comparison:\")\n",
        "print(all_methods[['training_method', 'train_samples','f1_score', 'emissions_kg', 'training_time_hours']].to_string(index=False))\n",
        "\n",
        "# Save combined results\n",
        "all_methods.to_csv(\"/content/drive/MyDrive/all_training_methods_comparison.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "yThvYIcx18Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0253c091-4238-425f-9dd1-9f7f216c96f6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 COMPARISON: FULL FT vs LoRA vs FEW-SHOT\n",
            "================================================================================\n",
            "\n",
            "🔍 Training Efficiency Comparison:\n",
            "           training_method  train_samples  f1_score  emissions_kg  training_time_hours\n",
            "          Full Fine-Tuning          32579  0.456665      0.007162             0.050625\n",
            "          Full Fine-Tuning          65159  0.569894      0.013308             0.089906\n",
            "          Full Fine-Tuning         104255  0.610566      0.020812             0.139686\n",
            "                      LoRA         104255  0.493001      0.000154             0.139547\n",
            "                      LoRA         104255  0.513852      0.018320             0.139261\n",
            "                      LoRA         104255  0.544429      0.018351             0.139900\n",
            "Few-Shot (Frozen Backbone)            100  0.009092      0.004220             0.033830\n",
            "Few-Shot (Frozen Backbone)            500  0.019856      0.004405             0.035559\n",
            "Few-Shot (Frozen Backbone)           1000  0.022245      0.004567             0.037006\n"
          ]
        }
      ]
    }
  ]
}