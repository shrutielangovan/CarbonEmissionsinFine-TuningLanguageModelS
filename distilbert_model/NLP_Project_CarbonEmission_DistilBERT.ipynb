{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT7GJLlUasqb"
      },
      "source": [
        "# Quantifying the Environmental Cost of AI: Carbon Emissions in Language Model Fine-Tuning for Question Answering\n",
        "\n",
        "> ### **Project Goal** : As language models continue to play a larger role in natural language processing, their environmental impact has become an important issue to consider. While much of the research in this area focuses on improving model accuracy, the energy use and carbon footprint involved in training these systems are often overlooked or poorly documented. This project aims to explore that imbalance by studying how improvements in model performance relate to the environmental costs of fine-tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDFB_pSelc1A"
      },
      "source": [
        "# Training Strategy 1: Full Fine-Tuning (Model DistilBERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AwY_kTISlSSE",
        "outputId": "70aa2e93-627b-430b-c98a-f3b6f0ab2a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.12/dist-packages (from codecarbon) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from codecarbon) (8.3.1)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.23.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from codecarbon) (7.1.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.12.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.580.82)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from codecarbon) (3.14.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.32.4)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2025.2)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->codecarbon) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.4.2)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from questionary->codecarbon) (3.0.52)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->codecarbon) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.12/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<4.0,>=3.1 in /usr/local/lib/python3.12/dist-packages (from yaspin->fief-client[cli]->codecarbon) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.23)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.12/dist-packages (from codecarbon) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from codecarbon) (8.3.1)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.23.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from codecarbon) (7.1.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.12.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.580.82)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from codecarbon) (3.14.3)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.12/dist-packages (from codecarbon) (2.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow->codecarbon) (2025.2)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.12/dist-packages (from fief-client[cli]->codecarbon) (3.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->codecarbon) (0.4.2)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from questionary->codecarbon) (3.0.52)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->codecarbon) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.12/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<4.0,>=3.1 in /usr/local/lib/python3.12/dist-packages (from yaspin->fief-client[cli]->codecarbon) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install codecarbon\n",
        "!pip install evaluate codecarbon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zsuW8wdlhSb",
        "outputId": "cdf60915-35a0-40ac-b4f4-0f3c60b9af16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Importing Necessary Libraries\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    default_data_collator,\n",
        "    pipeline\n",
        ")\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "from codecarbon import EmissionsTracker\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YcR2XtolnYA"
      },
      "source": [
        "## STEP 1: Loading The Stanford Question Answering Dataset (SQuAD) Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "d7b3d7ad327f477080f7c92fb02ea7a1",
            "173a4dbe0c864beeaf7f3915b7a163ca",
            "67485b4611d4438a8d1249433a0e071f",
            "fff3cad08d934ee0961af6c59e65b549",
            "f1067a5f8ae9465e963c268a459fe78b",
            "92807d108358488d824333bf980baf1f",
            "5072fa79f58145c9979813553647817f",
            "31d37f6449b1479cb15a5be414ae0e15",
            "ea9afc46b7a3402b90fcdba7c361a806",
            "02ff18e353554854a1c9924806097bfe",
            "7823f5f7a3624380bf3235d23bdb9263",
            "3a839281bcb34695bd2dc1a06f311002",
            "ca1f8d40efe949d886d8942822aa1ade",
            "1f11efa7a3074cb8ac5ef42912944d11",
            "5ce028160e6e40b68cb51f2f5360eda3",
            "7b34aa654a7849ad8aa6e359ac03bc8b",
            "702ee8bd72ca4f01a58ea4d88340493c",
            "e112f6f33e3e41c18be57e1eebaf151b",
            "521b274e0c914dcaa479a8a327982bbd",
            "bab04a025acf48fabff7e01b6c1c4ea9",
            "10391fec057f4b16be70f3acf9ac10ad",
            "7e8f13db778840ad9a94b8d1c2f29ccb",
            "9f729c7b70284376a7538a164cb66ae3",
            "2f944c76f7b1469ba26e7181ea46e5e3",
            "9b49b82da56c4a389fe300e554f2b6f4",
            "ecf9cd9af17f46caa7061259e2d57334",
            "46921d4706e74445b7ee3c59ec5aa607",
            "2f7f829a4c3e4498ac17c25c40f7885b",
            "60f75fdadc584bdf959a074a2f1b473b",
            "ed48aa0cf3224828b2a95b02c1e54f5e",
            "b0d41af66a604b1eb5a2e0eca31021aa",
            "78b892c5ced44dab96d957e3630b6572",
            "935cbd1d8c834d45a613976992467e89",
            "a4387a39a156400ea211ce9cf0cf183d",
            "c5dc664513714c099de9ed45d042e403",
            "3af0f61c625b4f8e8b1351490135adc2",
            "61f622d3b3f446338fdbf8b1f88da86f",
            "c675ea72988a4ad186f8597155905571",
            "8c9953d48a454e31b2779f63ef30f24a",
            "97bdf9cd3ad943f2882dbe0f6920f657",
            "bc51a21357474a7abfc9cdf4e31ba6cd",
            "c8caefc0fdfc46e6b52e0e2541218688",
            "60fe6db9694543df98319625bff2ffe3",
            "a79610aa810c4631afa931a3a465e049",
            "8238bdd87e5748ab8526c373f52fefc8",
            "9fe241adc8b54c8dad39b29c584078f6",
            "39077809c0514e67bbef1e65716aa4b0",
            "d6ffe11864344fcb9ce4e6df6f47aa4b",
            "5fe82d285d914d4280d10e207debddfb",
            "ebb3220e65fc4f82a70fc239754902b7",
            "2f12c90a58014c46a9b62a9a45a6dc0f",
            "14f070e40c6d4a6488a362ee11bfd552",
            "69a7436347d2401b9599ceac3d1b7652",
            "68d3bab328594d699ad159c66a1fda91",
            "4d992835ffbe4c1e8f8b70b72c5ffbfc"
          ]
        },
        "id": "eYkn3aL9lvj9",
        "outputId": "be9b1148-2023-4058-f5d5-10ad69a03fc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7b3d7ad327f477080f7c92fb02ea7a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a839281bcb34695bd2dc1a06f311002",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "squad_v2/train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f729c7b70284376a7538a164cb66ae3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "squad_v2/validation-00000-of-00001.parqu(…):   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4387a39a156400ea211ce9cf0cf183d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8238bdd87e5748ab8526c373f52fefc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "squad = load_dataset(\"squad_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mt2IAWUlv6X",
        "outputId": "96603e08-b274-44ac-8cee-12bdfaeb1a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SQuAD Format:  DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 130319\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 11873\n",
            "    })\n",
            "})\n",
            "\n",
            "Full training set size: 130319\n",
            "\n",
            "Validation set size: 11873\n"
          ]
        }
      ],
      "source": [
        "print(\"SQuAD Format: \",squad)\n",
        "print(f\"\\nFull training set size: {len(squad['train'])}\")\n",
        "print(f\"\\nValidation set size: {len(squad['validation'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Qz-_-0kl5q1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z2N-Gz3l0ub"
      },
      "source": [
        "## STEP 2: Tokenization For the Model Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "e240cc92999c4820a239e9ebee556339",
            "0f519a817e584ac780fbfc8b6be3b91f",
            "1197271181a241cf895c658712fc7ae7",
            "f43eb30acbd54898877c45035443bf0d",
            "545ddc94960244f48053a3a5bfd7dfde",
            "3181e33e6d574faf80c29d7054b2728b",
            "063061b48ad042d2b868dff535a51b40",
            "a8f333530c1640e6b71999ec62315cd5",
            "a961165d31e54a50ba2be0a9a6cddaba",
            "d4ff5a54196c423f8edeb5e7206b4943",
            "edbb60106e8c43dcb822b50ed2086818",
            "450666f0c24b4b5d8b9fbb58caf8cc95",
            "27f2ee99297c4f2e8efe5596d23f5dd2",
            "4329bd70bde84898a1b9274bb3010622",
            "f9ba16f45a2547d0bcc9c7f2343d2464",
            "455f3d1e2f904a0992b18ad7306aaf7f",
            "c8ca2b60a05648ccac592887ba0254c6",
            "5a108186003f4ceaa3959ac72d7b2b7a",
            "69488844fabb449f9ea0c461de2bdadf",
            "f86f0ef3b694464a81454fc99dc30737",
            "a8e5fd0b0add459f91c9e1fd6bb78113",
            "520f06d7d1ed4d9197a96766b921abe1",
            "4be4bdc0437b450398c841a7308a10b1",
            "a739e61b6ea94425b79681c85157f113",
            "0d6fc7fc82a94fdd80e34910363202a1",
            "85960286dc3142fe9a060376945480af",
            "b53693dbb5f34d23afb2718e014655ab",
            "ae2dbad9916e45f59828eda898b40a93",
            "26415c2dff7641e2a1d69a75c27a913a",
            "0a6d01f5033d44e4bf1b9d289ac89eac",
            "b0d1f39e48474305b127305a4bdb6abc",
            "5abd0688edc741a69adbb2ab1da4556b",
            "4dd51c094a244bd7b81638c7b1fd2296",
            "aeb0fa2a1c3244149a24d9cd0a0cde56",
            "dab7cce50eb649e3a0ad1ec6231dd6db",
            "a6468a135f68427f8a9b30e1fd9b55ba",
            "3436237e20a14c38a6022d2b8dde4cf8",
            "83d28e6614064cf1808c652e1f99664c",
            "f97e13acad9543f899820f5cf3f185c8",
            "64edd12242d945228af4c5a908d2685b",
            "0bae3ddc1d824da18335f8568342b173",
            "8f13f8d4e3ef43e8907656c4808f0644",
            "c4825fdd305a439f8be641d16f8ad879",
            "a5b2f13393d049efb90395d2bb9054b4"
          ]
        },
        "id": "16ktu0CDl4r2",
        "outputId": "3070e75c-b09b-4e87-ad3e-a622cbaa63dc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e240cc92999c4820a239e9ebee556339",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "450666f0c24b4b5d8b9fbb58caf8cc95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4be4bdc0437b450398c841a7308a10b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aeb0fa2a1c3244149a24d9cd0a0cde56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Autotokenizer automatically picks the correct tokenizer for given model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gD28U6xrl45G"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    contexts = [c.strip() for c in examples[\"context\"]]\n",
        "\n",
        "    # Tokenize\n",
        "    tokenized = tokenizer(\n",
        "        questions,\n",
        "        contexts,\n",
        "        max_length=384,\n",
        "        stride=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=\"only_second\",         #Truncate from context\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "    )\n",
        "\n",
        "    # Mapping back to original samples\n",
        "    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n",
        "    offset_mapping = tokenized[\"offset_mapping\"]\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        sample_idx = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_idx]\n",
        "\n",
        "        # In no answer case\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "            continue\n",
        "\n",
        "        start_char = answers[\"answer_start\"][0]\n",
        "        end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "        seq_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "        # Find context section\n",
        "        context_start = seq_ids.index(1) if 1 in seq_ids else 0\n",
        "        context_end = len(seq_ids) - 1 - seq_ids[::-1].index(1) if 1 in seq_ids else len(seq_ids) - 1\n",
        "\n",
        "        # If answer not inside context - mark no answer\n",
        "        if not (offsets[context_start][0] <= start_char and offsets[context_end][1] >= end_char):\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "            continue\n",
        "\n",
        "        # Find start token\n",
        "        token_start = context_start\n",
        "        while token_start <= context_end and offsets[token_start][0] <= start_char:\n",
        "            token_start += 1\n",
        "        start_positions.append(token_start - 1)\n",
        "\n",
        "        # Find end token - move forward until we pass answer end\n",
        "        token_end = context_start\n",
        "        while token_end <= context_end and offsets[token_end][1] < end_char:\n",
        "            token_end += 1\n",
        "        end_positions.append(token_end)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-gQk5Va0YVh",
        "outputId": "85792720-8193-42d9-eda0-f97fb9a37b0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== Data Format Within SQuAD Training Set ==========\n",
            "\n",
            "Question at Index[0]:  When did Beyonce start becoming popular?\n",
            "\n",
            "Context at Index[0]:  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
            "\n",
            "Answers at Index[0]:  {'text': ['in the late 1990s'], 'answer_start': [269]}\n",
            "\n",
            "========== Data Format After Preprocessing ==========\n",
            "\n",
            " input_ids : [[101, 2043, 2106, 20773, 2707, 3352, 2759, 1029, 102, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, 2088, 1005, 1055, 2190, 1011, 4855, 2611, 2967, 1997, 2035, 2051, 1012, 2037, 14221, 2387, 1996, 2713, 1997, 20773, 1005, 1055, 2834, 2201, 1010, 20754, 1999, 2293, 1006, 2494, 1007, 1010, 2029, 2511, 2014, 2004, 1037, 3948, 3063, 4969, 1010, 3687, 2274, 8922, 2982, 1998, 2956, 1996, 4908, 2980, 2531, 2193, 1011, 2028, 3895, 1000, 4689, 1999, 2293, 1000, 1998, 1000, 3336, 2879, 1000, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            " attention_mask : [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            " offset_mapping : [[(0, 0), (0, 4), (5, 8), (9, 16), (17, 22), (23, 31), (32, 39), (39, 40), (0, 0), (0, 7), (8, 10), (10, 15), (16, 23), (23, 24), (24, 30), (31, 32), (32, 33), (33, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 42), (42, 43), (43, 44), (45, 48), (48, 49), (49, 51), (51, 52), (52, 53), (53, 56), (56, 57), (58, 59), (59, 63), (64, 73), (74, 75), (75, 76), (77, 81), (81, 82), (83, 85), (86, 88), (89, 97), (98, 104), (104, 105), (106, 116), (116, 117), (118, 124), (125, 133), (134, 137), (138, 145), (145, 146), (147, 151), (152, 155), (156, 162), (163, 165), (166, 173), (173, 174), (175, 180), (180, 181), (182, 185), (186, 195), (196, 198), (199, 206), (207, 214), (215, 218), (219, 226), (227, 239), (240, 242), (243, 244), (245, 250), (250, 251), (252, 255), (256, 260), (261, 263), (264, 268), (269, 271), (272, 275), (276, 280), (281, 286), (287, 289), (290, 294), (295, 301), (302, 304), (305, 306), (306, 307), (307, 308), (309, 313), (313, 314), (314, 319), (320, 327), (327, 328), (328, 329), (330, 335), (335, 336), (337, 344), (345, 347), (348, 351), (352, 358), (358, 359), (360, 366), (367, 374), (374, 375), (376, 379), (380, 385), (386, 392), (393, 396), (397, 399), (400, 403), (404, 409), (409, 410), (410, 411), (412, 416), (416, 417), (417, 424), (425, 429), (430, 436), (437, 439), (440, 443), (444, 448), (448, 449), (450, 455), (456, 462), (463, 466), (467, 470), (471, 478), (479, 481), (482, 489), (489, 490), (490, 491), (492, 497), (498, 503), (503, 504), (505, 516), (517, 519), (520, 524), (525, 526), (526, 530), (530, 531), (531, 532), (533, 538), (539, 550), (551, 554), (555, 557), (558, 559), (560, 564), (565, 571), (572, 581), (581, 582), (583, 589), (590, 594), (595, 601), (602, 608), (609, 612), (613, 621), (622, 625), (626, 635), (636, 639), (640, 643), (644, 650), (650, 651), (651, 654), (655, 662), (663, 664), (664, 669), (670, 672), (673, 677), (677, 678), (679, 682), (683, 684), (684, 688), (689, 692), (692, 693), (693, 694), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]]\n",
            "\n",
            " start_positions : [75]\n",
            "\n",
            " end_positions : [78]\n",
            "\n",
            "Predicted Answer Mapping: 'in the late 1990s'\n"
          ]
        }
      ],
      "source": [
        "print(\"========== Data Format Within SQuAD Training Set ==========\")\n",
        "print(\"\\nQuestion at Index[0]: \", squad[\"train\"][0]['question'])\n",
        "print(\"\\nContext at Index[0]: \", squad[\"train\"][0]['context'])\n",
        "print(\"\\nAnswers at Index[0]: \", squad[\"train\"][0]['answers'])\n",
        "\n",
        "#Testing preprocess_function function\n",
        "sample = {\n",
        "    \"question\": [squad[\"train\"][0]['question']],\n",
        "    \"context\": [squad[\"train\"][0]['context']],\n",
        "    \"answers\": [squad[\"train\"][0]['answers']]\n",
        "}\n",
        "\n",
        "output = preprocess_function(sample)\n",
        "print(\"\\n========== Data Format After Preprocessing ==========\")\n",
        "\n",
        "for k, v in output.items():\n",
        "\n",
        "    print('\\n',k, \":\", v[:5] if isinstance(v, list) else v)\n",
        "\n",
        "# Now test start and end position mapping\n",
        "predicted = tokenizer.decode(output['input_ids'][0][output['start_positions'][0]:output['end_positions'][0]+1])\n",
        "print(f\"\\nPredicted Answer Mapping: '{predicted}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ut-Dl5w20X6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "3884bb1ebc52495a82e676fdfe94cacd",
            "82ecfae2b00f488ea05bfc9937899dd7",
            "38989071c87546c0af48454d71dc29e5",
            "51031e0c4f144797bb08a801eff85ec8",
            "a84ad6235d6b4e519e687464df4370b8",
            "3a8430b6680948d3bbf7be2feb9d1f1e",
            "75c1cb29719f490ab7192a3f0561d5d0",
            "61588aaa31de4d65bd8e9fa0afc82c78",
            "d6509aaf2c7e475281a9a40de0819cac",
            "c0c760d183474412a5be26bbba590b9b",
            "51432e9bca1f4d9f8fa414693aad8fd8"
          ]
        },
        "id": "q74X9XTMl5F3",
        "outputId": "26b2c37c-b59d-4525-9c54-dd5deeae5bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔄 Preprocessing validation set...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3884bb1ebc52495a82e676fdfe94cacd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Preprocess validation set (full)\n",
        "print(\"\\n🔄 Preprocessing validation set...\")\n",
        "tokenized_validation = squad[\"validation\"].map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=squad[\"validation\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEouPPA_l-HN",
        "outputId": "bab7c66e-4fb8-47cf-8216-dc7d715aeaae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': List(Value('int32')),\n",
              " 'attention_mask': List(Value('int8')),\n",
              " 'offset_mapping': List(List(Value('int64'))),\n",
              " 'start_positions': Value('int64'),\n",
              " 'end_positions': Value('int64')}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_validation.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N2vLL0gAl-Tc"
      },
      "outputs": [],
      "source": [
        "#Prepareing function for tokenization based of training size of the data.\n",
        "\n",
        "def prepare_dataset(train_data, size_fraction, preprocess_fn):\n",
        "\n",
        "    #Create and preprocess a subset of training data.\n",
        "    num_samples = int(len(train_data) * size_fraction)\n",
        "    train_subset = train_data.select(range(num_samples))\n",
        "\n",
        "    print(f\"🔄 Preprocessing {num_samples} training samples...\")\n",
        "    tokenized_train = train_subset.map(\n",
        "        preprocess_fn,\n",
        "        batched=True,\n",
        "        remove_columns=train_subset.column_names\n",
        "    )\n",
        "\n",
        "    return tokenized_train, num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3K3sGq6Gl-f8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdJOJApbmDiV"
      },
      "source": [
        "## STEP 3: Training The DistilBert Model Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426,
          "referenced_widgets": [
            "abf5b82ccd3a44aab62df8eca75b2557",
            "9b722d05fa3d4fd09b5904f52477d004",
            "d76bd6d56fac4089b445cbd276a44368",
            "2e94733bc4c54eb7823243c066adfbec",
            "e834f87ccd47400ba07940056387013f",
            "a28ed594876e4809b3cb96b5928a9655",
            "a26bf8cdd46b49ba82bde8afc79e4494",
            "818c7d49ecf34d70b451cb8900509481",
            "f3d80f1a5e2946a3ae9403835b65fef5",
            "d71fe67e483645d89e7286719f7f3415",
            "23616464687a409e816a80b59fd10062"
          ]
        },
        "id": "l_m7R8IxmHV0",
        "outputId": "637c288b-e6d6-4e6e-ff8c-4d2c2d8f9431"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abf5b82ccd3a44aab62df8eca75b2557",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "🛠 DistilBERT Model Architecture:\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Transformer layers: 6\n",
            "\n",
            "Hidden size: 768\n",
            "\n",
            "Intermediate feed-forward size: 3072\n",
            "\n",
            "Attention heads: 12\n",
            "\n",
            "Max positional embeddings: 512\n",
            "\n",
            "Vocabulary size: 30522\n"
          ]
        }
      ],
      "source": [
        "#Model Architecture:\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"\\n🛠 DistilBERT Model Architecture:\")\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"\\nTransformer layers:\",model.config.n_layers)\n",
        "print(\"\\nHidden size:\",model.config.dim)\n",
        "print('\\nIntermediate feed-forward size:',model.config.hidden_dim)\n",
        "print(\"\\nAttention heads:\",model.config.n_heads)\n",
        "print(\"\\nMax positional embeddings:\", model.config.max_position_embeddings)\n",
        "print(\"\\nVocabulary size:\", model.config.vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JplgJ5BumHh0"
      },
      "outputs": [],
      "source": [
        "# Custom compute metrics function for F1 and Exact Match\n",
        "def compute_metrics(pred):\n",
        "    predictions, labels = pred\n",
        "    start_preds = np.argmax(predictions[0], axis=1)\n",
        "    end_preds = np.argmax(predictions[1], axis=1)\n",
        "\n",
        "    start_true = labels[0]\n",
        "    end_true = labels[1]\n",
        "\n",
        "    # Calculate exact match\n",
        "    exact_matches = ((start_preds == start_true) & (end_preds == end_true)).sum()\n",
        "    exact_match = exact_matches / len(start_true)\n",
        "\n",
        "    # Calculate F1 score (token overlap)\n",
        "    f1_scores = []\n",
        "    for start_p, end_p, start_t, end_t in zip(start_preds, end_preds, start_true, end_true):\n",
        "        pred_tokens = set(range(start_p, end_p + 1))\n",
        "        true_tokens = set(range(start_t, end_t + 1))\n",
        "\n",
        "        if len(pred_tokens) == 0 and len(true_tokens) == 0:\n",
        "            f1_scores.append(1.0)\n",
        "        elif len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
        "            f1_scores.append(0.0)\n",
        "        else:\n",
        "            overlap = len(pred_tokens & true_tokens)\n",
        "            precision = overlap / len(pred_tokens)\n",
        "            recall = overlap / len(true_tokens)\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "    return {\n",
        "        \"exact_match\": exact_match,\n",
        "        \"f1\": avg_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ckLtCZSLmHuk"
      },
      "outputs": [],
      "source": [
        "def train_model(tokenized_train, tokenized_eval, tokenizer, compute_metrics_fn,\n",
        "                size_fraction, model_name):\n",
        "\n",
        "    # Load fresh model\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "    # Setup output directory\n",
        "    output_dir = f\"results_distilbert_{int(size_fraction*100)}pct\"\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=3e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=2,\n",
        "        weight_decay=0.01,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        push_to_hub=False,\n",
        "        logging_steps=100,\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        compute_metrics=compute_metrics_fn\n",
        "    )\n",
        "\n",
        "    # Start carbon tracking\n",
        "    tracker = EmissionsTracker(\n",
        "        project_name=f\"DistilBERT_{int(size_fraction*100)}pct\",\n",
        "        output_dir=output_dir\n",
        "    )\n",
        "    tracker.start()\n",
        "\n",
        "    # Train\n",
        "    print(\"🏋️ Training model...\")\n",
        "    train_results = trainer.train()\n",
        "\n",
        "    # Stop carbon tracking\n",
        "    tracker.stop()\n",
        "\n",
        "    emissions_data = tracker.final_emissions_data\n",
        "\n",
        "    return trainer, train_results, emissions_data, output_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BVu3KY31mII4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PLVjbcclmOCe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgTY34DmOYH"
      },
      "source": [
        "## STEP 4: Evaluating And Saving The Results Functions\n",
        "\n",
        "> We will be training our model on various data sizes from our SQuAD dataset.\n",
        ">\n",
        "> Training Data Variation: [25%, 50%, 80%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9CPJ12uUmSGG"
      },
      "outputs": [],
      "source": [
        "def evaluate_and_save(trainer, train_results, emissions_data, output_dir,\n",
        "                      size_fraction, num_samples):\n",
        "    \"\"\"Evaluate model, print results, and save artifacts.\"\"\"\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"📊 Evaluating model...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    #Calculate trainable parameters for Full Fine-tuning\n",
        "    model = trainer.model\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_percentage = 100 * trainable_params / total_params\n",
        "\n",
        "    # Compile results\n",
        "    result_entry = {\n",
        "        \"training_method\": \"Full Fine-Tuning\",\n",
        "        \"model_name\": \"DistilBERT\",\n",
        "        'dataset_size%': int(size_fraction*100),\n",
        "        \"train_samples\": num_samples,\n",
        "        \"valid_samples\": len(tokenized_validation),\n",
        "        \"trainable_params\": trainable_params,\n",
        "        \"total_params\": total_params,\n",
        "        \"trainable_percentage\": trainable_percentage,\n",
        "\n",
        "        # Performance metrics\n",
        "        \"f1_score\": eval_results[\"eval_f1\"],\n",
        "        \"exact_match\": eval_results[\"eval_exact_match\"],\n",
        "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
        "        \"training_time_hours\": train_results.metrics[\"train_runtime\"] / 3600,\n",
        "\n",
        "        # Emissions data\n",
        "        \"emissions_rate_kg_per_s\": emissions_data.emissions_rate,\n",
        "        \"emissions_kg\": emissions_data.emissions,\n",
        "        \"timestamp\": emissions_data.timestamp,\n",
        "        \"duration_seconds\": emissions_data.duration,\n",
        "        \"duration_hours\": emissions_data.duration / 3600,\n",
        "\n",
        "        # Energy consumption\n",
        "        \"energy_consumed_kwh\": emissions_data.energy_consumed,\n",
        "        \"cpu_energy_kwh\": emissions_data.cpu_energy,\n",
        "        \"gpu_energy_kwh\": emissions_data.gpu_energy,\n",
        "        \"ram_energy_kwh\": emissions_data.ram_energy,\n",
        "\n",
        "        # Power draw\n",
        "        \"cpu_power_w\": emissions_data.cpu_power,\n",
        "        \"gpu_power_w\": emissions_data.gpu_power,\n",
        "        \"ram_power_w\": emissions_data.ram_power,\n",
        "\n",
        "        # Location and system info\n",
        "        \"country_name\": emissions_data.country_name,\n",
        "        \"country_iso_code\": emissions_data.country_iso_code,\n",
        "        \"region\": emissions_data.region,\n",
        "        \"cloud_provider\": emissions_data.cloud_provider,\n",
        "        \"cloud_region\": emissions_data.cloud_region,\n",
        "        \"on_cloud\": emissions_data.on_cloud,\n",
        "\n",
        "        # System specifications\n",
        "        \"os\": emissions_data.os,\n",
        "        \"python_version\": emissions_data.python_version,\n",
        "        \"cpu_count\": emissions_data.cpu_count,\n",
        "        \"cpu_model\": emissions_data.cpu_model,\n",
        "        \"gpu_count\": emissions_data.gpu_count,\n",
        "        \"gpu_model\": emissions_data.gpu_model,\n",
        "        \"ram_total_size_gb\": emissions_data.ram_total_size,\n",
        "\n",
        "        # Additional metrics\n",
        "        \"pue\": emissions_data.pue,\n",
        "        \"codecarbon_version\": emissions_data.codecarbon_version,\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"\\n📈 FINE-TUNING RESULTS SUMMARY FOR {size_fraction*100}% DATASET:\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"  Training Method: Full Fine-Tuning\")\n",
        "    print(f\"  Model: DistilBERT\")\n",
        "\n",
        "    print(f\"\\n🔧 Model Parameters:\")\n",
        "    print(f\"  Total Parameters: {total_params:,}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"  Trainable Percentage: {trainable_percentage:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"\\n🎯 Performance Metrics:\")\n",
        "    print(f\"  F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"  Exact Match: {eval_results['eval_exact_match']:.4f}\")\n",
        "    print(f\"  Eval Loss: {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\n⚡ Energy Consumption:\")\n",
        "    print(f\"  Total Energy: {emissions_data.energy_consumed:.6f} kWh\")\n",
        "    print(f\"  CPU Energy: {emissions_data.cpu_energy:.6f} kWh ({emissions_data.cpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  GPU Energy: {emissions_data.gpu_energy:.6f} kWh ({emissions_data.gpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  RAM Energy: {emissions_data.ram_energy:.6f} kWh ({emissions_data.ram_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n🔌 Average Power Draw:\")\n",
        "    print(f\"  CPU Power: {emissions_data.cpu_power:.2f} W\")\n",
        "    print(f\"  GPU Power: {emissions_data.gpu_power:.2f} W\")\n",
        "    print(f\"  RAM Power: {emissions_data.ram_power:.2f} W\")\n",
        "    print(f\"  Total Power: {emissions_data.cpu_power + emissions_data.gpu_power + emissions_data.ram_power:.2f} W\")\n",
        "\n",
        "    print(f\"\\n🌱 Carbon Footprint:\")\n",
        "    print(f\"  Total CO2 Emissions: {emissions_data.emissions:.6f} kg\")\n",
        "    print(f\"  Emissions Rate: {emissions_data.emissions_rate:.9f} kg/s\")\n",
        "    print(f\"  Duration: {emissions_data.duration/3600:.2f} hours\")\n",
        "    print(f\"  Training Time (Trainer): {train_results.metrics['train_runtime']/3600:.2f} hours\")\n",
        "\n",
        "    print(f\"\\n📍 Location & Infrastructure:\")\n",
        "    print(f\"  Country: {emissions_data.country_name} ({emissions_data.country_iso_code})\")\n",
        "    print(f\"  Region: {emissions_data.region}\")\n",
        "    print(f\"  On Cloud: {emissions_data.on_cloud}\")\n",
        "    print(f\"  PUE (Power Usage Effectiveness): {emissions_data.pue}\")\n",
        "\n",
        "    print(f\"\\n💻 System Specifications:\")\n",
        "    print(f\"  OS: {emissions_data.os}\")\n",
        "    print(f\"  CPU: {emissions_data.cpu_model} ({emissions_data.cpu_count} cores)\")\n",
        "    if emissions_data.gpu_count and emissions_data.gpu_model:\n",
        "        print(f\"  GPU: {emissions_data.gpu_model} (Count: {emissions_data.gpu_count})\")\n",
        "    else:\n",
        "        print(f\"  GPU: None detected\")\n",
        "    print(f\"  RAM: {emissions_data.ram_total_size:.2f} GB\")\n",
        "    print(f\"  Python: {emissions_data.python_version}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "\n",
        "    # Save model\n",
        "    trainer.save_model(f\"{output_dir}/final_model\")\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del trainer.model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result_entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ttEc4sECmSSm"
      },
      "outputs": [],
      "source": [
        "def run_experiment(size_fraction, train_data, eval_data, tokenizer, preprocess_fn, compute_metrics_fn, model_name):\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🚀 Training with {size_fraction*100}% of training data\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Step 1: Prepare dataset\n",
        "    tokenized_train, num_samples = prepare_dataset(train_data, size_fraction, preprocess_fn)\n",
        "\n",
        "    # Step 2: Train model\n",
        "    trainer, train_results, emissions_data, output_dir = train_model(\n",
        "        tokenized_train, eval_data, tokenizer, compute_metrics_fn,\n",
        "        size_fraction, model_name\n",
        "    )\n",
        "\n",
        "    # Step 3: Evaluate and save\n",
        "    result_entry = evaluate_and_save(trainer, train_results, emissions_data, output_dir, size_fraction, num_samples)\n",
        "\n",
        "    return result_entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_9x0PvPSmSfo"
      },
      "outputs": [],
      "source": [
        "# Store results\n",
        "results_summary = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d07a631dc63d4077997a51dd1bd68d13",
            "0254a8671df14819bdccc13c636da06e",
            "930072e2d391409aaeb2286c307b97eb",
            "4eba3a91cf6f4c088d57be6fd64d1bb5",
            "ef8c455c0902409fbe6697185b68ff11",
            "22d0732239da44eda6d2300f9f6cc00a",
            "1bb22bd6ddbc4b1f97b408ae410a70ee",
            "f5637b25b569418f857ed80efa91fd6d",
            "d519d617b7104e51bf6ea1dec1191d3e",
            "c128edfc0fb649e2a617895583660b19",
            "9f8eb54e4ca0441fbb3655acd5a20312"
          ]
        },
        "collapsed": true,
        "id": "kD1HFhJsmSt9",
        "outputId": "6384ca79-2ca8-4ecc-c68c-29224886dc72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 1: FULL FINE-TUNING WITH 25.0% TRAINING DATASET\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Training with 25.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 32579 training samples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d07a631dc63d4077997a51dd1bd68d13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/32579 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1941336186.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "[codecarbon WARNING @ 03:20:12] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:20:12] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:20:12] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:20:13] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:20:13] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:20:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:20:13] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:20:13] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:20:13] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:20:13] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:20:13] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:20:13]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:20:13]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:20:13]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:20:13]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:20:13]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:20:13]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:20:13]   GPU count: 1\n",
            "[codecarbon INFO @ 03:20:13]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:20:13] Emissions data (if any) will be saved to file /content/results_distilbert_25pct/emissions.csv\n",
            "[codecarbon WARNING @ 03:20:13] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:20:13] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:20:13] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:20:15] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:20:15] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:20:15] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:20:15] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:20:15] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:20:15] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:20:15] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:20:15] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:20:15]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:20:15]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:20:15]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:20:15]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:20:15]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:20:15]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:20:15]   GPU count: 1\n",
            "[codecarbon INFO @ 03:20:15]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:20:15] Emissions data (if any) will be saved to file /content/results_distilbert_25pct/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏋️ Training model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdikshaph07\u001b[0m (\u001b[33mdikshaph07-rutgers-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251201_032020-khgxf3fk</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface/runs/khgxf3fk' target=\"_blank\">firm-flower-19</a></strong> to <a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface' target=\"_blank\">https://wandb.ai/dikshaph07-rutgers-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dikshaph07-rutgers-university/huggingface/runs/khgxf3fk' target=\"_blank\">https://wandb.ai/dikshaph07-rutgers-university/huggingface/runs/khgxf3fk</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4102' max='4102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4102/4102 02:49, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.278700</td>\n",
              "      <td>1.740836</td>\n",
              "      <td>0.388248</td>\n",
              "      <td>0.453493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.921000</td>\n",
              "      <td>1.985141</td>\n",
              "      <td>0.388083</td>\n",
              "      <td>0.467055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 03:20:30] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:20:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:20:30] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:20:30] Energy consumed for all GPUs : 0.000514 kWh. Total GPU Power : 123.21456454482632 W\n",
            "[codecarbon INFO @ 03:20:30] 0.000849 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:20:37] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:20:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:20:37] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:20:37] Energy consumed for all GPUs : 0.000865 kWh. Total GPU Power : 207.5472413139655 W\n",
            "[codecarbon INFO @ 03:20:37] 0.001201 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:20:45] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:20:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:20:45] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:20:45] Energy consumed for all GPUs : 0.001452 kWh. Total GPU Power : 225.29383683384808 W\n",
            "[codecarbon INFO @ 03:20:45] 0.002123 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:20:52] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:20:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:20:52] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:20:52] Energy consumed for all GPUs : 0.001805 kWh. Total GPU Power : 225.56668770283878 W\n",
            "[codecarbon INFO @ 03:20:52] 0.002475 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:00] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:00] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:21:00] Energy consumed for all GPUs : 0.002400 kWh. Total GPU Power : 227.54963762749986 W\n",
            "[codecarbon INFO @ 03:21:00] 0.003406 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:07] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:07] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:21:07] Energy consumed for all GPUs : 0.002745 kWh. Total GPU Power : 225.82436321596217 W\n",
            "[codecarbon INFO @ 03:21:07] 0.003751 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:15] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:15] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:21:15] Energy consumed for all GPUs : 0.003337 kWh. Total GPU Power : 224.83604882976826 W\n",
            "[codecarbon INFO @ 03:21:15] 0.004678 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:22] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:22] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:21:22] Energy consumed for all GPUs : 0.003703 kWh. Total GPU Power : 229.95084439378596 W\n",
            "[codecarbon INFO @ 03:21:22] 0.005045 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:30] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:30] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:21:30] Energy consumed for all GPUs : 0.004304 kWh. Total GPU Power : 232.29865964006774 W\n",
            "[codecarbon INFO @ 03:21:30] 0.005981 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:37] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:37] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:21:37] Energy consumed for all GPUs : 0.004643 kWh. Total GPU Power : 225.55812213569033 W\n",
            "[codecarbon INFO @ 03:21:37] 0.006319 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:45] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:45] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:21:45] Energy consumed for all GPUs : 0.005132 kWh. Total GPU Power : 198.6934709316046 W\n",
            "[codecarbon INFO @ 03:21:45] 0.007144 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:21:52] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:21:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:21:52] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:21:52] Energy consumed for all GPUs : 0.005408 kWh. Total GPU Power : 183.67262587804865 W\n",
            "[codecarbon INFO @ 03:21:52] 0.007420 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:00] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:00] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:22:00] Energy consumed for all GPUs : 0.006005 kWh. Total GPU Power : 209.60293824189404 W\n",
            "[codecarbon INFO @ 03:22:00] 0.008352 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:07] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:07] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:22:07] Energy consumed for all GPUs : 0.006365 kWh. Total GPU Power : 229.6473565572473 W\n",
            "[codecarbon INFO @ 03:22:07] 0.008712 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:15] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:15] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:15] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:22:15] Energy consumed for all GPUs : 0.006962 kWh. Total GPU Power : 229.81181437987829 W\n",
            "[codecarbon INFO @ 03:22:15] 0.009644 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:15] 0.021506 g.CO2eq/s mean an estimation of 678.2256264165585 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:22:22] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:22] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:22:22] Energy consumed for all GPUs : 0.007330 kWh. Total GPU Power : 231.8516364197182 W\n",
            "[codecarbon INFO @ 03:22:22] 0.010013 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:22] 0.022328 g.CO2eq/s mean an estimation of 704.1358993641811 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:22:30] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:30] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:30] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:22:30] Energy consumed for all GPUs : 0.007932 kWh. Total GPU Power : 232.63360547397784 W\n",
            "[codecarbon INFO @ 03:22:30] 0.010949 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:37] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:37] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:22:37] Energy consumed for all GPUs : 0.008291 kWh. Total GPU Power : 230.5928631693417 W\n",
            "[codecarbon INFO @ 03:22:37] 0.011309 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:45] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:45] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:45] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:22:45] Energy consumed for all GPUs : 0.008889 kWh. Total GPU Power : 229.84876438630113 W\n",
            "[codecarbon INFO @ 03:22:45] 0.012242 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:22:52] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:22:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:22:52] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:22:52] Energy consumed for all GPUs : 0.009250 kWh. Total GPU Power : 230.3260363876689 W\n",
            "[codecarbon INFO @ 03:22:52] 0.012603 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:23:00] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:23:00] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:23:00] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:23:00] Energy consumed for all GPUs : 0.009850 kWh. Total GPU Power : 230.78174223179855 W\n",
            "[codecarbon INFO @ 03:23:00] 0.013538 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:23:07] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:23:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:23:07] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:23:07] Energy consumed for all GPUs : 0.010117 kWh. Total GPU Power : 208.0557591935042 W\n",
            "[codecarbon INFO @ 03:23:07] 0.013805 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:23:13] Energy consumed for RAM : 0.001803 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:23:13] Delta energy consumed for CPU with constant : 0.000069 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:23:13] Energy consumed for All CPU : 0.002017 kWh\n",
            "[codecarbon INFO @ 03:23:13] Energy consumed for all GPUs : 0.010376 kWh. Total GPU Power : 158.5961648878114 W\n",
            "[codecarbon INFO @ 03:23:13] 0.014196 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:23:13] Energy consumed for RAM : 0.001877 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:23:13] Delta energy consumed for CPU with constant : 0.000153 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:23:13] Energy consumed for All CPU : 0.002100 kWh\n",
            "[codecarbon INFO @ 03:23:13] Energy consumed for all GPUs : 0.010467 kWh. Total GPU Power : 171.35710075170383 W\n",
            "[codecarbon INFO @ 03:23:13] 0.014444 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "📈 FINE-TUNING RESULTS SUMMARY FOR 25.0% DATASET:\n",
            "================================================================================\n",
            "  Training Method: Full Fine-Tuning\n",
            "  Model: DistilBERT\n",
            "\n",
            "🔧 Model Parameters:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 66,364,418\n",
            "  Trainable Percentage: 100.00%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.4671\n",
            "  Exact Match: 0.3881\n",
            "  Eval Loss: 1.9851\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.014444 kWh\n",
            "  CPU Energy: 0.002100 kWh (14.5%)\n",
            "  GPU Energy: 0.010467 kWh (72.5%)\n",
            "  RAM Energy: 0.001877 kWh (13.0%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 211.33 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 291.83 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.003866 kg\n",
            "  Emissions Rate: 0.000021720 kg/s\n",
            "  Duration: 0.05 hours\n",
            "  Training Time (Trainer): 0.05 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: The Netherlands (NLD)\n",
            "  Region: groningen\n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "CPU times: user 3min 44s, sys: 3.64 s, total: 3min 48s\n",
            "Wall time: 3min 33s\n"
          ]
        }
      ],
      "source": [
        "#Considering 25% of data for training the model\n",
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 1: FULL FINE-TUNING WITH 25.0% TRAINING DATASET\")\n",
        "print(\"=\"*80)\n",
        "result1 = run_experiment(\n",
        "        size_fraction=0.25,\n",
        "        train_data=squad[\"train\"],\n",
        "        eval_data=tokenized_validation,\n",
        "        tokenizer=tokenizer,\n",
        "        preprocess_fn=preprocess_function,\n",
        "        compute_metrics_fn=compute_metrics,\n",
        "        model_name=\"distilbert-base-uncased\"\n",
        "    )\n",
        "\n",
        "results_summary.append(result1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6200352379e04dcebfc8f9bc1828a53c",
            "07117a05f70148eca3c2024019cbffbd",
            "48bc3d14d6714126b3ab973383221385",
            "3bd0937be04e4f5896f52b62ac14d894",
            "a1a599fb20184a24bb3a288fa222d054",
            "a22e670f6f984dcf96e3c7d79a0e1a29",
            "032643bf52d6430eb723ded86297447e",
            "aaa5ac3ebc97462db2a81fb2a70b823b",
            "3067bdfae3fe4cfa98bf058f5846ba8c",
            "f9e3f563b817403ea325b612e77d72b3",
            "9c2cc9bc1be4478fb9f7243b08093aa2"
          ]
        },
        "collapsed": true,
        "id": "WKjvgrwCnscn",
        "outputId": "3b4d41b8-6bfa-4a66-b339-922246e97404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 2: FULL FINE-TUNING WITH 50.0% TRAINING DATASET\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Training with 50.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 65159 training samples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6200352379e04dcebfc8f9bc1828a53c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/65159 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1941336186.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "[codecarbon WARNING @ 03:24:03] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:24:03] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:24:03] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:24:04] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:24:04] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:24:04] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:24:04] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:24:04] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:24:04] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:24:04] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:24:04] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:24:04]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:24:04]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:24:04]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:24:04]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:24:04]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:24:04]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:24:04]   GPU count: 1\n",
            "[codecarbon INFO @ 03:24:04]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:24:04] Emissions data (if any) will be saved to file /content/results_distilbert_50pct/emissions.csv\n",
            "[codecarbon WARNING @ 03:24:04] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:24:04] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:24:04] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:24:05] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:24:05] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:24:05] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:24:05] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:24:05] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:24:05] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:24:05] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:24:05] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:24:05]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:24:05]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:24:05]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:24:05]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:24:05]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:24:05]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:24:05]   GPU count: 1\n",
            "[codecarbon INFO @ 03:24:05]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:24:05] Emissions data (if any) will be saved to file /content/results_distilbert_50pct/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏋️ Training model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8224' max='8224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8224/8224 05:14, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.232400</td>\n",
              "      <td>1.466417</td>\n",
              "      <td>0.452283</td>\n",
              "      <td>0.531723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.919500</td>\n",
              "      <td>1.443946</td>\n",
              "      <td>0.491017</td>\n",
              "      <td>0.569492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 03:24:20] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:24:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:24:20] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:24:20] Energy consumed for all GPUs : 0.000916 kWh. Total GPU Power : 219.73905841974874 W\n",
            "[codecarbon INFO @ 03:24:20] 0.001252 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:24:21] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:24:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:24:21] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:24:21] Energy consumed for all GPUs : 0.000936 kWh. Total GPU Power : 224.4718334008609 W\n",
            "[codecarbon INFO @ 03:24:21] 0.001271 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:24:35] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:24:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:24:35] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:24:35] Energy consumed for all GPUs : 0.001876 kWh. Total GPU Power : 230.30562209720392 W\n",
            "[codecarbon INFO @ 03:24:35] 0.002546 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:24:36] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:24:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:24:36] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:24:36] Energy consumed for all GPUs : 0.001903 kWh. Total GPU Power : 232.14134250215002 W\n",
            "[codecarbon INFO @ 03:24:36] 0.002573 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:24:50] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:24:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:24:50] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:24:50] Energy consumed for all GPUs : 0.002846 kWh. Total GPU Power : 232.87211425569564 W\n",
            "[codecarbon INFO @ 03:24:50] 0.003852 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:24:51] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:24:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:24:51] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:24:51] Energy consumed for all GPUs : 0.002866 kWh. Total GPU Power : 231.32615248639377 W\n",
            "[codecarbon INFO @ 03:24:51] 0.003872 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:05] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:05] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:25:05] Energy consumed for all GPUs : 0.003810 kWh. Total GPU Power : 231.43292364719434 W\n",
            "[codecarbon INFO @ 03:25:05] 0.005151 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:06] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:06] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:25:06] Energy consumed for all GPUs : 0.003830 kWh. Total GPU Power : 231.31862821068754 W\n",
            "[codecarbon INFO @ 03:25:06] 0.005171 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:20] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:20] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:25:20] Energy consumed for all GPUs : 0.004771 kWh. Total GPU Power : 230.67168976040134 W\n",
            "[codecarbon INFO @ 03:25:20] 0.006447 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:21] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:21] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:25:21] Energy consumed for all GPUs : 0.004791 kWh. Total GPU Power : 230.59000193939914 W\n",
            "[codecarbon INFO @ 03:25:21] 0.006467 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:35] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:35] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:25:35] Energy consumed for all GPUs : 0.005735 kWh. Total GPU Power : 231.57685627653322 W\n",
            "[codecarbon INFO @ 03:25:35] 0.007747 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:36] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:36] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:25:36] Energy consumed for all GPUs : 0.005762 kWh. Total GPU Power : 233.19978257255275 W\n",
            "[codecarbon INFO @ 03:25:36] 0.007774 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:50] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:50] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:25:50] Energy consumed for all GPUs : 0.006706 kWh. Total GPU Power : 233.0123661319433 W\n",
            "[codecarbon INFO @ 03:25:50] 0.009053 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:25:51] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:25:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:25:51] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:25:51] Energy consumed for all GPUs : 0.006727 kWh. Total GPU Power : 231.54695339126516 W\n",
            "[codecarbon INFO @ 03:25:51] 0.009074 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:05] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:05] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:26:05] Energy consumed for all GPUs : 0.007663 kWh. Total GPU Power : 229.6253597252225 W\n",
            "[codecarbon INFO @ 03:26:05] 0.010346 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:05] 0.023068 g.CO2eq/s mean an estimation of 727.4688651335865 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:26:06] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:06] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:26:06] Energy consumed for all GPUs : 0.007683 kWh. Total GPU Power : 229.36954279595935 W\n",
            "[codecarbon INFO @ 03:26:06] 0.010365 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:06] 0.023112 g.CO2eq/s mean an estimation of 728.8456922182811 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:26:20] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:20] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:26:20] Energy consumed for all GPUs : 0.008616 kWh. Total GPU Power : 228.83887951950067 W\n",
            "[codecarbon INFO @ 03:26:20] 0.011634 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:21] Energy consumed for RAM : 0.001425 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:21] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:26:21] Energy consumed for all GPUs : 0.008636 kWh. Total GPU Power : 228.91272733671585 W\n",
            "[codecarbon INFO @ 03:26:21] 0.011654 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:35] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:35] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:26:35] Energy consumed for all GPUs : 0.009504 kWh. Total GPU Power : 213.0562349495931 W\n",
            "[codecarbon INFO @ 03:26:35] 0.012857 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:36] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:36] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:26:36] Energy consumed for all GPUs : 0.009524 kWh. Total GPU Power : 212.9350359831212 W\n",
            "[codecarbon INFO @ 03:26:36] 0.012877 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:50] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:50] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:26:50] Energy consumed for all GPUs : 0.010323 kWh. Total GPU Power : 196.594311719505 W\n",
            "[codecarbon INFO @ 03:26:50] 0.014011 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:26:51] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:26:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:26:51] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:26:51] Energy consumed for all GPUs : 0.010343 kWh. Total GPU Power : 196.87244691688178 W\n",
            "[codecarbon INFO @ 03:26:51] 0.014032 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:05] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:05] Energy consumed for All CPU : 0.002125 kWh\n",
            "[codecarbon INFO @ 03:27:05] Energy consumed for all GPUs : 0.011275 kWh. Total GPU Power : 228.37942218154592 W\n",
            "[codecarbon INFO @ 03:27:05] 0.015298 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:06] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:06] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:27:06] Energy consumed for all GPUs : 0.011295 kWh. Total GPU Power : 228.38121268085666 W\n",
            "[codecarbon INFO @ 03:27:06] 0.015319 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:20] Energy consumed for RAM : 0.002058 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:20] Energy consumed for All CPU : 0.002302 kWh\n",
            "[codecarbon INFO @ 03:27:20] Energy consumed for all GPUs : 0.012228 kWh. Total GPU Power : 228.90883410118815 W\n",
            "[codecarbon INFO @ 03:27:20] 0.016587 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:21] Energy consumed for RAM : 0.002058 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:21] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:27:21] Energy consumed for all GPUs : 0.012249 kWh. Total GPU Power : 228.969197069323 W\n",
            "[codecarbon INFO @ 03:27:21] 0.016608 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:35] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:35] Energy consumed for All CPU : 0.002479 kWh\n",
            "[codecarbon INFO @ 03:27:35] Energy consumed for all GPUs : 0.013178 kWh. Total GPU Power : 227.98213084693023 W\n",
            "[codecarbon INFO @ 03:27:35] 0.017872 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:36] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:36] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:27:36] Energy consumed for all GPUs : 0.013204 kWh. Total GPU Power : 229.31408692417614 W\n",
            "[codecarbon INFO @ 03:27:36] 0.017899 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:50] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:50] Energy consumed for All CPU : 0.002656 kWh\n",
            "[codecarbon INFO @ 03:27:50] Energy consumed for all GPUs : 0.014136 kWh. Total GPU Power : 229.9636635670922 W\n",
            "[codecarbon INFO @ 03:27:50] 0.019165 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:27:51] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:27:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:27:51] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:27:51] Energy consumed for all GPUs : 0.014156 kWh. Total GPU Power : 228.58512102576861 W\n",
            "[codecarbon INFO @ 03:27:51] 0.019185 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:05] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:05] Energy consumed for All CPU : 0.002833 kWh\n",
            "[codecarbon INFO @ 03:28:05] Energy consumed for all GPUs : 0.015086 kWh. Total GPU Power : 228.2109938727897 W\n",
            "[codecarbon INFO @ 03:28:05] 0.020451 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:05] 0.022535 g.CO2eq/s mean an estimation of 710.676603210852 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:28:06] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:06] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:28:06] Energy consumed for all GPUs : 0.015106 kWh. Total GPU Power : 228.29307574318997 W\n",
            "[codecarbon INFO @ 03:28:06] 0.020471 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:06] 0.022534 g.CO2eq/s mean an estimation of 710.6362788100607 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:28:20] Energy consumed for RAM : 0.002691 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:20] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:20] Energy consumed for All CPU : 0.003010 kWh\n",
            "[codecarbon INFO @ 03:28:20] Energy consumed for all GPUs : 0.016036 kWh. Total GPU Power : 228.05997670394 W\n",
            "[codecarbon INFO @ 03:28:20] 0.021737 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:21] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:21] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 03:28:21] Energy consumed for all GPUs : 0.016057 kWh. Total GPU Power : 228.35526279829114 W\n",
            "[codecarbon INFO @ 03:28:21] 0.021757 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:35] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:35] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:35] Energy consumed for All CPU : 0.003187 kWh\n",
            "[codecarbon INFO @ 03:28:35] Energy consumed for all GPUs : 0.016990 kWh. Total GPU Power : 228.83625141400645 W\n",
            "[codecarbon INFO @ 03:28:35] 0.023025 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:36] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:36] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 03:28:36] Energy consumed for all GPUs : 0.017017 kWh. Total GPU Power : 230.32954695601723 W\n",
            "[codecarbon INFO @ 03:28:36] 0.023051 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:50] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:50] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:50] Energy consumed for All CPU : 0.003364 kWh\n",
            "[codecarbon INFO @ 03:28:50] Energy consumed for all GPUs : 0.017948 kWh. Total GPU Power : 229.98484120093153 W\n",
            "[codecarbon INFO @ 03:28:50] 0.024318 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:28:51] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:28:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:28:51] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 03:28:51] Energy consumed for all GPUs : 0.017967 kWh. Total GPU Power : 228.29302767353337 W\n",
            "[codecarbon INFO @ 03:28:51] 0.024337 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:29:05] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:29:05] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:29:05] Energy consumed for All CPU : 0.003541 kWh\n",
            "[codecarbon INFO @ 03:29:05] Energy consumed for all GPUs : 0.018899 kWh. Total GPU Power : 228.26830028975272 W\n",
            "[codecarbon INFO @ 03:29:05] 0.025605 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:29:06] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:29:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:29:06] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 03:29:06] Energy consumed for all GPUs : 0.018919 kWh. Total GPU Power : 228.50332835155382 W\n",
            "[codecarbon INFO @ 03:29:06] 0.025625 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:29:20] Energy consumed for RAM : 0.003318 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:29:20] Delta energy consumed for CPU with constant : 0.000171 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:29:20] Energy consumed for All CPU : 0.003711 kWh\n",
            "[codecarbon INFO @ 03:29:20] Energy consumed for all GPUs : 0.019621 kWh. Total GPU Power : 174.96012271943957 W\n",
            "[codecarbon INFO @ 03:29:20] 0.026650 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:29:20] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:29:20] Delta energy consumed for CPU with constant : 0.000176 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:29:20] Energy consumed for All CPU : 0.003716 kWh\n",
            "[codecarbon INFO @ 03:29:20] Energy consumed for all GPUs : 0.019627 kWh. Total GPU Power : 175.99272921659116 W\n",
            "[codecarbon INFO @ 03:29:20] 0.026666 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "📈 FINE-TUNING RESULTS SUMMARY FOR 50.0% DATASET:\n",
            "================================================================================\n",
            "  Training Method: Full Fine-Tuning\n",
            "  Model: DistilBERT\n",
            "\n",
            "🔧 Model Parameters:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 66,364,418\n",
            "  Trainable Percentage: 100.00%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.5695\n",
            "  Exact Match: 0.4910\n",
            "  Eval Loss: 1.4439\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.026666 kWh\n",
            "  CPU Energy: 0.003716 kWh (13.9%)\n",
            "  GPU Energy: 0.019627 kWh (73.6%)\n",
            "  RAM Energy: 0.003323 kWh (12.5%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 224.40 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 304.90 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.007136 kg\n",
            "  Emissions Rate: 0.000022660 kg/s\n",
            "  Duration: 0.09 hours\n",
            "  Training Time (Trainer): 0.09 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: The Netherlands (NLD)\n",
            "  Region: groningen\n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "CPU times: user 6min 51s, sys: 3.74 s, total: 6min 55s\n",
            "Wall time: 6min 7s\n"
          ]
        }
      ],
      "source": [
        "#Considering 50% of data for training the model\n",
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 2: FULL FINE-TUNING WITH 50.0% TRAINING DATASET\")\n",
        "print(\"=\"*80)\n",
        "result2 = run_experiment(\n",
        "        size_fraction=0.5,\n",
        "        train_data=squad[\"train\"],\n",
        "        eval_data=tokenized_validation,\n",
        "        tokenizer=tokenizer,\n",
        "        preprocess_fn=preprocess_function,\n",
        "        compute_metrics_fn=compute_metrics,\n",
        "        model_name=\"distilbert-base-uncased\"\n",
        "    )\n",
        "results_summary.append(result2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6f48bcdc82ed4e298ccd40a09d202b46",
            "62031443c96745ee8efffac289035af1",
            "abe7f5e5b1694065b1c2e517e2ae179d",
            "d4fa94ff87fd4defb76852520ea7c318",
            "f981a641d56c42cd92e3ba0c52ea98ba",
            "9254e15c133648cf97b171d34979d9f9",
            "f8822d6585fe44b088d8ae76c9c162fa",
            "ea94bafe0c114e0a9b2fa380e4fbba30",
            "3f1d1f4451b04a7f93535155017fb3f1",
            "025fdbbe3408452480d6983566441eea",
            "adfa979f20234a6eb2308408caeb1e25"
          ]
        },
        "collapsed": true,
        "id": "imZIy0CEn_Pe",
        "outputId": "e8ef07d6-1778-4cea-ef9f-af75568fd072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 3: FULL FINE-TUNING WITH 80.0% TRAINING DATASET\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f48bcdc82ed4e298ccd40a09d202b46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/104255 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1941336186.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "[codecarbon WARNING @ 03:30:34] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:30:34] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:30:34] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:30:35] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:30:35] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:30:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:30:35] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:30:35] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:30:35] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:30:35] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:30:35] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:30:35]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:30:35]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:30:35]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:30:35]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:30:35]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:30:35]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:30:35]   GPU count: 1\n",
            "[codecarbon INFO @ 03:30:35]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:30:35] Emissions data (if any) will be saved to file /content/results_distilbert_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 03:30:35] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:30:35] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:30:35] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:30:36] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:30:36] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:30:36] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:30:36] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:30:36] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:30:36] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:30:36] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:30:36] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:30:36]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:30:36]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:30:36]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:30:36]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:30:36]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:30:36]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:30:36]   GPU count: 1\n",
            "[codecarbon INFO @ 03:30:36]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:30:36] Emissions data (if any) will be saved to file /content/results_distilbert_80pct/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏋️ Training model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.258200</td>\n",
              "      <td>1.220999</td>\n",
              "      <td>0.522416</td>\n",
              "      <td>0.594213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>1.300708</td>\n",
              "      <td>0.530658</td>\n",
              "      <td>0.609658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 03:30:51] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:30:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:30:51] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:30:51] Energy consumed for all GPUs : 0.000911 kWh. Total GPU Power : 218.4722305666519 W\n",
            "[codecarbon INFO @ 03:30:51] 0.001246 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:30:52] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:30:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:30:52] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:30:52] Energy consumed for all GPUs : 0.000937 kWh. Total GPU Power : 224.6698272343695 W\n",
            "[codecarbon INFO @ 03:30:52] 0.001272 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:06] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:06] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:31:06] Energy consumed for all GPUs : 0.001866 kWh. Total GPU Power : 229.29288570139582 W\n",
            "[codecarbon INFO @ 03:31:06] 0.002537 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:07] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:07] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:31:07] Energy consumed for all GPUs : 0.001887 kWh. Total GPU Power : 228.12484285822242 W\n",
            "[codecarbon INFO @ 03:31:07] 0.002558 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:21] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:21] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:31:21] Energy consumed for all GPUs : 0.002830 kWh. Total GPU Power : 231.3678380630598 W\n",
            "[codecarbon INFO @ 03:31:21] 0.003836 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:22] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:22] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:31:22] Energy consumed for all GPUs : 0.002850 kWh. Total GPU Power : 231.1409875772628 W\n",
            "[codecarbon INFO @ 03:31:22] 0.003856 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:36] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:36] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:31:36] Energy consumed for all GPUs : 0.003790 kWh. Total GPU Power : 230.49970055855377 W\n",
            "[codecarbon INFO @ 03:31:36] 0.005131 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:37] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:37] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:31:37] Energy consumed for all GPUs : 0.003816 kWh. Total GPU Power : 231.88398778380676 W\n",
            "[codecarbon INFO @ 03:31:37] 0.005158 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:51] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:51] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:31:51] Energy consumed for all GPUs : 0.004752 kWh. Total GPU Power : 231.04302183854304 W\n",
            "[codecarbon INFO @ 03:31:51] 0.006429 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:31:52] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:31:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:31:52] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:31:52] Energy consumed for all GPUs : 0.004779 kWh. Total GPU Power : 231.1866698624474 W\n",
            "[codecarbon INFO @ 03:31:52] 0.006456 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:06] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:06] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:32:06] Energy consumed for all GPUs : 0.005717 kWh. Total GPU Power : 231.4728484477294 W\n",
            "[codecarbon INFO @ 03:32:06] 0.007728 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:07] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:07] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:32:07] Energy consumed for all GPUs : 0.005737 kWh. Total GPU Power : 229.92303096024082 W\n",
            "[codecarbon INFO @ 03:32:07] 0.007749 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:21] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:21] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:32:21] Energy consumed for all GPUs : 0.006681 kWh. Total GPU Power : 231.57318344756627 W\n",
            "[codecarbon INFO @ 03:32:21] 0.009028 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:22] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:22] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:32:22] Energy consumed for all GPUs : 0.006703 kWh. Total GPU Power : 231.88713956050017 W\n",
            "[codecarbon INFO @ 03:32:22] 0.009050 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:36] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:36] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:32:36] Energy consumed for all GPUs : 0.007645 kWh. Total GPU Power : 231.39761747490616 W\n",
            "[codecarbon INFO @ 03:32:36] 0.010328 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:36] 0.023030 g.CO2eq/s mean an estimation of 726.262018081938 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:32:37] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:37] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:32:37] Energy consumed for all GPUs : 0.007671 kWh. Total GPU Power : 232.57104721690976 W\n",
            "[codecarbon INFO @ 03:32:37] 0.010354 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:37] 0.023088 g.CO2eq/s mean an estimation of 728.0973033083893 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:32:51] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:51] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:32:51] Energy consumed for all GPUs : 0.008604 kWh. Total GPU Power : 230.18256208764765 W\n",
            "[codecarbon INFO @ 03:32:51] 0.011622 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:32:52] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:32:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:32:52] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:32:52] Energy consumed for all GPUs : 0.008631 kWh. Total GPU Power : 230.24776548486759 W\n",
            "[codecarbon INFO @ 03:32:52] 0.011648 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:06] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:06] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:33:06] Energy consumed for all GPUs : 0.009568 kWh. Total GPU Power : 231.35034089056444 W\n",
            "[codecarbon INFO @ 03:33:06] 0.012921 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:07] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:07] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:33:07] Energy consumed for all GPUs : 0.009588 kWh. Total GPU Power : 230.0409853488942 W\n",
            "[codecarbon INFO @ 03:33:07] 0.012941 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:21] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:21] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:33:21] Energy consumed for all GPUs : 0.010522 kWh. Total GPU Power : 229.05795921631955 W\n",
            "[codecarbon INFO @ 03:33:21] 0.014210 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:22] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:22] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:33:22] Energy consumed for all GPUs : 0.010543 kWh. Total GPU Power : 229.0414545228093 W\n",
            "[codecarbon INFO @ 03:33:22] 0.014231 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:36] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:36] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:33:36] Energy consumed for all GPUs : 0.011474 kWh. Total GPU Power : 228.65864513862263 W\n",
            "[codecarbon INFO @ 03:33:36] 0.015498 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:37] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:37] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:33:37] Energy consumed for all GPUs : 0.011501 kWh. Total GPU Power : 230.0112996422402 W\n",
            "[codecarbon INFO @ 03:33:37] 0.015524 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:51] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:51] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:33:51] Energy consumed for all GPUs : 0.012431 kWh. Total GPU Power : 229.5674748641406 W\n",
            "[codecarbon INFO @ 03:33:51] 0.016789 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:33:52] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:33:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:33:52] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:33:52] Energy consumed for all GPUs : 0.012458 kWh. Total GPU Power : 229.78443431095775 W\n",
            "[codecarbon INFO @ 03:33:52] 0.016816 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:06] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:06] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:34:06] Energy consumed for all GPUs : 0.013387 kWh. Total GPU Power : 229.4543481601019 W\n",
            "[codecarbon INFO @ 03:34:06] 0.018081 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:07] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:07] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:34:07] Energy consumed for all GPUs : 0.013407 kWh. Total GPU Power : 227.74530237213872 W\n",
            "[codecarbon INFO @ 03:34:07] 0.018100 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:21] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:21] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:34:21] Energy consumed for all GPUs : 0.014337 kWh. Total GPU Power : 228.24258824220814 W\n",
            "[codecarbon INFO @ 03:34:21] 0.019367 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:22] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:22] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:34:22] Energy consumed for all GPUs : 0.014358 kWh. Total GPU Power : 228.36417302210356 W\n",
            "[codecarbon INFO @ 03:34:22] 0.019387 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:36] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:36] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:34:36] Energy consumed for all GPUs : 0.015189 kWh. Total GPU Power : 204.4884721511634 W\n",
            "[codecarbon INFO @ 03:34:36] 0.020554 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:36] 0.022804 g.CO2eq/s mean an estimation of 719.1356253597396 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:34:37] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:37] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:34:37] Energy consumed for all GPUs : 0.015209 kWh. Total GPU Power : 204.42521366801978 W\n",
            "[codecarbon INFO @ 03:34:37] 0.020573 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:37] 0.022789 g.CO2eq/s mean an estimation of 718.688292546835 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:34:51] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:51] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 03:34:51] Energy consumed for all GPUs : 0.016027 kWh. Total GPU Power : 201.29512582129118 W\n",
            "[codecarbon INFO @ 03:34:51] 0.021727 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:34:52] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:34:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:34:52] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 03:34:52] Energy consumed for all GPUs : 0.016053 kWh. Total GPU Power : 202.5448348911739 W\n",
            "[codecarbon INFO @ 03:34:52] 0.021752 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:06] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:06] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 03:35:06] Energy consumed for all GPUs : 0.016980 kWh. Total GPU Power : 228.55117203572908 W\n",
            "[codecarbon INFO @ 03:35:06] 0.023015 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:07] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:07] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 03:35:07] Energy consumed for all GPUs : 0.016999 kWh. Total GPU Power : 227.2405450434864 W\n",
            "[codecarbon INFO @ 03:35:07] 0.023034 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:21] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:21] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 03:35:21] Energy consumed for all GPUs : 0.017926 kWh. Total GPU Power : 227.1592270006645 W\n",
            "[codecarbon INFO @ 03:35:21] 0.024296 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:22] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:22] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 03:35:22] Energy consumed for all GPUs : 0.017946 kWh. Total GPU Power : 227.39459099705212 W\n",
            "[codecarbon INFO @ 03:35:22] 0.024316 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:36] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:36] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 03:35:36] Energy consumed for all GPUs : 0.018876 kWh. Total GPU Power : 228.15291870468295 W\n",
            "[codecarbon INFO @ 03:35:36] 0.025582 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:37] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:37] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 03:35:37] Energy consumed for all GPUs : 0.018902 kWh. Total GPU Power : 229.45882814043426 W\n",
            "[codecarbon INFO @ 03:35:37] 0.025608 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:51] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:51] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 03:35:51] Energy consumed for all GPUs : 0.019829 kWh. Total GPU Power : 228.77959722266323 W\n",
            "[codecarbon INFO @ 03:35:51] 0.026870 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:35:52] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:35:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:35:52] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 03:35:52] Energy consumed for all GPUs : 0.019850 kWh. Total GPU Power : 227.42804023627724 W\n",
            "[codecarbon INFO @ 03:35:52] 0.026890 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:06] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:06] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 03:36:06] Energy consumed for all GPUs : 0.020773 kWh. Total GPU Power : 226.5400779189148 W\n",
            "[codecarbon INFO @ 03:36:06] 0.028149 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:07] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:07] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 03:36:07] Energy consumed for all GPUs : 0.020794 kWh. Total GPU Power : 226.63604013358187 W\n",
            "[codecarbon INFO @ 03:36:07] 0.028169 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:21] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:21] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 03:36:21] Energy consumed for all GPUs : 0.021720 kWh. Total GPU Power : 227.3898874662341 W\n",
            "[codecarbon INFO @ 03:36:21] 0.029432 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:22] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:22] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 03:36:22] Energy consumed for all GPUs : 0.021740 kWh. Total GPU Power : 227.29863530472622 W\n",
            "[codecarbon INFO @ 03:36:22] 0.029452 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:36] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:36] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 03:36:36] Energy consumed for all GPUs : 0.022672 kWh. Total GPU Power : 228.446722257247 W\n",
            "[codecarbon INFO @ 03:36:36] 0.030719 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:36] 0.022669 g.CO2eq/s mean an estimation of 714.8758351948333 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:36:37] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:37] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 03:36:37] Energy consumed for all GPUs : 0.022698 kWh. Total GPU Power : 229.96702324467705 W\n",
            "[codecarbon INFO @ 03:36:37] 0.030745 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:37] 0.022684 g.CO2eq/s mean an estimation of 715.3521730242185 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:36:51] Energy consumed for RAM : 0.003957 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:51] Energy consumed for All CPU : 0.004426 kWh\n",
            "[codecarbon INFO @ 03:36:51] Energy consumed for all GPUs : 0.023626 kWh. Total GPU Power : 228.89408324473123 W\n",
            "[codecarbon INFO @ 03:36:51] 0.032008 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:36:52] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:36:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:36:52] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 03:36:52] Energy consumed for all GPUs : 0.023646 kWh. Total GPU Power : 227.4271969334683 W\n",
            "[codecarbon INFO @ 03:36:52] 0.032027 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:06] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:06] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 03:37:06] Energy consumed for all GPUs : 0.024574 kWh. Total GPU Power : 227.59328574373887 W\n",
            "[codecarbon INFO @ 03:37:06] 0.033291 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:07] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:07] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 03:37:07] Energy consumed for all GPUs : 0.024594 kWh. Total GPU Power : 227.58304168166694 W\n",
            "[codecarbon INFO @ 03:37:07] 0.033310 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:21] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:21] Energy consumed for All CPU : 0.004780 kWh\n",
            "[codecarbon INFO @ 03:37:21] Energy consumed for all GPUs : 0.025523 kWh. Total GPU Power : 227.80966488913725 W\n",
            "[codecarbon INFO @ 03:37:21] 0.034575 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:22] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:22] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 03:37:22] Energy consumed for all GPUs : 0.025542 kWh. Total GPU Power : 227.7048089808134 W\n",
            "[codecarbon INFO @ 03:37:22] 0.034594 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:36] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:36] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 03:37:36] Energy consumed for all GPUs : 0.026465 kWh. Total GPU Power : 226.22271736103824 W\n",
            "[codecarbon INFO @ 03:37:36] 0.035853 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:37] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:37] Energy consumed for All CPU : 0.004956 kWh\n",
            "[codecarbon INFO @ 03:37:37] Energy consumed for all GPUs : 0.026491 kWh. Total GPU Power : 227.7484100741613 W\n",
            "[codecarbon INFO @ 03:37:37] 0.035878 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:51] Energy consumed for RAM : 0.004590 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:51] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 03:37:51] Energy consumed for all GPUs : 0.027416 kWh. Total GPU Power : 228.2246886621801 W\n",
            "[codecarbon INFO @ 03:37:51] 0.037139 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:37:52] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:37:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:37:52] Energy consumed for All CPU : 0.005133 kWh\n",
            "[codecarbon INFO @ 03:37:52] Energy consumed for all GPUs : 0.027435 kWh. Total GPU Power : 226.68318191227442 W\n",
            "[codecarbon INFO @ 03:37:52] 0.037158 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:06] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:06] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 03:38:06] Energy consumed for all GPUs : 0.028363 kWh. Total GPU Power : 227.46598363613577 W\n",
            "[codecarbon INFO @ 03:38:06] 0.038422 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:07] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:07] Energy consumed for All CPU : 0.005310 kWh\n",
            "[codecarbon INFO @ 03:38:07] Energy consumed for all GPUs : 0.028383 kWh. Total GPU Power : 227.50487774476773 W\n",
            "[codecarbon INFO @ 03:38:07] 0.038441 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:21] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:21] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 03:38:21] Energy consumed for all GPUs : 0.029312 kWh. Total GPU Power : 227.96972587110352 W\n",
            "[codecarbon INFO @ 03:38:21] 0.039706 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:22] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:22] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 03:38:22] Energy consumed for all GPUs : 0.029339 kWh. Total GPU Power : 229.47692223322218 W\n",
            "[codecarbon INFO @ 03:38:22] 0.039732 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:36] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:36] Energy consumed for All CPU : 0.005664 kWh\n",
            "[codecarbon INFO @ 03:38:36] Energy consumed for all GPUs : 0.030241 kWh. Total GPU Power : 222.89509850352252 W\n",
            "[codecarbon INFO @ 03:38:36] 0.040970 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:36] 0.022860 g.CO2eq/s mean an estimation of 720.9249406560477 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:38:37] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:37] Energy consumed for All CPU : 0.005664 kWh\n",
            "[codecarbon INFO @ 03:38:37] Energy consumed for all GPUs : 0.030260 kWh. Total GPU Power : 221.2114749660892 W\n",
            "[codecarbon INFO @ 03:38:37] 0.040989 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:37] 0.022846 g.CO2eq/s mean an estimation of 720.4699158401545 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:38:47] Energy consumed for RAM : 0.005175 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:47] Delta energy consumed for CPU with constant : 0.000123 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:47] Energy consumed for All CPU : 0.005788 kWh\n",
            "[codecarbon INFO @ 03:38:47] Energy consumed for all GPUs : 0.030744 kWh. Total GPU Power : 166.45664011338673 W\n",
            "[codecarbon INFO @ 03:38:47] 0.041707 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:38:47] Energy consumed for RAM : 0.005179 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:38:47] Delta energy consumed for CPU with constant : 0.000129 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:38:47] Energy consumed for All CPU : 0.005793 kWh\n",
            "[codecarbon INFO @ 03:38:47] Energy consumed for all GPUs : 0.030749 kWh. Total GPU Power : 167.77117934712297 W\n",
            "[codecarbon INFO @ 03:38:47] 0.041722 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "\n",
            "📈 FINE-TUNING RESULTS SUMMARY FOR 80.0% DATASET:\n",
            "================================================================================\n",
            "  Training Method: Full Fine-Tuning\n",
            "  Model: DistilBERT\n",
            "\n",
            "🔧 Model Parameters:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 66,364,418\n",
            "  Trainable Percentage: 100.00%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.6097\n",
            "  Exact Match: 0.5307\n",
            "  Eval Loss: 1.3007\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.041722 kWh\n",
            "  CPU Energy: 0.005793 kWh (13.9%)\n",
            "  GPU Energy: 0.030749 kWh (73.7%)\n",
            "  RAM Energy: 0.005179 kWh (12.4%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 225.07 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 305.57 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.011166 kg\n",
            "  Emissions Rate: 0.000022743 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: The Netherlands (NLD)\n",
            "  Region: groningen\n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "CPU times: user 10min 42s, sys: 5.23 s, total: 10min 47s\n",
            "Wall time: 9min 27s\n"
          ]
        }
      ],
      "source": [
        "#Considering 80% of data for training the model\n",
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 3: FULL FINE-TUNING WITH 80.0% TRAINING DATASET\")\n",
        "print(\"=\"*80)\n",
        "result3 = run_experiment(\n",
        "        size_fraction=0.8,\n",
        "        train_data=squad[\"train\"],\n",
        "        eval_data=tokenized_validation,\n",
        "        tokenizer=tokenizer,\n",
        "        preprocess_fn=preprocess_function,\n",
        "        compute_metrics_fn=compute_metrics,\n",
        "        model_name=\"distilbert-base-uncased\"\n",
        "    )\n",
        "results_summary.append(result3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZQ5cC8fqzIb"
      },
      "source": [
        "###STEP 4.1: Results and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivXHD_NMnssg",
        "outputId": "c55b7563-25fe-4acc-bd3f-5f8a3d439fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📊 FINAL RESULTS SUMMARY\n",
            "============================================================\n",
            " training_method model_name  dataset_size%  train_samples  valid_samples  trainable_params  total_params  trainable_percentage  f1_score  exact_match  eval_loss  training_time_hours  emissions_rate_kg_per_s  emissions_kg           timestamp  duration_seconds  duration_hours  energy_consumed_kwh  cpu_energy_kwh  gpu_energy_kwh  ram_energy_kwh  cpu_power_w  gpu_power_w  ram_power_w    country_name country_iso_code    region cloud_provider cloud_region on_cloud                                   os python_version  cpu_count                      cpu_model  gpu_count                 gpu_model  ram_total_size_gb  pue codecarbon_version\n",
            "Full Fine-Tuning DistilBERT             25          32579          12134          66364418      66364418                 100.0  0.467055     0.388083   1.985141             0.049323                 0.000022      0.003866 2025-12-01T03:23:13        177.968649        0.049436             0.014444        0.002100        0.010467        0.001877         42.5   211.326849         38.0 The Netherlands              NLD groningen                                    N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.2.0\n",
            "Full Fine-Tuning DistilBERT             50          65159          12134          66364418      66364418                 100.0  0.569492     0.491017   1.443946             0.087358                 0.000023      0.007136 2025-12-01T03:29:20        314.933694        0.087482             0.026666        0.003716        0.019627        0.003323         42.5   224.395836         38.0 The Netherlands              NLD groningen                                    N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.2.0\n",
            "Full Fine-Tuning DistilBERT             80         104255          12134          66364418      66364418                 100.0  0.609658     0.530658   1.300708             0.136250                 0.000023      0.011166 2025-12-01T03:38:47        490.955780        0.136377             0.041722        0.005793        0.030749        0.005179         42.5   225.069178         38.0 The Netherlands              NLD groningen                                    N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.2.0\n"
          ]
        }
      ],
      "source": [
        "# Create summary DataFrame\n",
        "results_df = pd.DataFrame(results_summary)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "630R99pens8p"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv(\"/content/drive/MyDrive/distilbert_dataset_size_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwRzBhAotdh",
        "outputId": "9b071941-6ca4-46f3-d82b-89b31bb216f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Data loaded successfully!\n",
            "Total experiments: 3\n",
            "\n",
            "Experiments:\n",
            "   train_samples  dataset_size%  f1_score  emissions_kg\n",
            "0          32579             25  0.467055      0.003866\n",
            "1          65159             50  0.569492      0.007136\n",
            "2         104255             80  0.609658      0.011166\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "full_ft_results = pd.read_csv(\"/content/drive/MyDrive/distilbert_dataset_size_results.csv\")\n",
        "\n",
        "print(\"📊 Data loaded successfully!\")\n",
        "print(f\"Total experiments: {len(full_ft_results)}\")\n",
        "print(\"\\nExperiments:\")\n",
        "print(full_ft_results[['train_samples', 'dataset_size%', 'f1_score', 'emissions_kg']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "gRFN8qeNo3OR",
        "outputId": "5a68e106-7f35-4777-fdfe-e831aa42c4eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c8553c1d-2645-4b28-8604-b7c12ef2bacb\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c8553c1d-2645-4b28-8604-b7c12ef2bacb\")) {                    Plotly.newPlot(                        \"c8553c1d-2645-4b28-8604-b7c12ef2bacb\",                        [{\"hovertemplate\":\"\\u003cb\\u003eCPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CPU Energy\",\"x\":[25,50,80],\"y\":[0.0020999958109263,0.0037163989916819,0.0057932926077826],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eGPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#4ECDC4\"},\"name\":\"GPU Energy\",\"x\":[25,50,80],\"y\":[0.010466530873218,0.0196266293124019,0.030749494599576],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eRAM Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#95E1D3\"},\"name\":\"RAM Energy\",\"x\":[25,50,80],\"y\":[0.0018774356415255,0.0033225447178116,0.0051793414472566],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":18},\"text\":\"Energy Consumption Scaling with Dataset Size\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Dataset Size (%)\"}},\"yaxis\":{\"title\":{\"text\":\"Energy Consumption (kWh)\"}},\"barmode\":\"stack\",\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c8553c1d-2645-4b28-8604-b7c12ef2bacb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT 1: Energy Consumption vs Dataset Size (Stacked Area)\n",
        "df_sorted = full_ft_results.sort_values('train_samples')\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    name='CPU Energy',\n",
        "    x=df_sorted['dataset_size%'],\n",
        "    y=df_sorted['cpu_energy_kwh'],\n",
        "    marker_color='#FF6B6B',\n",
        "    hovertemplate='<b>CPU Energy</b><br>%{y:.6f} kWh<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    name='GPU Energy',\n",
        "    x=df_sorted['dataset_size%'],\n",
        "    y=df_sorted['gpu_energy_kwh'],\n",
        "    marker_color='#4ECDC4',\n",
        "    hovertemplate='<b>GPU Energy</b><br>%{y:.6f} kWh<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    name='RAM Energy',\n",
        "    x=df_sorted['dataset_size%'],\n",
        "    y=df_sorted['ram_energy_kwh'],\n",
        "    marker_color='#95E1D3',\n",
        "    hovertemplate='<b>RAM Energy</b><br>%{y:.6f} kWh<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=dict(text=\"Energy Consumption Scaling with Dataset Size\", font=dict(size=18)),\n",
        "    xaxis_title='Dataset Size (%)',\n",
        "    yaxis_title='Energy Consumption (kWh)',\n",
        "    barmode='stack',\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "fig.write_html(\"/content/drive/MyDrive/full_ft_energy_scaling.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "yYHMfPECo3e7",
        "outputId": "904e3eb2-39df-4558-b008-1e95d5b3bc79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e5b4f493-9f49-4ee7-b62b-31b67115f907\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e5b4f493-9f49-4ee7-b62b-31b67115f907\")) {                    Plotly.newPlot(                        \"e5b4f493-9f49-4ee7-b62b-31b67115f907\",                        [{\"hovertemplate\":\"\\u003cb\\u003eF1 Score\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#4ECDC4\",\"width\":3},\"marker\":{\"line\":{\"color\":\"white\",\"width\":2},\"size\":12},\"mode\":\"lines+markers\",\"name\":\"F1 Score\",\"x\":[25,50,80],\"y\":[0.4670549978051946,0.569492261090313,0.6096579615945016],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eExact Match\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#95E1D3\",\"dash\":\"dash\",\"width\":3},\"marker\":{\"size\":10},\"mode\":\"lines+markers\",\"name\":\"Exact Match\",\"x\":[25,50,80],\"y\":[0.3880830723586616,0.4910169770891709,0.5306576561727377],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eCO₂\\u003c\\u002fb\\u003e: %{y:.6f} kg\\u003cbr\\u003eDataset: %{x:.0f}%\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CO₂ Emissions\",\"opacity\":0.6,\"x\":[25,50,80],\"y\":[0.0038655220855204,0.0071362939832657,0.0111657595148054],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Dataset Size (%)\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Performance Score\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"CO₂ Emissions (kg)\"}},\"title\":{\"font\":{\"size\":18},\"text\":\"Performance vs Carbon Emissions by Dataset Size\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e5b4f493-9f49-4ee7-b62b-31b67115f907');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT 2: Performance & Emissions Growth (Dual Y-axis)\n",
        "df_sorted = full_ft_results.sort_values('train_samples')\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# F1 Score line\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted['dataset_size%'],\n",
        "        y=df_sorted['f1_score'],\n",
        "        name='F1 Score',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#4ECDC4', width=3),\n",
        "        marker=dict(size=12, line=dict(width=2, color='white')),\n",
        "        hovertemplate='<b>F1 Score</b>: %{y:.4f}<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# Exact Match line\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted['dataset_size%'],\n",
        "        y=df_sorted['exact_match'],\n",
        "        name='Exact Match',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#95E1D3', width=3, dash='dash'),\n",
        "        marker=dict(size=10),\n",
        "        hovertemplate='<b>Exact Match</b>: %{y:.4f}<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# CO2 Emissions bar\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=df_sorted['dataset_size%'],\n",
        "        y=df_sorted['emissions_kg'],\n",
        "        name='CO₂ Emissions',\n",
        "        marker_color='#FF6B6B',\n",
        "        opacity=0.6,\n",
        "        hovertemplate='<b>CO₂</b>: %{y:.6f} kg<br>Dataset: %{x:.0f}%<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=True\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Dataset Size (%)\")\n",
        "fig.update_yaxes(title_text=\"Performance Score\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"CO₂ Emissions (kg)\", secondary_y=True)\n",
        "\n",
        "fig.update_layout(\n",
        "    title=dict(text=\"Performance vs Carbon Emissions by Dataset Size\", font=dict(size=18)),\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "fig.write_html(\"/content/drive/MyDrive/full_ft_performance_emissions.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZaEO8Qv3o8hl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0V-JV8Oro8zj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4XfW7zCt480"
      },
      "source": [
        "# Training Strategy 2: LoRA (Low-Rank Adaptation) fine-tuning (Model DistilBERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hDRdOCsVuUIr"
      },
      "outputs": [],
      "source": [
        "#Import PEFT for LoRA\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exzVOf5BpGqQ"
      },
      "source": [
        "## STEP 5: Creating And Training LoRA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LvqhQvzvpBt3"
      },
      "outputs": [],
      "source": [
        "def create_lora_model(model_name=\"distilbert-base-uncased\", r=8, lora_alpha=16, lora_dropout=0.1):\n",
        "    # Load base model\n",
        "    base_model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "    # Configure LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        task_type=TaskType.QUESTION_ANS,  # Task type for QA\n",
        "        r=r,                               # Rank of update matrices\n",
        "        lora_alpha=lora_alpha,             # Scaling factor\n",
        "        lora_dropout=lora_dropout,         # Dropout probability\n",
        "        target_modules=[\"q_lin\", \"v_lin\"], # Which layers to apply LoRA to\n",
        "        bias=\"none\",                       # Don't train biases\n",
        "        inference_mode=False,              # Training mode\n",
        "    )\n",
        "\n",
        "    # Apply LoRA to model\n",
        "    lora_model = get_peft_model(base_model, lora_config)\n",
        "\n",
        "    # Print trainable parameters\n",
        "    lora_model.print_trainable_parameters()\n",
        "\n",
        "    return lora_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2D4pyEJ9uUbt"
      },
      "outputs": [],
      "source": [
        "def train_lora_model(tokenized_train, tokenized_eval, tokenizer, compute_metrics_fn,\n",
        "                     size_fraction, lora_rank=8):\n",
        "\n",
        "    # Create LoRA model\n",
        "    print(f\"\\n🔧 Creating LoRA model (rank={lora_rank})...\")\n",
        "    lora_model = create_lora_model(\n",
        "        model_name=\"distilbert-base-uncased\",\n",
        "        r=lora_rank,\n",
        "        lora_alpha=lora_rank * 2,  # Common practice: alpha = 2*r\n",
        "        lora_dropout=0.1\n",
        "    )\n",
        "\n",
        "    # Setup output directory\n",
        "    output_dir = f\"results_distilbert_lora_r{lora_rank}_{int(size_fraction*100)}pct\"\n",
        "\n",
        "    # Training arguments (can use higher learning rate for LoRA)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=3e-4,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=2,\n",
        "        weight_decay=0.01,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        push_to_hub=False,\n",
        "        logging_steps=100,\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=lora_model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        compute_metrics=compute_metrics_fn\n",
        "    )\n",
        "\n",
        "    # Start carbon tracking\n",
        "    tracker = EmissionsTracker(\n",
        "        project_name=f\"DistilBERT_LoRA_r{lora_rank}_{int(size_fraction*100)}pct\",\n",
        "        output_dir=output_dir,\n",
        "        save_to_file=True,\n",
        "        log_level=\"info\"\n",
        "    )\n",
        "    tracker.start()\n",
        "\n",
        "    # Train\n",
        "    print(\"🏋️ Training LoRA model...\")\n",
        "    train_results = trainer.train()\n",
        "\n",
        "    # Stop tracking and get detailed emissions data\n",
        "    emissions_kg = tracker.stop()\n",
        "\n",
        "    # Get full emissions data object\n",
        "    emissions_data = tracker.final_emissions_data\n",
        "\n",
        "    return trainer, train_results, emissions_data, output_dir, lora_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "neFHBVv8pLfq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "F75_XSD6pLs7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El007ewSpM-t"
      },
      "source": [
        "##STEP 6: Evaluating The LoRA Model On Different Rank Sizes\n",
        "\n",
        "> We will be training our model on various ranks from our SQuAD dataset.\n",
        ">\n",
        "> Training Data Rank Variation: [4, 8, 16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YWrdJgkupRD4"
      },
      "outputs": [],
      "source": [
        "def evaluate_and_save_lora(trainer, train_results, emissions_data, output_dir,\n",
        "                           size_fraction, num_samples, lora_model):\n",
        "    \"\"\"Evaluate LoRA model and save results with detailed emissions.\"\"\"\n",
        "    print(\"📊 Evaluating LoRA model...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Count trainable parameters\n",
        "    trainable_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in lora_model.parameters())\n",
        "    trainable_percentage = 100 * trainable_params / total_params\n",
        "\n",
        "    # Extract emissions data from EmissionsData object\n",
        "    result_entry = {\n",
        "        \"training_method\": \"LoRA\",\n",
        "        \"model_name\": \"DistilBERT\",\n",
        "        \"dataset_size%\": int(size_fraction*100),\n",
        "        \"lora_rank\": lora_model.peft_config['default'].r,\n",
        "        \"train_samples\": num_samples,\n",
        "        \"valid_samples\": len(tokenized_validation),\n",
        "        \"trainable_params\": trainable_params,\n",
        "        \"total_params\": total_params,\n",
        "        \"trainable_percentage\": trainable_percentage,\n",
        "\n",
        "        # Performance metrics\n",
        "        \"f1_score\": eval_results[\"eval_f1\"],\n",
        "        \"exact_match\": eval_results[\"eval_exact_match\"],\n",
        "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
        "        \"training_time_hours\": train_results.metrics[\"train_runtime\"] / 3600,\n",
        "\n",
        "        # Emissions data (direct access to EmissionsData attributes)\n",
        "        \"emissions_rate_kg_per_s\": emissions_data.emissions_rate,\n",
        "        \"emissions_kg\": emissions_data.emissions,\n",
        "        \"timestamp\": emissions_data.timestamp,\n",
        "        \"duration_seconds\": emissions_data.duration,\n",
        "        \"duration_hours\": emissions_data.duration / 3600,\n",
        "\n",
        "        # Energy consumption\n",
        "        \"energy_consumed_kwh\": emissions_data.energy_consumed,\n",
        "        \"cpu_energy_kwh\": emissions_data.cpu_energy,\n",
        "        \"gpu_energy_kwh\": emissions_data.gpu_energy,\n",
        "        \"ram_energy_kwh\": emissions_data.ram_energy,\n",
        "\n",
        "        # Power draw\n",
        "        \"cpu_power_w\": emissions_data.cpu_power,\n",
        "        \"gpu_power_w\": emissions_data.gpu_power,\n",
        "        \"ram_power_w\": emissions_data.ram_power,\n",
        "\n",
        "        # Location and system info\n",
        "        \"country_name\": emissions_data.country_name,\n",
        "        \"country_iso_code\": emissions_data.country_iso_code,\n",
        "        \"region\": emissions_data.region,\n",
        "        \"cloud_provider\": emissions_data.cloud_provider,\n",
        "        \"cloud_region\": emissions_data.cloud_region,\n",
        "        \"on_cloud\": emissions_data.on_cloud,\n",
        "\n",
        "        # System specifications\n",
        "        \"os\": emissions_data.os,\n",
        "        \"python_version\": emissions_data.python_version,\n",
        "        \"cpu_count\": emissions_data.cpu_count,\n",
        "        \"cpu_model\": emissions_data.cpu_model,\n",
        "        \"gpu_count\": emissions_data.gpu_count,\n",
        "        \"gpu_model\": emissions_data.gpu_model,\n",
        "        \"ram_total_size_gb\": emissions_data.ram_total_size,\n",
        "\n",
        "        # Additional metrics\n",
        "        \"pue\": emissions_data.pue,  # Power Usage Effectiveness\n",
        "        \"codecarbon_version\": emissions_data.codecarbon_version,\n",
        "    }\n",
        "\n",
        "    # Print detailed summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"📈 LoRA RESULTS SUMMARY (Rank {result_entry['lora_rank']})\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    print(f\"\\n🔧 Model Configuration:\")\n",
        "    print(f\"  Training Method: LoRA\")\n",
        "    print(f\"  LoRA Rank: {result_entry['lora_rank']}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,} ({trainable_percentage:.2f}%)\")\n",
        "    print(f\"  Total Parameters: {total_params:,}\")\n",
        "    print(f\"  Dataset Size: {size_fraction*100}%\")\n",
        "\n",
        "    print(f\"\\n🎯 Performance Metrics:\")\n",
        "    print(f\"  F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"  Exact Match: {eval_results['eval_exact_match']:.4f}\")\n",
        "    print(f\"  Eval Loss: {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\n⚡ Energy Consumption:\")\n",
        "    print(f\"  Total Energy: {emissions_data.energy_consumed:.6f} kWh\")\n",
        "    print(f\"  CPU Energy: {emissions_data.cpu_energy:.6f} kWh ({emissions_data.cpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  GPU Energy: {emissions_data.gpu_energy:.6f} kWh ({emissions_data.gpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "    print(f\"  RAM Energy: {emissions_data.ram_energy:.6f} kWh ({emissions_data.ram_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n🔌 Average Power Draw:\")\n",
        "    print(f\"  CPU Power: {emissions_data.cpu_power:.2f} W\")\n",
        "    print(f\"  GPU Power: {emissions_data.gpu_power:.2f} W\")\n",
        "    print(f\"  RAM Power: {emissions_data.ram_power:.2f} W\")\n",
        "    print(f\"  Total Power: {emissions_data.cpu_power + emissions_data.gpu_power + emissions_data.ram_power:.2f} W\")\n",
        "\n",
        "    print(f\"\\n🌱 Carbon Footprint:\")\n",
        "    print(f\"  Total CO2 Emissions: {emissions_data.emissions:.6f} kg\")\n",
        "    print(f\"  Emissions Rate: {emissions_data.emissions_rate:.9f} kg/s\")\n",
        "    print(f\"  Duration: {emissions_data.duration/3600:.2f} hours\")\n",
        "    print(f\"  Training Time (Trainer): {train_results.metrics['train_runtime']/3600:.2f} hours\")\n",
        "\n",
        "    print(f\"\\n📍 Location & Infrastructure:\")\n",
        "    print(f\"  Country: {emissions_data.country_name} ({emissions_data.country_iso_code})\")\n",
        "    print(f\"  Region: {emissions_data.region}\")\n",
        "    print(f\"  On Cloud: {emissions_data.on_cloud}\")\n",
        "    print(f\"  PUE (Power Usage Effectiveness): {emissions_data.pue}\")\n",
        "\n",
        "    print(f\"\\n💻 System Specifications:\")\n",
        "    print(f\"  OS: {emissions_data.os}\")\n",
        "    print(f\"  CPU: {emissions_data.cpu_model} ({emissions_data.cpu_count} cores)\")\n",
        "    if emissions_data.gpu_count and emissions_data.gpu_model:\n",
        "        print(f\"  GPU: {emissions_data.gpu_model} (Count: {emissions_data.gpu_count})\")\n",
        "    else:\n",
        "        print(f\"  GPU: None detected\")\n",
        "    print(f\"  RAM: {emissions_data.ram_total_size:.2f} GB\")\n",
        "    print(f\"  Python: {emissions_data.python_version}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "\n",
        "    # Save LoRA adapters\n",
        "    lora_model.save_pretrained(f\"{output_dir}/lora_adapters\")\n",
        "    tokenizer.save_pretrained(f\"{output_dir}/lora_adapters\")\n",
        "    print(f\"✅ LoRA adapters saved to {output_dir}/lora_adapters\")\n",
        "\n",
        "    # Clean up\n",
        "    del trainer.model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result_entry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fFLJ0VF2pRP3"
      },
      "outputs": [],
      "source": [
        "def run_lora_experiment(size_fraction, train_data, eval_data, tokenizer, preprocess_fn, compute_metrics_fn, lora_rank):\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🚀 LoRA Training with {size_fraction*100}% of training data\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Step 1: Prepare dataset\n",
        "    tokenized_train, num_samples = prepare_dataset(train_data, size_fraction, preprocess_fn)\n",
        "\n",
        "    # Step 2: Train LoRA model\n",
        "    trainer, train_results, emissions_data, output_dir, lora_model = train_lora_model(\n",
        "        tokenized_train, eval_data, tokenizer, compute_metrics_fn,\n",
        "        size_fraction, lora_rank\n",
        "    )\n",
        "\n",
        "    # Step 3: Evaluate and save\n",
        "    result_entry = evaluate_and_save_lora(trainer, train_results, emissions_data, output_dir, size_fraction, num_samples, lora_model)\n",
        "\n",
        "    return result_entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "A8NIZe_NpRhl"
      },
      "outputs": [],
      "source": [
        "result_lora = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "RAdCCXunpczt",
        "outputId": "5ba66645-1089-421b-fdea-72393a659859"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 1: LoRA with Rank 4\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 LoRA Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n",
            "\n",
            "🔧 Creating LoRA model (rank=4)...\n",
            "trainable params: 75,266 || all params: 66,439,684 || trainable%: 0.1133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2477820024.py:35: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 03:39:04] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:39:04] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:39:04] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:39:05] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:39:05] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:39:05] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:39:05] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:39:05] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:39:05] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:39:05] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:39:05] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:39:05]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:39:05]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:39:05]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:39:05]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:39:05]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:39:05]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:39:05]   GPU count: 1\n",
            "[codecarbon INFO @ 03:39:05]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:39:05] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r4_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 03:39:05] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:39:05] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:39:05] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:39:06] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:39:06] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:39:06] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:39:06] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:39:06] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:39:06] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:39:06] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:39:06] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:39:06]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:39:06]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:39:06]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:39:06]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:39:06]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:39:06]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:39:06]   GPU count: 1\n",
            "[codecarbon INFO @ 03:39:06]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:39:06] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r4_80pct/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏋️ Training LoRA model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:08, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.730200</td>\n",
              "      <td>1.487096</td>\n",
              "      <td>0.408274</td>\n",
              "      <td>0.462559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.566400</td>\n",
              "      <td>1.417748</td>\n",
              "      <td>0.430526</td>\n",
              "      <td>0.493034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 03:39:21] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:39:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:39:21] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:39:21] Energy consumed for all GPUs : 0.000770 kWh. Total GPU Power : 184.6006738769024 W\n",
            "[codecarbon INFO @ 03:39:21] 0.001105 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:39:22] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:39:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:39:22] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:39:22] Energy consumed for all GPUs : 0.000789 kWh. Total GPU Power : 189.35941162223386 W\n",
            "[codecarbon INFO @ 03:39:22] 0.001125 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:39:36] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:39:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:39:36] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:39:36] Energy consumed for all GPUs : 0.001575 kWh. Total GPU Power : 193.26936421735377 W\n",
            "[codecarbon INFO @ 03:39:36] 0.002246 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:39:37] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:39:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:39:37] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:39:37] Energy consumed for all GPUs : 0.001589 kWh. Total GPU Power : 191.96432100513644 W\n",
            "[codecarbon INFO @ 03:39:37] 0.002260 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:39:51] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:39:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:39:51] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:39:51] Energy consumed for all GPUs : 0.002375 kWh. Total GPU Power : 192.15306490386791 W\n",
            "[codecarbon INFO @ 03:39:51] 0.003381 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:39:52] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:39:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:39:52] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:39:52] Energy consumed for all GPUs : 0.002395 kWh. Total GPU Power : 193.50155678256598 W\n",
            "[codecarbon INFO @ 03:39:52] 0.003402 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:06] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:06] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:40:06] Energy consumed for all GPUs : 0.003175 kWh. Total GPU Power : 192.1432908825399 W\n",
            "[codecarbon INFO @ 03:40:06] 0.004517 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:07] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:07] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:40:07] Energy consumed for all GPUs : 0.003196 kWh. Total GPU Power : 192.13970876455286 W\n",
            "[codecarbon INFO @ 03:40:07] 0.004537 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:21] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:21] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:40:21] Energy consumed for all GPUs : 0.003976 kWh. Total GPU Power : 192.30171603908798 W\n",
            "[codecarbon INFO @ 03:40:21] 0.005653 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:22] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:22] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:40:22] Energy consumed for all GPUs : 0.003997 kWh. Total GPU Power : 192.29447173717566 W\n",
            "[codecarbon INFO @ 03:40:22] 0.005673 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:36] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:36] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:40:36] Energy consumed for all GPUs : 0.004783 kWh. Total GPU Power : 193.65618169041667 W\n",
            "[codecarbon INFO @ 03:40:36] 0.006795 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:37] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:37] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:40:37] Energy consumed for all GPUs : 0.004798 kWh. Total GPU Power : 192.26813449941747 W\n",
            "[codecarbon INFO @ 03:40:37] 0.006810 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:51] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:51] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:40:51] Energy consumed for all GPUs : 0.005583 kWh. Total GPU Power : 192.02289573186678 W\n",
            "[codecarbon INFO @ 03:40:51] 0.007930 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:40:52] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:40:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:40:52] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:40:52] Energy consumed for all GPUs : 0.005603 kWh. Total GPU Power : 193.3239214329917 W\n",
            "[codecarbon INFO @ 03:40:52] 0.007950 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:06] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:06] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:41:06] Energy consumed for all GPUs : 0.006379 kWh. Total GPU Power : 190.93802738248854 W\n",
            "[codecarbon INFO @ 03:41:06] 0.009061 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:06] 0.020203 g.CO2eq/s mean an estimation of 637.1334678932496 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:41:07] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:07] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:41:07] Energy consumed for all GPUs : 0.006398 kWh. Total GPU Power : 190.9244197250166 W\n",
            "[codecarbon INFO @ 03:41:07] 0.009081 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:07] 0.020249 g.CO2eq/s mean an estimation of 638.5629403399369 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:41:21] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:21] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:41:21] Energy consumed for all GPUs : 0.007185 kWh. Total GPU Power : 193.5653316053867 W\n",
            "[codecarbon INFO @ 03:41:21] 0.010203 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:22] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:22] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:41:22] Energy consumed for all GPUs : 0.007199 kWh. Total GPU Power : 192.3198856668093 W\n",
            "[codecarbon INFO @ 03:41:22] 0.010217 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:36] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:36] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:41:36] Energy consumed for all GPUs : 0.007985 kWh. Total GPU Power : 192.02298180640008 W\n",
            "[codecarbon INFO @ 03:41:36] 0.011338 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:37] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:37] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:41:37] Energy consumed for all GPUs : 0.008005 kWh. Total GPU Power : 193.3860269059806 W\n",
            "[codecarbon INFO @ 03:41:37] 0.011358 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:51] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:51] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:41:51] Energy consumed for all GPUs : 0.008782 kWh. Total GPU Power : 191.37280240812666 W\n",
            "[codecarbon INFO @ 03:41:51] 0.012470 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:41:52] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:41:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:41:52] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:41:52] Energy consumed for all GPUs : 0.008802 kWh. Total GPU Power : 191.26310515872106 W\n",
            "[codecarbon INFO @ 03:41:52] 0.012490 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:06] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:06] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:42:06] Energy consumed for all GPUs : 0.009590 kWh. Total GPU Power : 193.8254945844549 W\n",
            "[codecarbon INFO @ 03:42:06] 0.013613 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:07] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:07] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:42:07] Energy consumed for all GPUs : 0.009604 kWh. Total GPU Power : 192.60936772603293 W\n",
            "[codecarbon INFO @ 03:42:07] 0.013628 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:21] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:21] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:42:21] Energy consumed for all GPUs : 0.010391 kWh. Total GPU Power : 192.40170746982804 W\n",
            "[codecarbon INFO @ 03:42:21] 0.014749 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:22] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:22] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:42:22] Energy consumed for all GPUs : 0.010411 kWh. Total GPU Power : 193.62325171228002 W\n",
            "[codecarbon INFO @ 03:42:22] 0.014770 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:36] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:36] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:42:36] Energy consumed for all GPUs : 0.011194 kWh. Total GPU Power : 192.92494621318366 W\n",
            "[codecarbon INFO @ 03:42:36] 0.015888 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:37] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:37] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:42:37] Energy consumed for all GPUs : 0.011214 kWh. Total GPU Power : 192.70266778715592 W\n",
            "[codecarbon INFO @ 03:42:37] 0.015908 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:51] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:51] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:42:51] Energy consumed for all GPUs : 0.011994 kWh. Total GPU Power : 191.89937018490897 W\n",
            "[codecarbon INFO @ 03:42:51] 0.017023 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:42:52] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:42:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:42:52] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:42:52] Energy consumed for all GPUs : 0.012014 kWh. Total GPU Power : 191.97921064699545 W\n",
            "[codecarbon INFO @ 03:42:52] 0.017043 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:06] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:06] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:43:06] Energy consumed for all GPUs : 0.012713 kWh. Total GPU Power : 172.60440857186467 W\n",
            "[codecarbon INFO @ 03:43:06] 0.018077 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:06] 0.020106 g.CO2eq/s mean an estimation of 634.0694460269677 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:43:07] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:07] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:43:07] Energy consumed for all GPUs : 0.012723 kWh. Total GPU Power : 170.30517942887684 W\n",
            "[codecarbon INFO @ 03:43:07] 0.018088 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:07] 0.020085 g.CO2eq/s mean an estimation of 633.3849991837617 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:43:21] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:21] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 03:43:21] Energy consumed for all GPUs : 0.013459 kWh. Total GPU Power : 179.01054498193545 W\n",
            "[codecarbon INFO @ 03:43:21] 0.019158 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:22] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:22] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 03:43:22] Energy consumed for all GPUs : 0.013478 kWh. Total GPU Power : 181.37317320556795 W\n",
            "[codecarbon INFO @ 03:43:22] 0.019178 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:36] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:36] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 03:43:36] Energy consumed for all GPUs : 0.014253 kWh. Total GPU Power : 190.84398221281185 W\n",
            "[codecarbon INFO @ 03:43:36] 0.020288 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:37] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:37] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 03:43:37] Energy consumed for all GPUs : 0.014274 kWh. Total GPU Power : 190.78555372187176 W\n",
            "[codecarbon INFO @ 03:43:37] 0.020309 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:51] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:51] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 03:43:51] Energy consumed for all GPUs : 0.015063 kWh. Total GPU Power : 194.24841775238428 W\n",
            "[codecarbon INFO @ 03:43:51] 0.021433 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:43:52] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:43:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:43:52] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 03:43:52] Energy consumed for all GPUs : 0.015077 kWh. Total GPU Power : 192.90402841684156 W\n",
            "[codecarbon INFO @ 03:43:52] 0.021448 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:06] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:06] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 03:44:06] Energy consumed for all GPUs : 0.015866 kWh. Total GPU Power : 192.72079462793525 W\n",
            "[codecarbon INFO @ 03:44:06] 0.022571 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:07] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:07] Energy consumed for All CPU : 0.003541 kWh\n",
            "[codecarbon INFO @ 03:44:07] Energy consumed for all GPUs : 0.015885 kWh. Total GPU Power : 193.94051176746785 W\n",
            "[codecarbon INFO @ 03:44:07] 0.022591 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:21] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:21] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 03:44:21] Energy consumed for all GPUs : 0.016663 kWh. Total GPU Power : 191.41094477771264 W\n",
            "[codecarbon INFO @ 03:44:21] 0.023704 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:22] Energy consumed for RAM : 0.003324 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:22] Energy consumed for All CPU : 0.003718 kWh\n",
            "[codecarbon INFO @ 03:44:22] Energy consumed for all GPUs : 0.016683 kWh. Total GPU Power : 191.5280359469937 W\n",
            "[codecarbon INFO @ 03:44:22] 0.023724 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:36] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:36] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 03:44:36] Energy consumed for all GPUs : 0.017461 kWh. Total GPU Power : 191.63953443307395 W\n",
            "[codecarbon INFO @ 03:44:36] 0.024837 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:37] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:37] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 03:44:37] Energy consumed for all GPUs : 0.017481 kWh. Total GPU Power : 191.7199957741743 W\n",
            "[codecarbon INFO @ 03:44:37] 0.024857 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:51] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:51] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 03:44:51] Energy consumed for all GPUs : 0.018265 kWh. Total GPU Power : 192.84279739712358 W\n",
            "[codecarbon INFO @ 03:44:51] 0.025976 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:44:52] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:44:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:44:52] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 03:44:52] Energy consumed for all GPUs : 0.018279 kWh. Total GPU Power : 191.5719465617799 W\n",
            "[codecarbon INFO @ 03:44:52] 0.025990 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:06] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:06] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 03:45:06] Energy consumed for all GPUs : 0.019060 kWh. Total GPU Power : 190.82296518968536 W\n",
            "[codecarbon INFO @ 03:45:06] 0.027106 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:06] 0.020135 g.CO2eq/s mean an estimation of 634.9692698415591 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:45:07] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:07] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 03:45:07] Energy consumed for all GPUs : 0.019079 kWh. Total GPU Power : 192.1699674415587 W\n",
            "[codecarbon INFO @ 03:45:07] 0.027126 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:07] 0.020156 g.CO2eq/s mean an estimation of 635.6495816464017 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:45:21] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:21] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 03:45:21] Energy consumed for all GPUs : 0.019855 kWh. Total GPU Power : 190.8903999973867 W\n",
            "[codecarbon INFO @ 03:45:21] 0.028237 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:22] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:22] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 03:45:22] Energy consumed for all GPUs : 0.019875 kWh. Total GPU Power : 191.00009376707766 W\n",
            "[codecarbon INFO @ 03:45:22] 0.028257 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:36] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:36] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 03:45:36] Energy consumed for all GPUs : 0.020656 kWh. Total GPU Power : 192.35264006356704 W\n",
            "[codecarbon INFO @ 03:45:36] 0.029373 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:37] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:37] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 03:45:37] Energy consumed for all GPUs : 0.020671 kWh. Total GPU Power : 191.06714253688884 W\n",
            "[codecarbon INFO @ 03:45:37] 0.029388 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:51] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:51] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 03:45:51] Energy consumed for all GPUs : 0.021456 kWh. Total GPU Power : 191.94470187200147 W\n",
            "[codecarbon INFO @ 03:45:51] 0.030508 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:45:52] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:45:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:45:52] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 03:45:52] Energy consumed for all GPUs : 0.021475 kWh. Total GPU Power : 193.1986424388642 W\n",
            "[codecarbon INFO @ 03:45:52] 0.030528 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:06] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:06] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 03:46:06] Energy consumed for all GPUs : 0.022252 kWh. Total GPU Power : 191.00101371933857 W\n",
            "[codecarbon INFO @ 03:46:06] 0.031640 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:07] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:07] Energy consumed for All CPU : 0.004956 kWh\n",
            "[codecarbon INFO @ 03:46:07] Energy consumed for all GPUs : 0.022271 kWh. Total GPU Power : 190.90742174044706 W\n",
            "[codecarbon INFO @ 03:46:07] 0.031659 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:21] Energy consumed for RAM : 0.004590 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:21] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:21] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 03:46:21] Energy consumed for all GPUs : 0.023052 kWh. Total GPU Power : 191.99122751129136 W\n",
            "[codecarbon INFO @ 03:46:21] 0.032775 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:22] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:22] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:22] Energy consumed for All CPU : 0.005133 kWh\n",
            "[codecarbon INFO @ 03:46:22] Energy consumed for all GPUs : 0.023066 kWh. Total GPU Power : 190.94695751449996 W\n",
            "[codecarbon INFO @ 03:46:22] 0.032789 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:36] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:36] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:36] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 03:46:36] Energy consumed for all GPUs : 0.023846 kWh. Total GPU Power : 190.63252886504645 W\n",
            "[codecarbon INFO @ 03:46:36] 0.033904 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:37] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:37] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:37] Energy consumed for All CPU : 0.005310 kWh\n",
            "[codecarbon INFO @ 03:46:37] Energy consumed for all GPUs : 0.023860 kWh. Total GPU Power : 190.61815718866055 W\n",
            "[codecarbon INFO @ 03:46:37] 0.033918 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:51] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:51] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:51] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 03:46:51] Energy consumed for all GPUs : 0.024644 kWh. Total GPU Power : 191.756473086295 W\n",
            "[codecarbon INFO @ 03:46:51] 0.035037 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:46:52] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:46:52] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:46:52] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 03:46:52] Energy consumed for all GPUs : 0.024664 kWh. Total GPU Power : 192.84535574448222 W\n",
            "[codecarbon INFO @ 03:46:52] 0.035057 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:47:06] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:47:06] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:47:06] Energy consumed for All CPU : 0.005664 kWh\n",
            "[codecarbon INFO @ 03:47:06] Energy consumed for all GPUs : 0.025392 kWh. Total GPU Power : 179.57523358624098 W\n",
            "[codecarbon INFO @ 03:47:06] 0.036121 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:47:06] 0.020100 g.CO2eq/s mean an estimation of 633.8796826496593 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:47:07] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:47:07] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:47:07] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 03:47:07] Energy consumed for all GPUs : 0.025407 kWh. Total GPU Power : 178.41008284032313 W\n",
            "[codecarbon INFO @ 03:47:07] 0.036136 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:47:07] 0.020091 g.CO2eq/s mean an estimation of 633.5886998870326 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:47:15] Energy consumed for RAM : 0.005152 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:47:15] Delta energy consumed for CPU with constant : 0.000098 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:47:15] Energy consumed for All CPU : 0.005762 kWh\n",
            "[codecarbon INFO @ 03:47:15] Energy consumed for all GPUs : 0.025759 kWh. Total GPU Power : 153.1271320198638 W\n",
            "[codecarbon INFO @ 03:47:15] 0.036673 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:47:15] Energy consumed for RAM : 0.005156 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:47:15] Delta energy consumed for CPU with constant : 0.000103 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:47:15] Energy consumed for All CPU : 0.005768 kWh\n",
            "[codecarbon INFO @ 03:47:15] Energy consumed for all GPUs : 0.025768 kWh. Total GPU Power : 154.4779026253674 W\n",
            "[codecarbon INFO @ 03:47:15] 0.036692 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating LoRA model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 LoRA RESULTS SUMMARY (Rank 4)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: LoRA\n",
            "  LoRA Rank: 4\n",
            "  Trainable Parameters: 75,266 (0.11%)\n",
            "  Total Parameters: 66,439,684\n",
            "  Dataset Size: 80.0%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.4930\n",
            "  Exact Match: 0.4305\n",
            "  Eval Loss: 1.4177\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.036692 kWh\n",
            "  CPU Energy: 0.005768 kWh (15.7%)\n",
            "  GPU Energy: 0.025768 kWh (70.2%)\n",
            "  RAM Energy: 0.005156 kWh (14.1%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 189.39 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 269.89 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.009820 kg\n",
            "  Emissions Rate: 0.000020088 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: The Netherlands (NLD)\n",
            "  Region: groningen\n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "✅ LoRA adapters saved to results_distilbert_lora_r4_80pct/lora_adapters\n",
            "CPU times: user 8min 21s, sys: 2.14 s, total: 8min 23s\n",
            "Wall time: 8min 25s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 1: LoRA with Rank 4\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_r4 = run_lora_experiment(\n",
        "    size_fraction=0.8,  # 80% of training data\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    lora_rank=4\n",
        ")\n",
        "result_lora.append(result_r4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "MYk1vM8kpdCB",
        "outputId": "20e1a97f-9c79-4057-cd35-b0230b0766c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 2: LoRA with Rank 8\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 LoRA Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n",
            "\n",
            "🔧 Creating LoRA model (rank=8)...\n",
            "trainable params: 148,994 || all params: 66,513,412 || trainable%: 0.2240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2477820024.py:35: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 03:47:29] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:47:29] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:47:29] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:47:31] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:47:31] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:47:31] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:47:31] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:47:31] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:47:31] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:47:31] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:47:31] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:47:31]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:47:31]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:47:31]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:47:31]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:47:31]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:47:31]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:47:31]   GPU count: 1\n",
            "[codecarbon INFO @ 03:47:31]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:47:31] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r8_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 03:47:31] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:47:31] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:47:31] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:47:32] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:47:32] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:47:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:47:32] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:47:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:47:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:47:32] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:47:32] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:47:32]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:47:32]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:47:32]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:47:32]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:47:32]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:47:32]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:47:32]   GPU count: 1\n",
            "[codecarbon INFO @ 03:47:32]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:47:32] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r8_80pct/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏋️ Training LoRA model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:06, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.643300</td>\n",
              "      <td>1.424173</td>\n",
              "      <td>0.423768</td>\n",
              "      <td>0.484082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.459500</td>\n",
              "      <td>1.371498</td>\n",
              "      <td>0.443053</td>\n",
              "      <td>0.512776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 03:47:47] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:47:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:47:47] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:47:47] Energy consumed for all GPUs : 0.000779 kWh. Total GPU Power : 187.00624227949908 W\n",
            "[codecarbon INFO @ 03:47:47] 0.001115 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:47:48] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:47:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:47:48] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:47:48] Energy consumed for all GPUs : 0.000794 kWh. Total GPU Power : 190.49705863434735 W\n",
            "[codecarbon INFO @ 03:47:48] 0.001130 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:02] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:02] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:48:02] Energy consumed for all GPUs : 0.001586 kWh. Total GPU Power : 193.7189530530254 W\n",
            "[codecarbon INFO @ 03:48:02] 0.002257 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:03] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:03] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:48:03] Energy consumed for all GPUs : 0.001602 kWh. Total GPU Power : 193.922857895757 W\n",
            "[codecarbon INFO @ 03:48:03] 0.002273 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:17] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:17] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:48:17] Energy consumed for all GPUs : 0.002390 kWh. Total GPU Power : 192.89316165162927 W\n",
            "[codecarbon INFO @ 03:48:17] 0.003396 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:18] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:18] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:48:18] Energy consumed for all GPUs : 0.002410 kWh. Total GPU Power : 193.9533170644058 W\n",
            "[codecarbon INFO @ 03:48:18] 0.003416 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:32] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:32] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:48:32] Energy consumed for all GPUs : 0.003191 kWh. Total GPU Power : 192.31325438329586 W\n",
            "[codecarbon INFO @ 03:48:32] 0.004533 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:33] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:33] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:48:33] Energy consumed for all GPUs : 0.003212 kWh. Total GPU Power : 192.46004064113677 W\n",
            "[codecarbon INFO @ 03:48:33] 0.004553 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:47] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:47] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:48:47] Energy consumed for all GPUs : 0.004000 kWh. Total GPU Power : 194.2203526738054 W\n",
            "[codecarbon INFO @ 03:48:47] 0.005677 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:48:48] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:48:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:48:48] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:48:48] Energy consumed for all GPUs : 0.004015 kWh. Total GPU Power : 192.9460586135419 W\n",
            "[codecarbon INFO @ 03:48:48] 0.005692 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:02] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:02] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:49:02] Energy consumed for all GPUs : 0.004802 kWh. Total GPU Power : 192.5096488947481 W\n",
            "[codecarbon INFO @ 03:49:02] 0.006814 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:03] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:03] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:49:03] Energy consumed for all GPUs : 0.004817 kWh. Total GPU Power : 192.49452061166562 W\n",
            "[codecarbon INFO @ 03:49:03] 0.006829 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:17] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:17] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:49:17] Energy consumed for all GPUs : 0.005606 kWh. Total GPU Power : 193.00571648960732 W\n",
            "[codecarbon INFO @ 03:49:17] 0.007953 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:18] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:18] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:49:18] Energy consumed for all GPUs : 0.005626 kWh. Total GPU Power : 194.0779605715538 W\n",
            "[codecarbon INFO @ 03:49:18] 0.007973 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:32] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:32] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:49:32] Energy consumed for all GPUs : 0.006415 kWh. Total GPU Power : 194.26858998979282 W\n",
            "[codecarbon INFO @ 03:49:32] 0.009097 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:32] 0.020287 g.CO2eq/s mean an estimation of 639.7685824423745 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:49:33] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:33] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:49:33] Energy consumed for all GPUs : 0.006430 kWh. Total GPU Power : 193.0151328367789 W\n",
            "[codecarbon INFO @ 03:49:33] 0.009113 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:33] 0.020319 g.CO2eq/s mean an estimation of 640.7853886127257 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:49:47] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:47] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:49:47] Energy consumed for all GPUs : 0.007218 kWh. Total GPU Power : 192.7959980314413 W\n",
            "[codecarbon INFO @ 03:49:47] 0.010236 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:49:48] Energy consumed for RAM : 0.001425 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:49:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:49:48] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:49:48] Energy consumed for all GPUs : 0.007233 kWh. Total GPU Power : 192.5891096555042 W\n",
            "[codecarbon INFO @ 03:49:48] 0.010250 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:02] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:02] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:50:02] Energy consumed for all GPUs : 0.008021 kWh. Total GPU Power : 192.8011500220866 W\n",
            "[codecarbon INFO @ 03:50:02] 0.011374 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:03] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:03] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:50:03] Energy consumed for all GPUs : 0.008042 kWh. Total GPU Power : 194.2702803793343 W\n",
            "[codecarbon INFO @ 03:50:03] 0.011395 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:17] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:17] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:50:17] Energy consumed for all GPUs : 0.008823 kWh. Total GPU Power : 192.53905565234962 W\n",
            "[codecarbon INFO @ 03:50:17] 0.012511 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:18] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:18] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:50:18] Energy consumed for all GPUs : 0.008844 kWh. Total GPU Power : 192.5207993348095 W\n",
            "[codecarbon INFO @ 03:50:18] 0.012533 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:32] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:32] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:50:32] Energy consumed for all GPUs : 0.009633 kWh. Total GPU Power : 194.3605896322871 W\n",
            "[codecarbon INFO @ 03:50:32] 0.013656 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:33] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:33] Energy consumed for All CPU : 0.002125 kWh\n",
            "[codecarbon INFO @ 03:50:33] Energy consumed for all GPUs : 0.009648 kWh. Total GPU Power : 193.03421098249945 W\n",
            "[codecarbon INFO @ 03:50:33] 0.013672 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:47] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:47] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:50:47] Energy consumed for all GPUs : 0.010436 kWh. Total GPU Power : 192.62391472222268 W\n",
            "[codecarbon INFO @ 03:50:47] 0.014794 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:50:48] Energy consumed for RAM : 0.002058 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:50:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:50:48] Energy consumed for All CPU : 0.002302 kWh\n",
            "[codecarbon INFO @ 03:50:48] Energy consumed for all GPUs : 0.010456 kWh. Total GPU Power : 193.8255848022368 W\n",
            "[codecarbon INFO @ 03:50:48] 0.014815 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:02] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:02] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:51:02] Energy consumed for all GPUs : 0.011236 kWh. Total GPU Power : 192.14202026712653 W\n",
            "[codecarbon INFO @ 03:51:02] 0.015930 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:03] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:03] Energy consumed for All CPU : 0.002479 kWh\n",
            "[codecarbon INFO @ 03:51:03] Energy consumed for all GPUs : 0.011256 kWh. Total GPU Power : 192.0678247120673 W\n",
            "[codecarbon INFO @ 03:51:03] 0.015950 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:17] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:17] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:51:17] Energy consumed for all GPUs : 0.012042 kWh. Total GPU Power : 193.47361964290263 W\n",
            "[codecarbon INFO @ 03:51:17] 0.017071 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:18] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:18] Energy consumed for All CPU : 0.002656 kWh\n",
            "[codecarbon INFO @ 03:51:18] Energy consumed for all GPUs : 0.012057 kWh. Total GPU Power : 192.3150411084937 W\n",
            "[codecarbon INFO @ 03:51:18] 0.017087 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:32] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:32] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:51:32] Energy consumed for all GPUs : 0.012749 kWh. Total GPU Power : 169.77212067542453 W\n",
            "[codecarbon INFO @ 03:51:32] 0.018114 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:32] 0.020107 g.CO2eq/s mean an estimation of 634.0801081839296 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:51:33] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:33] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:51:33] Energy consumed for all GPUs : 0.012763 kWh. Total GPU Power : 169.58478822437073 W\n",
            "[codecarbon INFO @ 03:51:33] 0.018128 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:33] 0.020104 g.CO2eq/s mean an estimation of 633.9852326096515 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:51:47] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:47] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 03:51:47] Energy consumed for all GPUs : 0.013489 kWh. Total GPU Power : 177.6576558602001 W\n",
            "[codecarbon INFO @ 03:51:47] 0.019189 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:51:48] Energy consumed for RAM : 0.002691 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:51:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:51:48] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 03:51:48] Energy consumed for all GPUs : 0.013510 kWh. Total GPU Power : 179.09517178264758 W\n",
            "[codecarbon INFO @ 03:51:48] 0.019210 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:02] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:02] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 03:52:02] Energy consumed for all GPUs : 0.014293 kWh. Total GPU Power : 193.062484844705 W\n",
            "[codecarbon INFO @ 03:52:02] 0.020328 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:03] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:03] Energy consumed for All CPU : 0.003187 kWh\n",
            "[codecarbon INFO @ 03:52:03] Energy consumed for all GPUs : 0.014314 kWh. Total GPU Power : 192.99836518293577 W\n",
            "[codecarbon INFO @ 03:52:03] 0.020349 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:17] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:17] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 03:52:17] Energy consumed for all GPUs : 0.015096 kWh. Total GPU Power : 192.56678437395195 W\n",
            "[codecarbon INFO @ 03:52:17] 0.021466 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:18] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:18] Energy consumed for All CPU : 0.003364 kWh\n",
            "[codecarbon INFO @ 03:52:18] Energy consumed for all GPUs : 0.015111 kWh. Total GPU Power : 191.32138108707318 W\n",
            "[codecarbon INFO @ 03:52:18] 0.021481 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:32] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:32] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 03:52:32] Energy consumed for all GPUs : 0.015901 kWh. Total GPU Power : 193.28844996013055 W\n",
            "[codecarbon INFO @ 03:52:32] 0.022606 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:33] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:33] Energy consumed for All CPU : 0.003541 kWh\n",
            "[codecarbon INFO @ 03:52:33] Energy consumed for all GPUs : 0.015921 kWh. Total GPU Power : 194.460472278805 W\n",
            "[codecarbon INFO @ 03:52:33] 0.022627 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:47] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:47] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 03:52:47] Energy consumed for all GPUs : 0.016697 kWh. Total GPU Power : 191.19749637451278 W\n",
            "[codecarbon INFO @ 03:52:47] 0.023738 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:52:48] Energy consumed for RAM : 0.003324 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:52:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:52:48] Energy consumed for All CPU : 0.003718 kWh\n",
            "[codecarbon INFO @ 03:52:48] Energy consumed for all GPUs : 0.016717 kWh. Total GPU Power : 191.0959571775196 W\n",
            "[codecarbon INFO @ 03:52:48] 0.023758 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:02] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:02] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 03:53:02] Energy consumed for all GPUs : 0.017501 kWh. Total GPU Power : 193.03411103732824 W\n",
            "[codecarbon INFO @ 03:53:02] 0.024877 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:03] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:03] Energy consumed for All CPU : 0.003895 kWh\n",
            "[codecarbon INFO @ 03:53:03] Energy consumed for all GPUs : 0.017522 kWh. Total GPU Power : 193.39426255512868 W\n",
            "[codecarbon INFO @ 03:53:03] 0.024899 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:17] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:17] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 03:53:17] Energy consumed for all GPUs : 0.018308 kWh. Total GPU Power : 193.76760779515516 W\n",
            "[codecarbon INFO @ 03:53:17] 0.026019 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:18] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:18] Energy consumed for All CPU : 0.004072 kWh\n",
            "[codecarbon INFO @ 03:53:18] Energy consumed for all GPUs : 0.018329 kWh. Total GPU Power : 193.525226499638 W\n",
            "[codecarbon INFO @ 03:53:18] 0.026040 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:32] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:32] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 03:53:32] Energy consumed for all GPUs : 0.019111 kWh. Total GPU Power : 192.87005750549991 W\n",
            "[codecarbon INFO @ 03:53:32] 0.027158 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:32] 0.020169 g.CO2eq/s mean an estimation of 636.0465629378691 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:53:33] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:33] Energy consumed for All CPU : 0.004249 kWh\n",
            "[codecarbon INFO @ 03:53:33] Energy consumed for all GPUs : 0.019131 kWh. Total GPU Power : 192.72302018267234 W\n",
            "[codecarbon INFO @ 03:53:33] 0.027178 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:33] 0.020182 g.CO2eq/s mean an estimation of 636.4606683875795 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:53:47] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:47] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 03:53:47] Energy consumed for all GPUs : 0.019915 kWh. Total GPU Power : 192.83469941144367 W\n",
            "[codecarbon INFO @ 03:53:47] 0.028296 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:53:48] Energy consumed for RAM : 0.003957 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:53:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:53:48] Energy consumed for All CPU : 0.004426 kWh\n",
            "[codecarbon INFO @ 03:53:48] Energy consumed for all GPUs : 0.019934 kWh. Total GPU Power : 192.75742131610434 W\n",
            "[codecarbon INFO @ 03:53:48] 0.028317 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:02] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:02] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 03:54:02] Energy consumed for all GPUs : 0.020720 kWh. Total GPU Power : 193.3088709729065 W\n",
            "[codecarbon INFO @ 03:54:02] 0.029437 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:03] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:03] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 03:54:03] Energy consumed for all GPUs : 0.020734 kWh. Total GPU Power : 191.94292963202508 W\n",
            "[codecarbon INFO @ 03:54:03] 0.029451 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:17] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:17] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 03:54:17] Energy consumed for all GPUs : 0.021516 kWh. Total GPU Power : 191.04515017566175 W\n",
            "[codecarbon INFO @ 03:54:17] 0.030568 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:18] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:18] Energy consumed for All CPU : 0.004780 kWh\n",
            "[codecarbon INFO @ 03:54:18] Energy consumed for all GPUs : 0.021535 kWh. Total GPU Power : 192.40754262336299 W\n",
            "[codecarbon INFO @ 03:54:18] 0.030588 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:32] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:32] Energy consumed for All CPU : 0.004956 kWh\n",
            "[codecarbon INFO @ 03:54:32] Energy consumed for all GPUs : 0.022316 kWh. Total GPU Power : 191.991150566143 W\n",
            "[codecarbon INFO @ 03:54:32] 0.031703 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:33] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:33] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 03:54:33] Energy consumed for all GPUs : 0.022335 kWh. Total GPU Power : 192.00791742779538 W\n",
            "[codecarbon INFO @ 03:54:33] 0.031723 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:47] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:47] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:47] Energy consumed for All CPU : 0.005133 kWh\n",
            "[codecarbon INFO @ 03:54:47] Energy consumed for all GPUs : 0.023122 kWh. Total GPU Power : 193.5063589368887 W\n",
            "[codecarbon INFO @ 03:54:47] 0.032844 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:54:48] Energy consumed for RAM : 0.004590 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:54:48] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:54:48] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 03:54:48] Energy consumed for all GPUs : 0.023137 kWh. Total GPU Power : 192.347477030736 W\n",
            "[codecarbon INFO @ 03:54:48] 0.032860 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:02] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:02] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:02] Energy consumed for All CPU : 0.005310 kWh\n",
            "[codecarbon INFO @ 03:55:02] Energy consumed for all GPUs : 0.023923 kWh. Total GPU Power : 192.35435134934954 W\n",
            "[codecarbon INFO @ 03:55:02] 0.033981 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:03] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:03] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:03] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 03:55:03] Energy consumed for all GPUs : 0.023943 kWh. Total GPU Power : 193.54416168368806 W\n",
            "[codecarbon INFO @ 03:55:03] 0.034002 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:17] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:17] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:17] Energy consumed for All CPU : 0.005487 kWh\n",
            "[codecarbon INFO @ 03:55:17] Energy consumed for all GPUs : 0.024722 kWh. Total GPU Power : 191.8665244564323 W\n",
            "[codecarbon INFO @ 03:55:17] 0.035115 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:18] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:18] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:18] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 03:55:18] Energy consumed for all GPUs : 0.024743 kWh. Total GPU Power : 191.89393201744417 W\n",
            "[codecarbon INFO @ 03:55:18] 0.035137 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:32] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:32] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:32] Energy consumed for All CPU : 0.005664 kWh\n",
            "[codecarbon INFO @ 03:55:32] Energy consumed for all GPUs : 0.025464 kWh. Total GPU Power : 178.03156389873627 W\n",
            "[codecarbon INFO @ 03:55:32] 0.036193 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:32] 0.020148 g.CO2eq/s mean an estimation of 635.377113628344 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:55:33] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:33] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:33] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 03:55:33] Energy consumed for all GPUs : 0.025478 kWh. Total GPU Power : 176.6356189359187 W\n",
            "[codecarbon INFO @ 03:55:33] 0.036208 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:33] 0.020134 g.CO2eq/s mean an estimation of 634.9350334705082 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:55:39] Energy consumed for RAM : 0.005137 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:39] Delta energy consumed for CPU with constant : 0.000081 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:39] Energy consumed for All CPU : 0.005746 kWh\n",
            "[codecarbon INFO @ 03:55:39] Energy consumed for all GPUs : 0.025767 kWh. Total GPU Power : 150.84254089430303 W\n",
            "[codecarbon INFO @ 03:55:39] 0.036650 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:55:39] Energy consumed for RAM : 0.005142 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:55:39] Delta energy consumed for CPU with constant : 0.000087 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:55:39] Energy consumed for All CPU : 0.005752 kWh\n",
            "[codecarbon INFO @ 03:55:40] Energy consumed for all GPUs : 0.025774 kWh. Total GPU Power : 150.83726324912521 W\n",
            "[codecarbon INFO @ 03:55:40] 0.036667 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating LoRA model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 LoRA RESULTS SUMMARY (Rank 8)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: LoRA\n",
            "  LoRA Rank: 8\n",
            "  Trainable Parameters: 148,994 (0.22%)\n",
            "  Total Parameters: 66,513,412\n",
            "  Dataset Size: 80.0%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.5128\n",
            "  Exact Match: 0.4431\n",
            "  Eval Loss: 1.3715\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.036667 kWh\n",
            "  CPU Energy: 0.005752 kWh (15.7%)\n",
            "  GPU Energy: 0.025774 kWh (70.3%)\n",
            "  RAM Energy: 0.005142 kWh (14.0%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 189.81 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 270.31 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.009813 kg\n",
            "  Emissions Rate: 0.000020132 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: The Netherlands (NLD)\n",
            "  Region: groningen\n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "✅ LoRA adapters saved to results_distilbert_lora_r8_80pct/lora_adapters\n",
            "CPU times: user 8min 19s, sys: 2.05 s, total: 8min 21s\n",
            "Wall time: 8min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 2: LoRA with Rank 8\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_r8 = run_lora_experiment(\n",
        "    size_fraction=0.8,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    lora_rank=8\n",
        ")\n",
        "result_lora.append(result_r8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "LMG3E0GHpdPV",
        "outputId": "e6b086f5-c7fc-4c40-9f4e-d901032baccc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 3: LoRA with Rank 16\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 LoRA Training with 80.0% of training data\n",
            "============================================================\n",
            "🔄 Preprocessing 104255 training samples...\n",
            "\n",
            "🔧 Creating LoRA model (rank=16)...\n",
            "trainable params: 296,450 || all params: 66,660,868 || trainable%: 0.4447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2477820024.py:35: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 03:55:54] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:55:54] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:55:54] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:55:55] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:55:55] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:55:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:55:55] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:55:55] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:55:55] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:55:55] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:55:55] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:55:55]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:55:55]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:55:55]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:55:55]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:55:55]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:55:55]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:55:55]   GPU count: 1\n",
            "[codecarbon INFO @ 03:55:55]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:55:55] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r16_80pct/emissions.csv\n",
            "[codecarbon WARNING @ 03:55:55] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 03:55:55] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 03:55:55] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 03:55:56] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 03:55:56] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 03:55:56] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 03:55:56] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 03:55:56] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 03:55:56] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 03:55:56] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 03:55:56] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 03:55:56]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 03:55:56]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 03:55:56]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 03:55:56]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 03:55:56]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 03:55:56]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 03:55:56]   GPU count: 1\n",
            "[codecarbon INFO @ 03:55:56]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 03:55:56] Emissions data (if any) will be saved to file /content/results_distilbert_lora_r16_80pct/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏋️ Training LoRA model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13184' max='13184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13184/13184 08:09, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.562000</td>\n",
              "      <td>1.345946</td>\n",
              "      <td>0.459206</td>\n",
              "      <td>0.522682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.368900</td>\n",
              "      <td>1.309249</td>\n",
              "      <td>0.476183</td>\n",
              "      <td>0.545845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 03:56:11] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:11] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:56:11] Energy consumed for all GPUs : 0.000772 kWh. Total GPU Power : 185.20461018538904 W\n",
            "[codecarbon INFO @ 03:56:11] 0.001107 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:56:12] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:12] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 03:56:12] Energy consumed for all GPUs : 0.000792 kWh. Total GPU Power : 189.94245020067257 W\n",
            "[codecarbon INFO @ 03:56:12] 0.001127 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:56:26] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:26] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:56:26] Energy consumed for all GPUs : 0.001580 kWh. Total GPU Power : 193.79234230904706 W\n",
            "[codecarbon INFO @ 03:56:26] 0.002250 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:56:27] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:27] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 03:56:27] Energy consumed for all GPUs : 0.001595 kWh. Total GPU Power : 192.76256886853977 W\n",
            "[codecarbon INFO @ 03:56:27] 0.002266 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:56:41] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:41] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:56:41] Energy consumed for all GPUs : 0.002379 kWh. Total GPU Power : 192.09701906588143 W\n",
            "[codecarbon INFO @ 03:56:41] 0.003385 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:56:42] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:42] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 03:56:42] Energy consumed for all GPUs : 0.002399 kWh. Total GPU Power : 193.1473874318551 W\n",
            "[codecarbon INFO @ 03:56:42] 0.003405 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:56:56] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:56] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:56:56] Energy consumed for all GPUs : 0.003172 kWh. Total GPU Power : 190.15595101833716 W\n",
            "[codecarbon INFO @ 03:56:56] 0.004513 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:56:57] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:56:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:56:57] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 03:56:57] Energy consumed for all GPUs : 0.003191 kWh. Total GPU Power : 190.21714496667153 W\n",
            "[codecarbon INFO @ 03:56:57] 0.004532 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:11] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:11] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:57:11] Energy consumed for all GPUs : 0.003981 kWh. Total GPU Power : 194.13004174809626 W\n",
            "[codecarbon INFO @ 03:57:11] 0.005657 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:12] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:12] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 03:57:12] Energy consumed for all GPUs : 0.003995 kWh. Total GPU Power : 192.78001346803467 W\n",
            "[codecarbon INFO @ 03:57:12] 0.005671 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:26] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:26] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:57:26] Energy consumed for all GPUs : 0.004779 kWh. Total GPU Power : 191.74268684272693 W\n",
            "[codecarbon INFO @ 03:57:26] 0.006791 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:27] Energy consumed for RAM : 0.000949 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:27] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 03:57:27] Energy consumed for all GPUs : 0.004794 kWh. Total GPU Power : 191.94406537294958 W\n",
            "[codecarbon INFO @ 03:57:27] 0.006806 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:41] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:41] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:57:41] Energy consumed for all GPUs : 0.005575 kWh. Total GPU Power : 190.9953456836659 W\n",
            "[codecarbon INFO @ 03:57:41] 0.007922 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:42] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:42] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 03:57:42] Energy consumed for all GPUs : 0.005595 kWh. Total GPU Power : 192.24960824034727 W\n",
            "[codecarbon INFO @ 03:57:42] 0.007942 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:56] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:56] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:57:56] Energy consumed for all GPUs : 0.006377 kWh. Total GPU Power : 192.5882597759534 W\n",
            "[codecarbon INFO @ 03:57:56] 0.009060 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:56] 0.020201 g.CO2eq/s mean an estimation of 637.0448918517687 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:57:57] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:57:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:57:57] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 03:57:57] Energy consumed for all GPUs : 0.006392 kWh. Total GPU Power : 191.29617395446027 W\n",
            "[codecarbon INFO @ 03:57:57] 0.009074 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:57:57] 0.020233 g.CO2eq/s mean an estimation of 638.082916939813 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:58:11] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:11] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:58:11] Energy consumed for all GPUs : 0.007177 kWh. Total GPU Power : 191.9245958829713 W\n",
            "[codecarbon INFO @ 03:58:11] 0.010194 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:58:12] Energy consumed for RAM : 0.001424 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:12] Energy consumed for All CPU : 0.001593 kWh\n",
            "[codecarbon INFO @ 03:58:12] Energy consumed for all GPUs : 0.007191 kWh. Total GPU Power : 191.80587664617133 W\n",
            "[codecarbon INFO @ 03:58:12] 0.010208 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:58:26] Energy consumed for RAM : 0.001583 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:26] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:58:26] Energy consumed for all GPUs : 0.007972 kWh. Total GPU Power : 190.9600918832931 W\n",
            "[codecarbon INFO @ 03:58:26] 0.011325 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:58:27] Energy consumed for RAM : 0.001582 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:27] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 03:58:27] Energy consumed for all GPUs : 0.007992 kWh. Total GPU Power : 192.2336192441422 W\n",
            "[codecarbon INFO @ 03:58:27] 0.011344 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:58:41] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:41] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:58:41] Energy consumed for all GPUs : 0.008767 kWh. Total GPU Power : 190.64441722143792 W\n",
            "[codecarbon INFO @ 03:58:41] 0.012455 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:58:42] Energy consumed for RAM : 0.001741 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:42] Energy consumed for All CPU : 0.001947 kWh\n",
            "[codecarbon INFO @ 03:58:42] Energy consumed for all GPUs : 0.008787 kWh. Total GPU Power : 190.78959784100698 W\n",
            "[codecarbon INFO @ 03:58:42] 0.012474 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:58:56] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:56] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:58:56] Energy consumed for all GPUs : 0.009573 kWh. Total GPU Power : 193.5593815984334 W\n",
            "[codecarbon INFO @ 03:58:56] 0.013596 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:58:57] Energy consumed for RAM : 0.001899 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:58:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:58:57] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 03:58:57] Energy consumed for all GPUs : 0.009587 kWh. Total GPU Power : 192.19633332761714 W\n",
            "[codecarbon INFO @ 03:58:57] 0.013610 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:11] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:11] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:59:11] Energy consumed for all GPUs : 0.010367 kWh. Total GPU Power : 190.5137971539464 W\n",
            "[codecarbon INFO @ 03:59:11] 0.014725 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:12] Energy consumed for RAM : 0.002057 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:12] Energy consumed for All CPU : 0.002301 kWh\n",
            "[codecarbon INFO @ 03:59:12] Energy consumed for all GPUs : 0.010387 kWh. Total GPU Power : 192.05393225762523 W\n",
            "[codecarbon INFO @ 03:59:12] 0.014745 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:26] Energy consumed for RAM : 0.002216 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:26] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:59:26] Energy consumed for all GPUs : 0.011161 kWh. Total GPU Power : 190.59991085565525 W\n",
            "[codecarbon INFO @ 03:59:26] 0.015854 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:27] Energy consumed for RAM : 0.002215 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:27] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 03:59:27] Energy consumed for all GPUs : 0.011180 kWh. Total GPU Power : 190.50726666992256 W\n",
            "[codecarbon INFO @ 03:59:27] 0.015874 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:41] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:41] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:59:41] Energy consumed for all GPUs : 0.011953 kWh. Total GPU Power : 190.41852363309465 W\n",
            "[codecarbon INFO @ 03:59:41] 0.016982 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:42] Energy consumed for RAM : 0.002374 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:42] Energy consumed for All CPU : 0.002655 kWh\n",
            "[codecarbon INFO @ 03:59:42] Energy consumed for all GPUs : 0.011973 kWh. Total GPU Power : 190.36557230104702 W\n",
            "[codecarbon INFO @ 03:59:42] 0.017002 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:56] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:56] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:59:56] Energy consumed for all GPUs : 0.012670 kWh. Total GPU Power : 172.0688618558984 W\n",
            "[codecarbon INFO @ 03:59:56] 0.018035 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:56] 0.020014 g.CO2eq/s mean an estimation of 631.1567025953508 kg.CO2eq/year\n",
            "[codecarbon INFO @ 03:59:57] Energy consumed for RAM : 0.002532 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 03:59:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 03:59:57] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 03:59:57] Energy consumed for all GPUs : 0.012680 kWh. Total GPU Power : 169.68926703071534 W\n",
            "[codecarbon INFO @ 03:59:57] 0.018044 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 03:59:57] 0.020005 g.CO2eq/s mean an estimation of 630.862808708657 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:00:11] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:11] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 04:00:11] Energy consumed for all GPUs : 0.013392 kWh. Total GPU Power : 173.25139071404018 W\n",
            "[codecarbon INFO @ 04:00:11] 0.019092 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:00:12] Energy consumed for RAM : 0.002690 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:12] Energy consumed for All CPU : 0.003009 kWh\n",
            "[codecarbon INFO @ 04:00:12] Energy consumed for all GPUs : 0.013411 kWh. Total GPU Power : 175.38410495453857 W\n",
            "[codecarbon INFO @ 04:00:12] 0.019111 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:00:26] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:26] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 04:00:26] Energy consumed for all GPUs : 0.014179 kWh. Total GPU Power : 188.85037100625422 W\n",
            "[codecarbon INFO @ 04:00:26] 0.020213 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:00:27] Energy consumed for RAM : 0.002849 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:27] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 04:00:27] Energy consumed for all GPUs : 0.014198 kWh. Total GPU Power : 188.84545814800686 W\n",
            "[codecarbon INFO @ 04:00:27] 0.020232 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:00:41] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:41] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 04:00:41] Energy consumed for all GPUs : 0.014975 kWh. Total GPU Power : 191.10345286620492 W\n",
            "[codecarbon INFO @ 04:00:41] 0.021345 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:00:42] Energy consumed for RAM : 0.003007 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:42] Energy consumed for All CPU : 0.003363 kWh\n",
            "[codecarbon INFO @ 04:00:42] Energy consumed for all GPUs : 0.014989 kWh. Total GPU Power : 189.89313188121216 W\n",
            "[codecarbon INFO @ 04:00:42] 0.021359 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:00:56] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:56] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 04:00:56] Energy consumed for all GPUs : 0.015771 kWh. Total GPU Power : 191.1567292532691 W\n",
            "[codecarbon INFO @ 04:00:56] 0.022477 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:00:57] Energy consumed for RAM : 0.003165 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:00:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:00:57] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 04:00:57] Energy consumed for all GPUs : 0.015786 kWh. Total GPU Power : 191.19907683818752 W\n",
            "[codecarbon INFO @ 04:00:57] 0.022491 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:11] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:11] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 04:01:11] Energy consumed for all GPUs : 0.016570 kWh. Total GPU Power : 191.71939143855616 W\n",
            "[codecarbon INFO @ 04:01:11] 0.023611 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:12] Energy consumed for RAM : 0.003323 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:12] Energy consumed for All CPU : 0.003717 kWh\n",
            "[codecarbon INFO @ 04:01:12] Energy consumed for all GPUs : 0.016590 kWh. Total GPU Power : 193.01579144099315 W\n",
            "[codecarbon INFO @ 04:01:12] 0.023630 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:26] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:26] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 04:01:26] Energy consumed for all GPUs : 0.017365 kWh. Total GPU Power : 190.8061179382998 W\n",
            "[codecarbon INFO @ 04:01:26] 0.024741 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:27] Energy consumed for RAM : 0.003482 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:27] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 04:01:27] Energy consumed for all GPUs : 0.017380 kWh. Total GPU Power : 189.65740193761604 W\n",
            "[codecarbon INFO @ 04:01:27] 0.024756 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:41] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:41] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 04:01:41] Energy consumed for all GPUs : 0.018164 kWh. Total GPU Power : 191.72386328853392 W\n",
            "[codecarbon INFO @ 04:01:41] 0.025875 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:42] Energy consumed for RAM : 0.003640 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:42] Energy consumed for All CPU : 0.004071 kWh\n",
            "[codecarbon INFO @ 04:01:42] Energy consumed for all GPUs : 0.018178 kWh. Total GPU Power : 191.65745666930673 W\n",
            "[codecarbon INFO @ 04:01:42] 0.025889 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:56] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:56] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 04:01:56] Energy consumed for all GPUs : 0.018965 kWh. Total GPU Power : 192.23467517862704 W\n",
            "[codecarbon INFO @ 04:01:56] 0.027011 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:56] 0.020017 g.CO2eq/s mean an estimation of 631.2609681453581 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:01:57] Energy consumed for RAM : 0.003798 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:01:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:01:57] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 04:01:57] Energy consumed for all GPUs : 0.018985 kWh. Total GPU Power : 193.67274336872765 W\n",
            "[codecarbon INFO @ 04:01:57] 0.027031 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:01:57] 0.020040 g.CO2eq/s mean an estimation of 631.98588804943 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:02:11] Energy consumed for RAM : 0.003957 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:11] Energy consumed for All CPU : 0.004426 kWh\n",
            "[codecarbon INFO @ 04:02:11] Energy consumed for all GPUs : 0.019764 kWh. Total GPU Power : 191.7651132836975 W\n",
            "[codecarbon INFO @ 04:02:11] 0.028146 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:02:12] Energy consumed for RAM : 0.003956 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:12] Energy consumed for All CPU : 0.004425 kWh\n",
            "[codecarbon INFO @ 04:02:12] Energy consumed for all GPUs : 0.019784 kWh. Total GPU Power : 191.73861630731258 W\n",
            "[codecarbon INFO @ 04:02:12] 0.028166 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:02:26] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:26] Energy consumed for All CPU : 0.004603 kWh\n",
            "[codecarbon INFO @ 04:02:26] Energy consumed for all GPUs : 0.020565 kWh. Total GPU Power : 192.34884239112242 W\n",
            "[codecarbon INFO @ 04:02:26] 0.029282 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:02:27] Energy consumed for RAM : 0.004115 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:27] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 04:02:27] Energy consumed for all GPUs : 0.020580 kWh. Total GPU Power : 191.1218053781741 W\n",
            "[codecarbon INFO @ 04:02:27] 0.029297 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:02:41] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:41] Energy consumed for All CPU : 0.004780 kWh\n",
            "[codecarbon INFO @ 04:02:41] Energy consumed for all GPUs : 0.021366 kWh. Total GPU Power : 192.24490518838937 W\n",
            "[codecarbon INFO @ 04:02:41] 0.030419 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:02:42] Energy consumed for RAM : 0.004273 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:42] Energy consumed for All CPU : 0.004779 kWh\n",
            "[codecarbon INFO @ 04:02:42] Energy consumed for all GPUs : 0.021386 kWh. Total GPU Power : 193.53827296844338 W\n",
            "[codecarbon INFO @ 04:02:42] 0.030438 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:02:56] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:56] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 04:02:56] Energy consumed for all GPUs : 0.022163 kWh. Total GPU Power : 191.46007564536956 W\n",
            "[codecarbon INFO @ 04:02:56] 0.031551 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:02:57] Energy consumed for RAM : 0.004431 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:02:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:02:57] Energy consumed for All CPU : 0.004957 kWh\n",
            "[codecarbon INFO @ 04:02:57] Energy consumed for all GPUs : 0.022183 kWh. Total GPU Power : 191.12519545429447 W\n",
            "[codecarbon INFO @ 04:02:57] 0.031570 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:11] Energy consumed for RAM : 0.004590 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:11] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:11] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 04:03:11] Energy consumed for all GPUs : 0.022964 kWh. Total GPU Power : 192.1341111092766 W\n",
            "[codecarbon INFO @ 04:03:11] 0.032687 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:12] Energy consumed for RAM : 0.004589 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:12] Energy consumed for All CPU : 0.005134 kWh\n",
            "[codecarbon INFO @ 04:03:12] Energy consumed for all GPUs : 0.022978 kWh. Total GPU Power : 190.95043431604296 W\n",
            "[codecarbon INFO @ 04:03:12] 0.032701 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:26] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:26] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 04:03:26] Energy consumed for all GPUs : 0.023761 kWh. Total GPU Power : 191.31300871540523 W\n",
            "[codecarbon INFO @ 04:03:26] 0.033819 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:27] Energy consumed for RAM : 0.004748 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:27] Energy consumed for All CPU : 0.005311 kWh\n",
            "[codecarbon INFO @ 04:03:27] Energy consumed for all GPUs : 0.023775 kWh. Total GPU Power : 191.3214611989003 W\n",
            "[codecarbon INFO @ 04:03:27] 0.033834 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:41] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:41] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:41] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 04:03:41] Energy consumed for all GPUs : 0.024551 kWh. Total GPU Power : 189.79237127615542 W\n",
            "[codecarbon INFO @ 04:03:41] 0.034945 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:42] Energy consumed for RAM : 0.004906 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:42] Energy consumed for All CPU : 0.005488 kWh\n",
            "[codecarbon INFO @ 04:03:42] Energy consumed for all GPUs : 0.024571 kWh. Total GPU Power : 190.92491491712732 W\n",
            "[codecarbon INFO @ 04:03:42] 0.034964 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:56] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:56] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:56] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 04:03:56] Energy consumed for all GPUs : 0.025295 kWh. Total GPU Power : 178.60721987129094 W\n",
            "[codecarbon INFO @ 04:03:56] 0.036024 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:56] 0.020099 g.CO2eq/s mean an estimation of 633.8458225109905 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:03:57] Energy consumed for RAM : 0.005064 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:03:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:03:57] Energy consumed for All CPU : 0.005665 kWh\n",
            "[codecarbon INFO @ 04:03:57] Energy consumed for all GPUs : 0.025309 kWh. Total GPU Power : 177.34941833037928 W\n",
            "[codecarbon INFO @ 04:03:57] 0.036038 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:03:57] 0.020084 g.CO2eq/s mean an estimation of 633.3776677148727 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:04:06] Energy consumed for RAM : 0.005161 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:04:06] Delta energy consumed for CPU with constant : 0.000108 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:04:06] Energy consumed for All CPU : 0.005773 kWh\n",
            "[codecarbon INFO @ 04:04:06] Energy consumed for all GPUs : 0.025683 kWh. Total GPU Power : 146.6806140167657 W\n",
            "[codecarbon INFO @ 04:04:06] 0.036616 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:04:06] Energy consumed for RAM : 0.005166 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:04:06] Delta energy consumed for CPU with constant : 0.000114 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:04:06] Energy consumed for All CPU : 0.005778 kWh\n",
            "[codecarbon INFO @ 04:04:06] Energy consumed for all GPUs : 0.025689 kWh. Total GPU Power : 147.2510219480836 W\n",
            "[codecarbon INFO @ 04:04:06] 0.036633 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating LoRA model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 LoRA RESULTS SUMMARY (Rank 16)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: LoRA\n",
            "  LoRA Rank: 16\n",
            "  Trainable Parameters: 296,450 (0.44%)\n",
            "  Total Parameters: 66,660,868\n",
            "  Dataset Size: 80.0%\n",
            "\n",
            "🎯 Performance Metrics:\n",
            "  F1 Score: 0.5458\n",
            "  Exact Match: 0.4762\n",
            "  Eval Loss: 1.3092\n",
            "\n",
            "⚡ Energy Consumption:\n",
            "  Total Energy: 0.036633 kWh\n",
            "  CPU Energy: 0.005778 kWh (15.8%)\n",
            "  GPU Energy: 0.025689 kWh (70.1%)\n",
            "  RAM Energy: 0.005166 kWh (14.1%)\n",
            "\n",
            "🔌 Average Power Draw:\n",
            "  CPU Power: 42.50 W\n",
            "  GPU Power: 188.46 W\n",
            "  RAM Power: 38.00 W\n",
            "  Total Power: 268.96 W\n",
            "\n",
            "🌱 Carbon Footprint:\n",
            "  Total CO2 Emissions: 0.009804 kg\n",
            "  Emissions Rate: 0.000020021 kg/s\n",
            "  Duration: 0.14 hours\n",
            "  Training Time (Trainer): 0.14 hours\n",
            "\n",
            "📍 Location & Infrastructure:\n",
            "  Country: The Netherlands (NLD)\n",
            "  Region: groningen\n",
            "  On Cloud: N\n",
            "  PUE (Power Usage Effectiveness): 1.0\n",
            "\n",
            "💻 System Specifications:\n",
            "  OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  CPU: Intel(R) Xeon(R) CPU @ 2.20GHz (12 cores)\n",
            "  GPU: 1 x NVIDIA A100-SXM4-40GB (Count: 1)\n",
            "  RAM: 83.47 GB\n",
            "  Python: 3.12.12\n",
            "\n",
            "================================================================================\n",
            "✅ LoRA adapters saved to results_distilbert_lora_r16_80pct/lora_adapters\n",
            "CPU times: user 8min 22s, sys: 2.16 s, total: 8min 24s\n",
            "Wall time: 8min 26s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 3: LoRA with Rank 16\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_r16 = run_lora_experiment(\n",
        "    size_fraction=0.8,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    lora_rank=16\n",
        ")\n",
        "result_lora.append(result_r16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dTmKr9Tcp7fg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxtPee6kp7Lu"
      },
      "source": [
        "###STEP 6.1: Results and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cppqVHWWp66A",
        "outputId": "9cfeb425-e980-4d0b-9bbf-d17d731f6756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📊 LoRA RESULTS SUMMARY\n",
            "============================================================\n",
            "training_method model_name  dataset_size%  lora_rank  train_samples  valid_samples  trainable_params  total_params  trainable_percentage  f1_score  exact_match  eval_loss  training_time_hours  emissions_rate_kg_per_s  emissions_kg           timestamp  duration_seconds  duration_hours  energy_consumed_kwh  cpu_energy_kwh  gpu_energy_kwh  ram_energy_kwh  cpu_power_w  gpu_power_w  ram_power_w    country_name country_iso_code    region cloud_provider cloud_region on_cloud                                   os python_version  cpu_count                      cpu_model  gpu_count                 gpu_model  ram_total_size_gb  pue codecarbon_version\n",
            "           LoRA DistilBERT             80          4         104255          12134             75266      66439684              0.113285  0.493034     0.430526   1.417748             0.135649                  0.00002      0.009820 2025-12-01T03:47:15        488.820864        0.135784             0.036692        0.005768        0.025768        0.005156         42.5   189.389829         38.0 The Netherlands              NLD groningen                                    N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.2.0\n",
            "           LoRA DistilBERT             80          8         104255          12134            148994      66513412              0.224006  0.512776     0.443053   1.371498             0.135268                  0.00002      0.009813 2025-12-01T03:55:40        487.425996        0.135396             0.036667        0.005752        0.025774        0.005142         42.5   189.808029         38.0 The Netherlands              NLD groningen                                    N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.2.0\n",
            "           LoRA DistilBERT             80         16         104255          12134            296450      66660868              0.444714  0.545845     0.476183   1.309249             0.135895                  0.00002      0.009804 2025-12-01T04:04:06        489.692924        0.136026             0.036633        0.005778        0.025689        0.005166         42.5   188.459348         38.0 The Netherlands              NLD groningen                                    N Linux-6.6.105+-x86_64-with-glibc2.35        3.12.12         12 Intel(R) Xeon(R) CPU @ 2.20GHz          1 1 x NVIDIA A100-SXM4-40GB          83.473717  1.0              3.2.0\n"
          ]
        }
      ],
      "source": [
        "results_df_lora = pd.DataFrame(result_lora)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 LoRA RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(results_df_lora.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "results_df_lora.to_csv(\"/content/drive/MyDrive/distilbert_lora_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YhfuQ9pqA9P",
        "outputId": "e43bbddd-51d2-4334-9213-9b74b607c490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 LoRA RANK COMPARISON\n",
            "================================================================================\n",
            " lora_rank  trainable_params  trainable_percentage  f1_score  exact_match  emissions_kg  training_time_hours\n",
            "         4             75266              0.113285  0.493034     0.430526      0.009820             0.135649\n",
            "         8            148994              0.224006  0.512776     0.443053      0.009813             0.135268\n",
            "        16            296450              0.444714  0.545845     0.476183      0.009804             0.135895\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📊 LoRA RANK COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(results_df_lora[['lora_rank', 'trainable_params', 'trainable_percentage', 'f1_score', 'exact_match', 'emissions_kg', 'training_time_hours']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "nq2WGsgCqGSZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IV69YyUqD-N",
        "outputId": "002b5f09-04cc-4af9-a3a8-24ff1c68945a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 EFFICIENCY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "LoRA Rank 4:\n",
            "  Trainable Params: 75,266 (0.11%)\n",
            "  vs Rank 8: 0.51x parameters\n",
            "  F1 Score: 0.4930 (-0.0197 vs Rank 8)\n",
            "  Emissions: 0.009820 kg (+0.000007 vs Rank 8)\n",
            "  Training Time: 0.14 hours\n",
            "  Efficiency (F1/kg CO2): 50.21\n",
            "\n",
            "LoRA Rank 8:\n",
            "  Trainable Params: 148,994 (0.22%)\n",
            "  vs Rank 8: 1.00x parameters\n",
            "  F1 Score: 0.5128 (+0.0000 vs Rank 8)\n",
            "  Emissions: 0.009813 kg (+0.000000 vs Rank 8)\n",
            "  Training Time: 0.14 hours\n",
            "  Efficiency (F1/kg CO2): 52.25\n",
            "\n",
            "LoRA Rank 16:\n",
            "  Trainable Params: 296,450 (0.44%)\n",
            "  vs Rank 8: 1.99x parameters\n",
            "  F1 Score: 0.5458 (+0.0331 vs Rank 8)\n",
            "  Emissions: 0.009804 kg (-0.000009 vs Rank 8)\n",
            "  Training Time: 0.14 hours\n",
            "  Efficiency (F1/kg CO2): 55.68\n"
          ]
        }
      ],
      "source": [
        "# Compare efficiency vs performance\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📈 EFFICIENCY ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "baseline = results_df_lora[results_df_lora['lora_rank'] == 8].iloc[0]  # Use rank 8 as baseline\n",
        "\n",
        "for _, row in results_df_lora.iterrows():\n",
        "    rank = row['lora_rank']\n",
        "    params_ratio = row['trainable_params'] / baseline['trainable_params']\n",
        "    f1_diff = row['f1_score'] - baseline['f1_score']\n",
        "    emissions_diff = row['emissions_kg'] - baseline['emissions_kg']\n",
        "\n",
        "    print(f\"\\nLoRA Rank {rank}:\")\n",
        "    print(f\"  Trainable Params: {row['trainable_params']:,} ({row['trainable_percentage']:.2f}%)\")\n",
        "    print(f\"  vs Rank 8: {params_ratio:.2f}x parameters\")\n",
        "    print(f\"  F1 Score: {row['f1_score']:.4f} ({f1_diff:+.4f} vs Rank 8)\")\n",
        "    print(f\"  Emissions: {row['emissions_kg']:.6f} kg ({emissions_diff:+.6f} vs Rank 8)\")\n",
        "    print(f\"  Training Time: {row['training_time_hours']:.2f} hours\")\n",
        "\n",
        "    # Efficiency metric: F1 per kg CO2\n",
        "    efficiency = row['f1_score'] / row['emissions_kg']\n",
        "    print(f\"  Efficiency (F1/kg CO2): {efficiency:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "oJj_TKSrXFI-",
        "outputId": "1535d06a-dc69-4792-f6af-720f455bf1e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"167b5cd6-ba4e-4e78-b4f1-808003a90640\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"167b5cd6-ba4e-4e78-b4f1-808003a90640\")) {                    Plotly.newPlot(                        \"167b5cd6-ba4e-4e78-b4f1-808003a90640\",                        [{\"hovertemplate\":\"\\u003cb\\u003eCPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CPU Energy\",\"x\":[4,8,16],\"y\":[0.005767731442420124,0.005751600932707639,0.0057782989182569465],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eGPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#4ECDC4\"},\"name\":\"GPU Energy\",\"x\":[4,8,16],\"y\":[0.025767531447341993,0.025773661174468,0.025689140273517985],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eRAM Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#95E1D3\"},\"name\":\"RAM Energy\",\"x\":[4,8,16],\"y\":[0.005156494936649995,0.005141963238543905,0.005165974165037229],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":18},\"text\":\"LoRA: Energy Consumption by Rank\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"LoRA Rank\"}},\"yaxis\":{\"title\":{\"text\":\"Energy Consumption (kWh)\"}},\"barmode\":\"stack\",\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('167b5cd6-ba4e-4e78-b4f1-808003a90640');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT 1: LoRA Energy Consumption by Rank\n",
        "df_sorted_lora = results_df_lora.sort_values('lora_rank')\n",
        "\n",
        "fig_lora_energy = go.Figure()\n",
        "\n",
        "fig_lora_energy.add_trace(go.Bar(\n",
        "    name='CPU Energy',\n",
        "    x=df_sorted_lora['lora_rank'],\n",
        "    y=df_sorted_lora['cpu_energy_kwh'],\n",
        "    marker_color='#FF6B6B',\n",
        "    hovertemplate='<b>CPU Energy</b><br>%{y:.6f} kWh<br>Rank: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_lora_energy.add_trace(go.Bar(\n",
        "    name='GPU Energy',\n",
        "    x=df_sorted_lora['lora_rank'],\n",
        "    y=df_sorted_lora['gpu_energy_kwh'],\n",
        "    marker_color='#4ECDC4',\n",
        "    hovertemplate='<b>GPU Energy</b><br>%{y:.6f} kWh<br>Rank: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_lora_energy.add_trace(go.Bar(\n",
        "    name='RAM Energy',\n",
        "    x=df_sorted_lora['lora_rank'],\n",
        "    y=df_sorted_lora['ram_energy_kwh'],\n",
        "    marker_color='#95E1D3',\n",
        "    hovertemplate='<b>RAM Energy</b><br>%{y:.6f} kWh<br>Rank: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_lora_energy.update_layout(\n",
        "    title=dict(text=\"LoRA: Energy Consumption by Rank\", font=dict(size=18)),\n",
        "    xaxis_title='LoRA Rank',\n",
        "    yaxis_title='Energy Consumption (kWh)',\n",
        "    barmode='stack',\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig_lora_energy.show()\n",
        "fig_lora_energy.write_html(\"/content/drive/MyDrive/lora_energy_by_rank.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "lyGfA29KXE1b",
        "outputId": "14c41a63-a939-4099-fb2e-d2e66901ff69"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6c39a8a7-058e-4a34-8ee1-2f209edec5c7\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6c39a8a7-058e-4a34-8ee1-2f209edec5c7\")) {                    Plotly.newPlot(                        \"6c39a8a7-058e-4a34-8ee1-2f209edec5c7\",                        [{\"hovertemplate\":\"\\u003cb\\u003eF1 Score\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#4ECDC4\",\"width\":3},\"marker\":{\"line\":{\"color\":\"white\",\"width\":2},\"size\":12},\"mode\":\"lines+markers\",\"name\":\"F1 Score\",\"x\":[4,8,16],\"y\":[0.4930335343604761,0.512775500119927,0.5458453270860725],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eExact Match\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#95E1D3\",\"dash\":\"dash\",\"width\":3},\"marker\":{\"size\":10},\"mode\":\"lines+markers\",\"name\":\"Exact Match\",\"x\":[4,8,16],\"y\":[0.4305257952859733,0.44305257952859733,0.4761826273281688],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eCO₂\\u003c\\u002fb\\u003e: %{y:.6f} kg\\u003cbr\\u003eRank: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CO₂ Emissions\",\"opacity\":0.6,\"x\":[4,8,16],\"y\":[0.009819521613020065,0.00981295618147216,0.009803907349376783],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"LoRA Rank\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Performance Score\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"CO₂ Emissions (kg)\"}},\"title\":{\"font\":{\"size\":18},\"text\":\"LoRA: Performance vs Carbon Emissions by Rank\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6c39a8a7-058e-4a34-8ee1-2f209edec5c7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT 2: LoRA Performance & Emissions by Rank (Dual Y-axis)\n",
        "df_sorted_lora = results_df_lora.sort_values('lora_rank')\n",
        "\n",
        "fig_lora_perf = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# F1 Score line\n",
        "fig_lora_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_lora['lora_rank'],\n",
        "        y=df_sorted_lora['f1_score'],\n",
        "        name='F1 Score',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#4ECDC4', width=3),\n",
        "        marker=dict(size=12, line=dict(width=2, color='white')),\n",
        "        hovertemplate='<b>F1 Score</b>: %{y:.4f}<br>Rank: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# Exact Match line\n",
        "fig_lora_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_lora['lora_rank'],\n",
        "        y=df_sorted_lora['exact_match'],\n",
        "        name='Exact Match',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#95E1D3', width=3, dash='dash'),\n",
        "        marker=dict(size=10),\n",
        "        hovertemplate='<b>Exact Match</b>: %{y:.4f}<br>Rank: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# CO2 Emissions bar\n",
        "fig_lora_perf.add_trace(\n",
        "    go.Bar(\n",
        "        x=df_sorted_lora['lora_rank'],\n",
        "        y=df_sorted_lora['emissions_kg'],\n",
        "        name='CO₂ Emissions',\n",
        "        marker_color='#FF6B6B',\n",
        "        opacity=0.6,\n",
        "        hovertemplate='<b>CO₂</b>: %{y:.6f} kg<br>Rank: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=True\n",
        ")\n",
        "\n",
        "fig_lora_perf.update_xaxes(title_text=\"LoRA Rank\")\n",
        "fig_lora_perf.update_yaxes(title_text=\"Performance Score\", secondary_y=False)\n",
        "fig_lora_perf.update_yaxes(title_text=\"CO₂ Emissions (kg)\", secondary_y=True)\n",
        "\n",
        "fig_lora_perf.update_layout(\n",
        "    title=dict(text=\"LoRA: Performance vs Carbon Emissions by Rank\", font=dict(size=18)),\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_lora_perf.show()\n",
        "fig_lora_perf.write_html(\"/content/drive/MyDrive/lora_performance_emissions.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7h3wrMix97lS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1ESW0WEuWLJ"
      },
      "source": [
        "# Training Strategy 3: Few-shot Learning With Frozen Backbone\n",
        "\n",
        "## STEP 7: Creating And Training Few-shot Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8TtNcPqRuvP5"
      },
      "outputs": [],
      "source": [
        "def create_frozen_model(model_name=\"distilbert-base-uncased\"):\n",
        "    #Create model with frozen backbone (only QA head is trainable).\n",
        "    # Load base model\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "    # Freeze ALL parameters first\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze ONLY the QA head (classifier layer)\n",
        "    # For DistilBERT: qa_outputs layer\n",
        "    for param in model.qa_outputs.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Count parameters\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    print(f\"\\n🔒 Model Configuration:\")\n",
        "    print(f\"  Total Parameters: {total_params:,}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"  Frozen Parameters: {total_params - trainable_params:,}\")\n",
        "    print(f\"  Trainable Percentage: {100 * trainable_params / total_params:.4f}%\")\n",
        "\n",
        "    return model, trainable_params, total_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XYukCtgAuvgQ"
      },
      "outputs": [],
      "source": [
        "def prepare_fewshot_dataset(train_data, num_shots, preprocess_fn):\n",
        "    # Select only num_shots examples\n",
        "    train_subset = train_data.select(range(num_shots))\n",
        "\n",
        "    print(f\"🔄 Creating few-shot dataset with {num_shots} examples...\")\n",
        "    tokenized_train = train_subset.map(\n",
        "        preprocess_fn,\n",
        "        batched=True,\n",
        "        remove_columns=train_subset.column_names\n",
        "    )\n",
        "\n",
        "    # After tokenization with sliding window, we get more samples\n",
        "    actual_samples = len(tokenized_train)\n",
        "    print(f\"  Original examples: {num_shots}\")\n",
        "    print(f\"  After tokenization (with sliding window): {actual_samples} samples\")\n",
        "\n",
        "    return tokenized_train, num_shots  # Return original num_shots for tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LN-zQJ7HkfkB"
      },
      "outputs": [],
      "source": [
        "def train_fewshot_model(tokenized_train, tokenized_eval, tokenizer, compute_metrics_fn, num_shots, model_name=\"distilbert-base-uncased\"):\n",
        "    # Create frozen model\n",
        "    model, trainable_params, total_params = create_frozen_model(model_name)\n",
        "\n",
        "    # Setup output directory\n",
        "    output_dir = f\"results_distilbert_fewshot_{num_shots}shots\"\n",
        "\n",
        "    # Training arguments - DIFFERENT from full fine-tuning\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=5e-4,  # Higher LR since we're only training the head\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=10,  # More epochs for few-shot\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        push_to_hub=False,\n",
        "        logging_steps=50,\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        compute_metrics=compute_metrics_fn\n",
        "    )\n",
        "\n",
        "    # Start carbon tracking\n",
        "    tracker = EmissionsTracker(\n",
        "        project_name=f\"DistilBERT_FewShot_{num_shots}shots\",\n",
        "        output_dir=output_dir,\n",
        "        save_to_file=True,\n",
        "        log_level=\"info\"\n",
        "    )\n",
        "    tracker.start()\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\n🏋️ Training few-shot model ({num_shots} examples)...\")\n",
        "    train_results = trainer.train()\n",
        "\n",
        "    # Stop tracking and get detailed emissions data\n",
        "    emissions_kg = tracker.stop()\n",
        "    emissions_data = tracker.final_emissions_data\n",
        "\n",
        "    return trainer, train_results, emissions_data, output_dir, model, trainable_params, total_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TDucSX0a3s2Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_I0ad6Qc3tHa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozi7C-1p3IMd"
      },
      "source": [
        "## STEP 8: Evaluating The Few-shot Model On Different Shot Sizes\n",
        "\n",
        ">We will be training our model on various shots from our SQuAD dataset.\n",
        ">\n",
        ">Training Few-shot Variation: [100, 500, 1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gfC-Xe2l0j32"
      },
      "outputs": [],
      "source": [
        "def evaluate_and_save_fewshot(trainer, train_results, emissions_data, output_dir, num_shots, trainable_params, total_params):\n",
        "    print(\"📊 Evaluating few-shot model...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    trainable_percentage = 100 * trainable_params / total_params\n",
        "\n",
        "    # Compile results\n",
        "    result_entry = {\n",
        "        \"training_method\": \"Few-Shot (Frozen Backbone)\",\n",
        "        \"model_name\": \"DistilBERT\",\n",
        "        \"num_shots\": num_shots,\n",
        "        \"train_samples\": num_shots,\n",
        "        \"valid_samples\": len(tokenized_validation),\n",
        "        \"trainable_params\": trainable_params,\n",
        "        \"total_params\": total_params,\n",
        "        \"trainable_percentage\": trainable_percentage,\n",
        "\n",
        "        # Performance\n",
        "        \"f1_score\": eval_results[\"eval_f1\"],\n",
        "        \"exact_match\": eval_results[\"eval_exact_match\"],\n",
        "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
        "        \"training_time_hours\": train_results.metrics[\"train_runtime\"] / 3600,\n",
        "\n",
        "        # Emissions data\n",
        "        \"emissions_rate_kg_per_s\": emissions_data.emissions_rate,\n",
        "        \"emissions_kg\": emissions_data.emissions,\n",
        "        \"timestamp\": emissions_data.timestamp,\n",
        "        \"duration_seconds\": emissions_data.duration,\n",
        "        \"duration_hours\": emissions_data.duration / 3600,\n",
        "\n",
        "        # Energy\n",
        "        \"energy_consumed_kwh\": emissions_data.energy_consumed,\n",
        "        \"cpu_energy_kwh\": emissions_data.cpu_energy,\n",
        "        \"gpu_energy_kwh\": emissions_data.gpu_energy,\n",
        "        \"ram_energy_kwh\": emissions_data.ram_energy,\n",
        "\n",
        "        # Power\n",
        "        \"cpu_power_w\": emissions_data.cpu_power,\n",
        "        \"gpu_power_w\": emissions_data.gpu_power,\n",
        "        \"ram_power_w\": emissions_data.ram_power,\n",
        "\n",
        "        # Location and system info\n",
        "        \"country_name\": emissions_data.country_name,\n",
        "        \"country_iso_code\": emissions_data.country_iso_code,\n",
        "        \"region\": emissions_data.region,\n",
        "        \"cloud_provider\": emissions_data.cloud_provider,\n",
        "        \"cloud_region\": emissions_data.cloud_region,\n",
        "        \"on_cloud\": emissions_data.on_cloud,\n",
        "\n",
        "        # System specifications\n",
        "        \"os\": emissions_data.os,\n",
        "        \"python_version\": emissions_data.python_version,\n",
        "        \"cpu_count\": emissions_data.cpu_count,\n",
        "        \"cpu_model\": emissions_data.cpu_model,\n",
        "        \"gpu_count\": emissions_data.gpu_count,\n",
        "        \"gpu_model\": emissions_data.gpu_model,\n",
        "        \"ram_total_size_gb\": emissions_data.ram_total_size,\n",
        "\n",
        "        # Additional metrics\n",
        "        \"pue\": emissions_data.pue,\n",
        "        \"codecarbon_version\": emissions_data.codecarbon_version,\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"📈 FEW-SHOT LEARNING RESULTS ({num_shots} examples)\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"\\n🔧 Model Configuration:\")\n",
        "    print(f\"  Training Method: Few-Shot (Frozen Backbone)\")\n",
        "    print(f\"  Training Examples: {num_shots}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,} ({trainable_percentage:.4f}%)\")\n",
        "    print(f\"  Frozen Parameters: {total_params - trainable_params:,}\")\n",
        "\n",
        "    print(f\"\\n🎯 Performance:\")\n",
        "    print(f\"  F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"  Exact Match: {eval_results['eval_exact_match']:.4f}\")\n",
        "    print(f\"  Eval Loss: {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\n⚡ Energy:\")\n",
        "    print(f\"  Total: {emissions_data.energy_consumed:.6f} kWh\")\n",
        "    if emissions_data.energy_consumed > 0:\n",
        "        print(f\"  GPU: {emissions_data.gpu_energy:.6f} kWh ({emissions_data.gpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "        print(f\"  CPU: {emissions_data.cpu_energy:.6f} kWh ({emissions_data.cpu_energy/emissions_data.energy_consumed*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n🌱 Carbon:\")\n",
        "    print(f\"  CO₂ Emissions: {emissions_data.emissions:.6f} kg\")\n",
        "    print(f\"  Training Time: {train_results.metrics['train_runtime']/3600:.2f} hours\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Save model\n",
        "    trainer.save_model(f\"{output_dir}/final_model\")\n",
        "    print(f\"✅ Model saved to {output_dir}/final_model\")\n",
        "\n",
        "    # Clean up\n",
        "    del trainer.model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result_entry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KK7HslIr0kXH"
      },
      "outputs": [],
      "source": [
        "def run_fewshot_experiment(num_shots, train_data, eval_data, tokenizer, preprocess_fn, compute_metrics_fn, model_name=\"distilbert-base-uncased\"):\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🚀 Few-Shot Learning with {num_shots} examples\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Step 1: Prepare few-shot dataset\n",
        "    tokenized_train, num_shots = prepare_fewshot_dataset(train_data, num_shots, preprocess_fn)\n",
        "\n",
        "    # Step 2: Train with frozen backbone\n",
        "    trainer, train_results, emissions_data, output_dir, model, trainable_params, total_params = train_fewshot_model(\n",
        "        tokenized_train, eval_data, tokenizer, compute_metrics_fn,\n",
        "        num_shots, model_name\n",
        "    )\n",
        "\n",
        "    # Step 3: Evaluate and save\n",
        "    result_entry = evaluate_and_save_fewshot(\n",
        "        trainer, train_results, emissions_data, output_dir,\n",
        "        num_shots, trainable_params, total_params\n",
        "    )\n",
        "\n",
        "    return result_entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JclbGt1g0kqH"
      },
      "outputs": [],
      "source": [
        "result_fewshot = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "23726b814b3f43dd9a8961dac48d1feb",
            "7807b68ecc7743cbbba24fd1ed22d3aa",
            "e302ea827e154c6ca2155e76268d138b",
            "53b7e2e68d074b1c9026fc88a047cee3",
            "f9bfd302e2104e38ada243b78326378a",
            "f4517f2067884448be69e76c138fecea",
            "efc9cc8c98454097b93ffc40fe787911",
            "b5e25975c2a5484f833fe23782a7a2f7",
            "358b210639694eacb5a4386f7605c407",
            "676a6368aeff4eb28963ed15a41c11d7",
            "d664bd4b05ea45149b5323c9d69ca465"
          ]
        },
        "collapsed": true,
        "id": "dE4Wnm061AL2",
        "outputId": "81f36cd7-3c72-4dc1-ccc3-decac4d5375c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 1: 100-shot Learning\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Few-Shot Learning with 100 examples\n",
            "============================================================\n",
            "🔄 Creating few-shot dataset with 100 examples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23726b814b3f43dd9a8961dac48d1feb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Original examples: 100\n",
            "  After tokenization (with sliding window): 100 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔒 Model Configuration:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 1,538\n",
            "  Frozen Parameters: 66,362,880\n",
            "  Trainable Percentage: 0.0023%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1092708844.py:26: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 04:04:22] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 04:04:22] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 04:04:22] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 04:04:24] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 04:04:24] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 04:04:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 04:04:24] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 04:04:24] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 04:04:24] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 04:04:24] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 04:04:24] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 04:04:24]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 04:04:24]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 04:04:24]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 04:04:24]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 04:04:24]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 04:04:24]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 04:04:24]   GPU count: 1\n",
            "[codecarbon INFO @ 04:04:24]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 04:04:24] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_100shots/emissions.csv\n",
            "[codecarbon WARNING @ 04:04:24] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 04:04:24] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 04:04:24] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 04:04:25] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 04:04:25] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 04:04:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 04:04:25] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 04:04:25] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 04:04:25] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 04:04:25] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 04:04:25] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 04:04:25]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 04:04:25]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 04:04:25]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 04:04:25]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 04:04:25]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 04:04:25]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 04:04:25]   GPU count: 1\n",
            "[codecarbon INFO @ 04:04:25]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 04:04:25] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_100shots/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏋️ Training few-shot model (100 examples)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 02:00, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.960748</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.006065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.925188</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.006769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.897899</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.006562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.877831</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.007620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.861616</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.007852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.847296</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>0.008439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.837134</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>0.008846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.605100</td>\n",
              "      <td>5.830018</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.009092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>5.605100</td>\n",
              "      <td>5.825410</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.009039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5.605100</td>\n",
              "      <td>5.823724</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.009082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 04:04:40] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:04:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:04:40] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 04:04:40] Energy consumed for all GPUs : 0.000692 kWh. Total GPU Power : 165.8547214679277 W\n",
            "[codecarbon INFO @ 04:04:40] 0.001027 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:04:40] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:04:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:04:40] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 04:04:40] Energy consumed for all GPUs : 0.000711 kWh. Total GPU Power : 170.44782118470903 W\n",
            "[codecarbon INFO @ 04:04:40] 0.001046 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:04:55] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:04:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:04:55] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 04:04:55] Energy consumed for all GPUs : 0.001411 kWh. Total GPU Power : 172.55692256576955 W\n",
            "[codecarbon INFO @ 04:04:55] 0.002081 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:04:55] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:04:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:04:55] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 04:04:55] Energy consumed for all GPUs : 0.001430 kWh. Total GPU Power : 172.61174712912575 W\n",
            "[codecarbon INFO @ 04:04:55] 0.002101 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:10] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:10] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 04:05:10] Energy consumed for all GPUs : 0.002146 kWh. Total GPU Power : 176.45378116946569 W\n",
            "[codecarbon INFO @ 04:05:10] 0.003152 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:10] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:11] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 04:05:11] Energy consumed for all GPUs : 0.002160 kWh. Total GPU Power : 175.14972281854963 W\n",
            "[codecarbon INFO @ 04:05:11] 0.003167 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:25] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:25] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 04:05:25] Energy consumed for all GPUs : 0.002873 kWh. Total GPU Power : 174.71213787240126 W\n",
            "[codecarbon INFO @ 04:05:25] 0.004215 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:25] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:25] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 04:05:25] Energy consumed for all GPUs : 0.002893 kWh. Total GPU Power : 175.91097788930745 W\n",
            "[codecarbon INFO @ 04:05:25] 0.004234 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:40] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:40] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 04:05:40] Energy consumed for all GPUs : 0.003589 kWh. Total GPU Power : 171.72432293987495 W\n",
            "[codecarbon INFO @ 04:05:40] 0.005265 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:40] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:40] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 04:05:40] Energy consumed for all GPUs : 0.003608 kWh. Total GPU Power : 171.65961005651957 W\n",
            "[codecarbon INFO @ 04:05:40] 0.005284 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:55] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:55] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 04:05:55] Energy consumed for all GPUs : 0.004324 kWh. Total GPU Power : 176.3604281684805 W\n",
            "[codecarbon INFO @ 04:05:55] 0.006336 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:05:55] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:05:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:05:56] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 04:05:56] Energy consumed for all GPUs : 0.004338 kWh. Total GPU Power : 175.27146224781268 W\n",
            "[codecarbon INFO @ 04:05:56] 0.006350 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:06:10] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:10] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 04:06:10] Energy consumed for all GPUs : 0.005052 kWh. Total GPU Power : 174.97015884180217 W\n",
            "[codecarbon INFO @ 04:06:10] 0.007400 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:06:10] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:11] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 04:06:11] Energy consumed for all GPUs : 0.005072 kWh. Total GPU Power : 176.18711085202523 W\n",
            "[codecarbon INFO @ 04:06:11] 0.007420 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:06:25] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:25] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 04:06:25] Energy consumed for all GPUs : 0.005781 kWh. Total GPU Power : 174.9283954700789 W\n",
            "[codecarbon INFO @ 04:06:25] 0.008464 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:06:25] 0.018870 g.CO2eq/s mean an estimation of 595.089803285053 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:26] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for all GPUs : 0.005800 kWh. Total GPU Power : 174.86109695345252 W\n",
            "[codecarbon INFO @ 04:06:26] 0.008483 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:06:26] 0.018913 g.CO2eq/s mean an estimation of 596.4531020017043 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for RAM : 0.001276 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:26] Delta energy consumed for CPU with constant : 0.000011 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for All CPU : 0.001428 kWh\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for all GPUs : 0.005835 kWh. Total GPU Power : 129.4513506890642 W\n",
            "[codecarbon INFO @ 04:06:26] 0.008540 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for RAM : 0.001281 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:26] Delta energy consumed for CPU with constant : 0.000017 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for All CPU : 0.001433 kWh\n",
            "[codecarbon INFO @ 04:06:26] Energy consumed for all GPUs : 0.005841 kWh. Total GPU Power : 148.42835587546648 W\n",
            "[codecarbon INFO @ 04:06:26] 0.008555 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating few-shot model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT LEARNING RESULTS (100 examples)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: Few-Shot (Frozen Backbone)\n",
            "  Training Examples: 100\n",
            "  Trainable Parameters: 1,538 (0.0023%)\n",
            "  Frozen Parameters: 66,362,880\n",
            "\n",
            "🎯 Performance:\n",
            "  F1 Score: 0.0091\n",
            "  Exact Match: 0.0004\n",
            "  Eval Loss: 5.8300\n",
            "\n",
            "⚡ Energy:\n",
            "  Total: 0.008555 kWh\n",
            "  GPU: 0.005841 kWh (68.3%)\n",
            "  CPU: 0.001433 kWh (16.8%)\n",
            "\n",
            "🌱 Carbon:\n",
            "  CO₂ Emissions: 0.002290 kg\n",
            "  Training Time: 0.03 hours\n",
            "================================================================================\n",
            "✅ Model saved to results_distilbert_fewshot_100shots/final_model\n",
            "CPU times: user 2min 11s, sys: 2.78 s, total: 2min 14s\n",
            "Wall time: 2min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 1: 100-shot Learning\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_100 = run_fewshot_experiment(\n",
        "    num_shots=100,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    model_name=\"distilbert-base-uncased\"\n",
        ")\n",
        "result_fewshot.append(result_100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ae0c12e59dd540dea02e5c9f6ace9876",
            "552ce30d83d749759e2c67c0c522aec1",
            "400f5f78ff5645478c926177a6691b1f",
            "79be407f83a14ae8b9e3a74b2d2bdb45",
            "d47fc137f3474bde9e4886c061eb5dcc",
            "80ff827b9d6d464c9ad37f6ddb7b4d12",
            "b2653f772ec54560b98c6cb0c3b20b8e",
            "c954fb49d8764a8ba26b576c712e0124",
            "c72ffefd0b8e4b018c7d228d41124074",
            "0f6e2368ab2047db81b743d622bc4f90",
            "dda0557ff727447ab48237c9fe83df19"
          ]
        },
        "collapsed": true,
        "id": "7eBIzG071Aar",
        "outputId": "4d53fd18-224b-44e2-c837-624f08e64e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 2: 500-shot Learning\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Few-Shot Learning with 500 examples\n",
            "============================================================\n",
            "🔄 Creating few-shot dataset with 500 examples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae0c12e59dd540dea02e5c9f6ace9876",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Original examples: 500\n",
            "  After tokenization (with sliding window): 527 samples\n",
            "\n",
            "🔒 Model Configuration:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 1,538\n",
            "  Frozen Parameters: 66,362,880\n",
            "  Trainable Percentage: 0.0023%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1092708844.py:26: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 04:06:39] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 04:06:39] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 04:06:39] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 04:06:40] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 04:06:40] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 04:06:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 04:06:40] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 04:06:40] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 04:06:40] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 04:06:40] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 04:06:40] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 04:06:40]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 04:06:40]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 04:06:40]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 04:06:40]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 04:06:40]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 04:06:40]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 04:06:40]   GPU count: 1\n",
            "[codecarbon INFO @ 04:06:40]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 04:06:40] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_500shots/emissions.csv\n",
            "[codecarbon WARNING @ 04:06:40] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 04:06:40] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 04:06:40] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 04:06:42] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 04:06:42] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 04:06:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 04:06:42] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 04:06:42] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 04:06:42] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 04:06:42] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 04:06:42] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 04:06:42]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 04:06:42]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 04:06:42]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 04:06:42]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 04:06:42]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 04:06:42]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 04:06:42]   GPU count: 1\n",
            "[codecarbon INFO @ 04:06:42]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 04:06:42] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_500shots/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏋️ Training few-shot model (500 examples)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [330/330 02:05, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.600938</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.012893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.614300</td>\n",
              "      <td>5.365770</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.013981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.614300</td>\n",
              "      <td>5.196386</td>\n",
              "      <td>0.000989</td>\n",
              "      <td>0.014842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.119000</td>\n",
              "      <td>5.050659</td>\n",
              "      <td>0.001731</td>\n",
              "      <td>0.015044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.839400</td>\n",
              "      <td>4.921439</td>\n",
              "      <td>0.002225</td>\n",
              "      <td>0.015549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.839400</td>\n",
              "      <td>4.848420</td>\n",
              "      <td>0.002720</td>\n",
              "      <td>0.015826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.660800</td>\n",
              "      <td>4.767348</td>\n",
              "      <td>0.005357</td>\n",
              "      <td>0.017459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.575200</td>\n",
              "      <td>4.723065</td>\n",
              "      <td>0.006840</td>\n",
              "      <td>0.018732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.575200</td>\n",
              "      <td>4.696511</td>\n",
              "      <td>0.007747</td>\n",
              "      <td>0.019596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.522800</td>\n",
              "      <td>4.687153</td>\n",
              "      <td>0.008241</td>\n",
              "      <td>0.019856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 04:06:57] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:57] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 04:06:57] Energy consumed for all GPUs : 0.000686 kWh. Total GPU Power : 164.6809040429256 W\n",
            "[codecarbon INFO @ 04:06:57] 0.001022 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:06:57] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:06:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:06:57] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 04:06:57] Energy consumed for all GPUs : 0.000705 kWh. Total GPU Power : 169.03454929120085 W\n",
            "[codecarbon INFO @ 04:06:57] 0.001040 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:12] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:12] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 04:07:12] Energy consumed for all GPUs : 0.001418 kWh. Total GPU Power : 175.50093169699915 W\n",
            "[codecarbon INFO @ 04:07:12] 0.002089 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:12] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:12] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 04:07:12] Energy consumed for all GPUs : 0.001431 kWh. Total GPU Power : 174.3383628985002 W\n",
            "[codecarbon INFO @ 04:07:12] 0.002102 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:27] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:27] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 04:07:27] Energy consumed for all GPUs : 0.002146 kWh. Total GPU Power : 174.9398222797011 W\n",
            "[codecarbon INFO @ 04:07:27] 0.003153 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:27] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:27] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 04:07:27] Energy consumed for all GPUs : 0.002160 kWh. Total GPU Power : 174.9923771228738 W\n",
            "[codecarbon INFO @ 04:07:27] 0.003166 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:42] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:42] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 04:07:42] Energy consumed for all GPUs : 0.002872 kWh. Total GPU Power : 174.11262363948848 W\n",
            "[codecarbon INFO @ 04:07:42] 0.004213 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:42] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:42] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 04:07:42] Energy consumed for all GPUs : 0.002890 kWh. Total GPU Power : 175.2342559456197 W\n",
            "[codecarbon INFO @ 04:07:42] 0.004231 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:57] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:57] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 04:07:57] Energy consumed for all GPUs : 0.003604 kWh. Total GPU Power : 175.56996274477572 W\n",
            "[codecarbon INFO @ 04:07:57] 0.005280 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:07:57] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:07:57] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:07:57] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 04:07:57] Energy consumed for all GPUs : 0.003617 kWh. Total GPU Power : 174.4474149954055 W\n",
            "[codecarbon INFO @ 04:07:57] 0.005293 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:12] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:12] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 04:08:12] Energy consumed for all GPUs : 0.004308 kWh. Total GPU Power : 169.11325190261377 W\n",
            "[codecarbon INFO @ 04:08:12] 0.006320 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:12] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:12] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:12] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 04:08:12] Energy consumed for all GPUs : 0.004321 kWh. Total GPU Power : 169.01215148323374 W\n",
            "[codecarbon INFO @ 04:08:12] 0.006333 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:27] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:27] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 04:08:27] Energy consumed for all GPUs : 0.005037 kWh. Total GPU Power : 174.9579503380267 W\n",
            "[codecarbon INFO @ 04:08:27] 0.007384 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:27] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:27] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:27] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 04:08:27] Energy consumed for all GPUs : 0.005055 kWh. Total GPU Power : 176.25917854174742 W\n",
            "[codecarbon INFO @ 04:08:27] 0.007402 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:42] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:42] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 04:08:42] Energy consumed for all GPUs : 0.005766 kWh. Total GPU Power : 175.08463643733967 W\n",
            "[codecarbon INFO @ 04:08:42] 0.008449 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:42] 0.018838 g.CO2eq/s mean an estimation of 594.0720825084012 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:08:42] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:42] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:42] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 04:08:42] Energy consumed for all GPUs : 0.005780 kWh. Total GPU Power : 173.92080977608586 W\n",
            "[codecarbon INFO @ 04:08:42] 0.008462 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:42] 0.018869 g.CO2eq/s mean an estimation of 595.0442370895828 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:08:48] Energy consumed for RAM : 0.001329 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:48] Delta energy consumed for CPU with constant : 0.000070 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:48] Energy consumed for All CPU : 0.001486 kWh\n",
            "[codecarbon INFO @ 04:08:48] Energy consumed for all GPUs : 0.006062 kWh. Total GPU Power : 171.96775510720795 W\n",
            "[codecarbon INFO @ 04:08:48] 0.008877 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:08:48] Energy consumed for RAM : 0.001333 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:08:48] Delta energy consumed for CPU with constant : 0.000075 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:08:48] Energy consumed for All CPU : 0.001492 kWh\n",
            "[codecarbon INFO @ 04:08:48] Energy consumed for all GPUs : 0.006069 kWh. Total GPU Power : 170.8101311311067 W\n",
            "[codecarbon INFO @ 04:08:48] 0.008894 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating few-shot model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT LEARNING RESULTS (500 examples)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: Few-Shot (Frozen Backbone)\n",
            "  Training Examples: 500\n",
            "  Trainable Parameters: 1,538 (0.0023%)\n",
            "  Frozen Parameters: 66,362,880\n",
            "\n",
            "🎯 Performance:\n",
            "  F1 Score: 0.0199\n",
            "  Exact Match: 0.0082\n",
            "  Eval Loss: 4.6872\n",
            "\n",
            "⚡ Energy:\n",
            "  Total: 0.008894 kWh\n",
            "  GPU: 0.006069 kWh (68.2%)\n",
            "  CPU: 0.001492 kWh (16.8%)\n",
            "\n",
            "🌱 Carbon:\n",
            "  CO₂ Emissions: 0.002380 kg\n",
            "  Training Time: 0.03 hours\n",
            "================================================================================\n",
            "✅ Model saved to results_distilbert_fewshot_500shots/final_model\n",
            "CPU times: user 2min 16s, sys: 2.8 s, total: 2min 19s\n",
            "Wall time: 2min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 2: 500-shot Learning\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_500 = run_fewshot_experiment(\n",
        "    num_shots=500,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    model_name=\"distilbert-base-uncased\"\n",
        ")\n",
        "result_fewshot.append(result_500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "249e965ef9b442b68905c2562b88628a",
            "a0346b917a964f1ca0f656467d4fd714",
            "3ce0f5c70b7447acaea287aa6d9c57dd",
            "0a0f4f885aa14004b07eabef3facb6c4",
            "3608ce978a8046dda77607c5f150bc33",
            "a2593041f1d04c6ea8eeaab70681d332",
            "752def0daf0f440c96237a292041d75d",
            "ee308a32731a440eaa9297b26dd1546d",
            "2c413302a6d1413a91e221a54035ad48",
            "c150eb26356940dfbef99ceaa479a48f",
            "27423f5250634024b241b61da791fcd0"
          ]
        },
        "collapsed": true,
        "id": "xPgMm5Dp1AqU",
        "outputId": "a4852a61-5a5d-4347-b843-ff84c0097a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "🔬 EXPERIMENT 3: 1000-shot Learning\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "🚀 Few-Shot Learning with 1000 examples\n",
            "============================================================\n",
            "🔄 Creating few-shot dataset with 1000 examples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "249e965ef9b442b68905c2562b88628a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Original examples: 1000\n",
            "  After tokenization (with sliding window): 1027 samples\n",
            "\n",
            "🔒 Model Configuration:\n",
            "  Total Parameters: 66,364,418\n",
            "  Trainable Parameters: 1,538\n",
            "  Frozen Parameters: 66,362,880\n",
            "  Trainable Percentage: 0.0023%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1092708844.py:26: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n",
            "[codecarbon WARNING @ 04:09:01] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 04:09:01] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 04:09:01] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 04:09:02] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 04:09:02] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 04:09:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 04:09:02] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 04:09:02] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 04:09:02] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 04:09:02] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 04:09:02] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 04:09:02]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 04:09:02]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 04:09:02]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 04:09:02]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 04:09:02]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 04:09:02]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 04:09:02]   GPU count: 1\n",
            "[codecarbon INFO @ 04:09:02]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon WARNING @ 04:09:03] Unable to access geographical location through primary API. Will resort to using the backup API - Exception : HTTPSConnectionPool(host='get.geojs.io', port=443): Read timed out. (read timeout=0.5) - url=https://get.geojs.io/v1/ip/geo.json\n",
            "[codecarbon WARNING @ 04:09:03] Unable to access geographical location. Using 'Canada' as the default value - Exception : 'country' - url=https://get.geojs.io/v1/ip/geo.json\n",
            "[codecarbon INFO @ 04:09:03] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_1000shots/emissions.csv\n",
            "[codecarbon WARNING @ 04:09:03] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 04:09:03] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 04:09:03] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 04:09:04] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 04:09:04] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 04:09:04] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 04:09:04] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 04:09:04] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 04:09:04] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 04:09:04] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 04:09:04] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 04:09:04]   Platform system: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 04:09:04]   Python version: 3.12.12\n",
            "[codecarbon INFO @ 04:09:04]   CodeCarbon version: 3.2.0\n",
            "[codecarbon INFO @ 04:09:04]   Available RAM : 83.474 GB\n",
            "[codecarbon INFO @ 04:09:04]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 04:09:04]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 04:09:04]   GPU count: 1\n",
            "[codecarbon INFO @ 04:09:04]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n",
            "[codecarbon INFO @ 04:09:04] Emissions data (if any) will be saved to file /content/results_distilbert_fewshot_1000shots/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏋️ Training few-shot model (1000 examples)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='650' max='650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [650/650 02:12, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.640500</td>\n",
              "      <td>5.487395</td>\n",
              "      <td>0.001071</td>\n",
              "      <td>0.014791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.122300</td>\n",
              "      <td>5.161344</td>\n",
              "      <td>0.002225</td>\n",
              "      <td>0.016665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.808000</td>\n",
              "      <td>4.953194</td>\n",
              "      <td>0.003626</td>\n",
              "      <td>0.018421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.479300</td>\n",
              "      <td>4.815657</td>\n",
              "      <td>0.004533</td>\n",
              "      <td>0.019417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.401300</td>\n",
              "      <td>4.721910</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.020926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.297600</td>\n",
              "      <td>4.657375</td>\n",
              "      <td>0.005934</td>\n",
              "      <td>0.021714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.226000</td>\n",
              "      <td>4.601258</td>\n",
              "      <td>0.006099</td>\n",
              "      <td>0.021734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.170100</td>\n",
              "      <td>4.566637</td>\n",
              "      <td>0.006346</td>\n",
              "      <td>0.022027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.182700</td>\n",
              "      <td>4.545423</td>\n",
              "      <td>0.006428</td>\n",
              "      <td>0.022245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.120200</td>\n",
              "      <td>4.540926</td>\n",
              "      <td>0.006428</td>\n",
              "      <td>0.022166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 04:09:19] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:09:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:09:19] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 04:09:19] Energy consumed for all GPUs : 0.000676 kWh. Total GPU Power : 162.1411535663205 W\n",
            "[codecarbon INFO @ 04:09:19] 0.001011 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:09:19] Energy consumed for RAM : 0.000158 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:09:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:09:19] Energy consumed for All CPU : 0.000177 kWh\n",
            "[codecarbon INFO @ 04:09:19] Energy consumed for all GPUs : 0.000691 kWh. Total GPU Power : 165.88317416048844 W\n",
            "[codecarbon INFO @ 04:09:19] 0.001027 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:09:34] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:09:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:09:34] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 04:09:34] Energy consumed for all GPUs : 0.001384 kWh. Total GPU Power : 169.95974778591489 W\n",
            "[codecarbon INFO @ 04:09:34] 0.002055 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:09:34] Energy consumed for RAM : 0.000317 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:09:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:09:34] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 04:09:34] Energy consumed for all GPUs : 0.001404 kWh. Total GPU Power : 170.88826749432482 W\n",
            "[codecarbon INFO @ 04:09:34] 0.002074 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:09:49] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:09:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:09:49] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 04:09:49] Energy consumed for all GPUs : 0.002112 kWh. Total GPU Power : 174.7669298353137 W\n",
            "[codecarbon INFO @ 04:09:49] 0.003118 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:09:49] Energy consumed for RAM : 0.000475 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:09:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:09:49] Energy consumed for All CPU : 0.000531 kWh\n",
            "[codecarbon INFO @ 04:09:49] Energy consumed for all GPUs : 0.002126 kWh. Total GPU Power : 173.448212302903 W\n",
            "[codecarbon INFO @ 04:09:49] 0.003133 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:04] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:04] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 04:10:04] Energy consumed for all GPUs : 0.002834 kWh. Total GPU Power : 173.38173358406343 W\n",
            "[codecarbon INFO @ 04:10:04] 0.004176 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:04] Energy consumed for RAM : 0.000633 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:04] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 04:10:04] Energy consumed for all GPUs : 0.002854 kWh. Total GPU Power : 174.69189364293757 W\n",
            "[codecarbon INFO @ 04:10:04] 0.004195 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:19] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:19] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 04:10:19] Energy consumed for all GPUs : 0.003548 kWh. Total GPU Power : 171.28305549400133 W\n",
            "[codecarbon INFO @ 04:10:19] 0.005225 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:19] Energy consumed for RAM : 0.000791 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:19] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:19] Energy consumed for All CPU : 0.000885 kWh\n",
            "[codecarbon INFO @ 04:10:19] Energy consumed for all GPUs : 0.003568 kWh. Total GPU Power : 171.29784277840636 W\n",
            "[codecarbon INFO @ 04:10:19] 0.005244 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:34] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:34] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 04:10:34] Energy consumed for all GPUs : 0.004273 kWh. Total GPU Power : 174.17210132042456 W\n",
            "[codecarbon INFO @ 04:10:34] 0.006285 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:34] Energy consumed for RAM : 0.000950 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:34] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:34] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 04:10:34] Energy consumed for all GPUs : 0.004288 kWh. Total GPU Power : 172.86353342478657 W\n",
            "[codecarbon INFO @ 04:10:34] 0.006300 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:49] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:49] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 04:10:49] Energy consumed for all GPUs : 0.004986 kWh. Total GPU Power : 171.12495987847757 W\n",
            "[codecarbon INFO @ 04:10:49] 0.007333 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:10:49] Energy consumed for RAM : 0.001108 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:10:49] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:10:49] Energy consumed for All CPU : 0.001239 kWh\n",
            "[codecarbon INFO @ 04:10:49] Energy consumed for all GPUs : 0.005005 kWh. Total GPU Power : 172.17854456249367 W\n",
            "[codecarbon INFO @ 04:10:49] 0.007353 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:11:04] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:11:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:11:04] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 04:11:04] Energy consumed for all GPUs : 0.005682 kWh. Total GPU Power : 166.93007479896323 W\n",
            "[codecarbon INFO @ 04:11:04] 0.008364 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:11:04] 0.018649 g.CO2eq/s mean an estimation of 588.1189989624093 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:11:04] Energy consumed for RAM : 0.001266 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:11:04] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:11:04] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 04:11:04] Energy consumed for all GPUs : 0.005700 kWh. Total GPU Power : 166.93614659381552 W\n",
            "[codecarbon INFO @ 04:11:04] 0.008383 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:11:04] 0.000275 g.CO2eq/s mean an estimation of 8.671838775514738 kg.CO2eq/year\n",
            "[codecarbon INFO @ 04:11:17] Energy consumed for RAM : 0.001396 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:11:17] Delta energy consumed for CPU with constant : 0.000145 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:11:17] Energy consumed for All CPU : 0.001561 kWh\n",
            "[codecarbon INFO @ 04:11:17] Energy consumed for all GPUs : 0.006289 kWh. Total GPU Power : 172.42442782560187 W\n",
            "[codecarbon INFO @ 04:11:17] 0.009246 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
            "[codecarbon INFO @ 04:11:17] Energy consumed for RAM : 0.001401 kWh. RAM Power : 38.0 W\n",
            "[codecarbon INFO @ 04:11:17] Delta energy consumed for CPU with constant : 0.000151 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 04:11:17] Energy consumed for All CPU : 0.001567 kWh\n",
            "[codecarbon INFO @ 04:11:17] Energy consumed for all GPUs : 0.006294 kWh. Total GPU Power : 172.77790135505853 W\n",
            "[codecarbon INFO @ 04:11:17] 0.009262 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating few-shot model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='759' max='759' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [759/759 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT LEARNING RESULTS (1000 examples)\n",
            "================================================================================\n",
            "\n",
            "🔧 Model Configuration:\n",
            "  Training Method: Few-Shot (Frozen Backbone)\n",
            "  Training Examples: 1000\n",
            "  Trainable Parameters: 1,538 (0.0023%)\n",
            "  Frozen Parameters: 66,362,880\n",
            "\n",
            "🎯 Performance:\n",
            "  F1 Score: 0.0222\n",
            "  Exact Match: 0.0064\n",
            "  Eval Loss: 4.5454\n",
            "\n",
            "⚡ Energy:\n",
            "  Total: 0.009262 kWh\n",
            "  GPU: 0.006294 kWh (68.0%)\n",
            "  CPU: 0.001567 kWh (16.9%)\n",
            "\n",
            "🌱 Carbon:\n",
            "  CO₂ Emissions: 0.002479 kg\n",
            "  Training Time: 0.04 hours\n",
            "================================================================================\n",
            "✅ Model saved to results_distilbert_fewshot_1000shots/final_model\n",
            "CPU times: user 2min 23s, sys: 3.27 s, total: 2min 26s\n",
            "Wall time: 2min 28s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔬 EXPERIMENT 3: 1000-shot Learning\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "result_1000 = run_fewshot_experiment(\n",
        "    num_shots=1000,\n",
        "    train_data=squad[\"train\"],\n",
        "    eval_data=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    preprocess_fn=preprocess_function,\n",
        "    compute_metrics_fn=compute_metrics,\n",
        "    model_name=\"distilbert-base-uncased\"\n",
        ")\n",
        "result_fewshot.append(result_1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "73LUuhELBxn0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvyO3HSu6DJ-"
      },
      "source": [
        "### STEP 8.1: Results and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CbzUJ-w1A4E",
        "outputId": "1c657863-5d23-490e-dd7b-06f0cd539636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "📊 FEW-SHOT LEARNING RESULTS SUMMARY\n",
            "============================================================\n",
            " num_shots  trainable_percentage  f1_score  exact_match  emissions_kg  training_time_hours\n",
            "       100              0.002318  0.009092     0.000412      0.002290             0.033616\n",
            "       500              0.002318  0.019856     0.008241      0.002380             0.034983\n",
            "      1000              0.002318  0.022245     0.006428      0.002479             0.036757\n"
          ]
        }
      ],
      "source": [
        "results_df_fewshot = pd.DataFrame(result_fewshot)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 FEW-SHOT LEARNING RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(results_df_fewshot[['num_shots', 'trainable_percentage', 'f1_score', 'exact_match', 'emissions_kg', 'training_time_hours']].to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "results_df_fewshot.to_csv(\"/content/drive/MyDrive/distilbert_fewshot_results.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDevPRqz1U4z",
        "outputId": "8780f56c-729c-4309-fd05-3022c8059f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📈 FEW-SHOT EFFICIENCY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "100-Shot Learning:\n",
            "  Training Examples: 100\n",
            "  Trainable Params: 1,538 (0.0023%)\n",
            "  vs 500-shot: 0.20x training data\n",
            "  F1 Score: 0.0091 (-0.0108 vs 500-shot)\n",
            "  Emissions: 0.002290 kg (-0.000091 vs 500-shot)\n",
            "  Training Time: 0.03 hours (-0.00 vs 500-shot)\n",
            "  Efficiency (F1/kg CO₂): 3.97\n",
            "  Efficiency (F1/hour): 0.2705\n",
            "  Efficiency (F1/sample): 0.000091\n",
            "\n",
            "500-Shot Learning:\n",
            "  Training Examples: 500\n",
            "  Trainable Params: 1,538 (0.0023%)\n",
            "  vs 500-shot: 1.00x training data\n",
            "  F1 Score: 0.0199 (+0.0000 vs 500-shot)\n",
            "  Emissions: 0.002380 kg (+0.000000 vs 500-shot)\n",
            "  Training Time: 0.03 hours (+0.00 vs 500-shot)\n",
            "  Efficiency (F1/kg CO₂): 8.34\n",
            "  Efficiency (F1/hour): 0.5676\n",
            "  Efficiency (F1/sample): 0.000040\n",
            "\n",
            "1000-Shot Learning:\n",
            "  Training Examples: 1,000\n",
            "  Trainable Params: 1,538 (0.0023%)\n",
            "  vs 500-shot: 2.00x training data\n",
            "  F1 Score: 0.0222 (+0.0024 vs 500-shot)\n",
            "  Emissions: 0.002479 kg (+0.000099 vs 500-shot)\n",
            "  Training Time: 0.04 hours (+0.00 vs 500-shot)\n",
            "  Efficiency (F1/kg CO₂): 8.97\n",
            "  Efficiency (F1/hour): 0.6052\n",
            "  Efficiency (F1/sample): 0.000022\n"
          ]
        }
      ],
      "source": [
        "# FEW-SHOT EFFICIENCY ANALYSIS\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📈 FEW-SHOT EFFICIENCY ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Use 500-shot as baseline (middle ground)\n",
        "baseline = results_df_fewshot[results_df_fewshot['num_shots'] == 500].iloc[0]\n",
        "\n",
        "for _, row in results_df_fewshot.iterrows():\n",
        "    shots = row['num_shots']\n",
        "    samples_ratio = row['num_shots'] / baseline['num_shots']\n",
        "    f1_diff = row['f1_score'] - baseline['f1_score']\n",
        "    emissions_diff = row['emissions_kg'] - baseline['emissions_kg']\n",
        "    time_diff = row['training_time_hours'] - baseline['training_time_hours']\n",
        "\n",
        "    print(f\"\\n{shots}-Shot Learning:\")\n",
        "    print(f\"  Training Examples: {row['num_shots']:,}\")\n",
        "    print(f\"  Trainable Params: {row['trainable_params']:,} ({row['trainable_percentage']:.4f}%)\")\n",
        "    print(f\"  vs 500-shot: {samples_ratio:.2f}x training data\")\n",
        "    print(f\"  F1 Score: {row['f1_score']:.4f} ({f1_diff:+.4f} vs 500-shot)\")\n",
        "    print(f\"  Emissions: {row['emissions_kg']:.6f} kg ({emissions_diff:+.6f} vs 500-shot)\")\n",
        "    print(f\"  Training Time: {row['training_time_hours']:.2f} hours ({time_diff:+.2f} vs 500-shot)\")\n",
        "\n",
        "    # Efficiency metrics\n",
        "    efficiency_co2 = row['f1_score'] / row['emissions_kg'] if row['emissions_kg'] > 0 else 0\n",
        "    efficiency_time = row['f1_score'] / row['training_time_hours'] if row['training_time_hours'] > 0 else 0\n",
        "    efficiency_samples = row['f1_score'] / row['num_shots'] if row['num_shots'] > 0 else 0\n",
        "\n",
        "    print(f\"  Efficiency (F1/kg CO₂): {efficiency_co2:.2f}\")\n",
        "    print(f\"  Efficiency (F1/hour): {efficiency_time:.4f}\")\n",
        "    print(f\"  Efficiency (F1/sample): {efficiency_samples:.6f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RUoMqBkSBzII"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "txftDBXu_bNs",
        "outputId": "aaee664a-4579-463b-dc3a-473c1c69ad6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1cc7debc-8d7f-4aeb-b904-4f276f245dd0\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1cc7debc-8d7f-4aeb-b904-4f276f245dd0\")) {                    Plotly.newPlot(                        \"1cc7debc-8d7f-4aeb-b904-4f276f245dd0\",                        [{\"hovertemplate\":\"\\u003cb\\u003eCPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CPU Energy\",\"x\":[100,500,1000],\"y\":[0.001433358701289592,0.0014915879818423556,0.0015669080317347091],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eGPU Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#4ECDC4\"},\"name\":\"GPU Energy\",\"x\":[100,500,1000],\"y\":[0.00584057606134597,0.006068547910389993,0.006294073646366],\"type\":\"bar\"},{\"hovertemplate\":\"\\u003cb\\u003eRAM Energy\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{y:.6f} kWh\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#95E1D3\"},\"name\":\"RAM Energy\",\"x\":[100,500,1000],\"y\":[0.001281455796057777,0.0013334237306922262,0.00140086049219943],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":18},\"text\":\"Few-Shot: Energy Consumption by Number of Examples\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"xaxis\":{\"title\":{\"text\":\"Number of Training Examples\"}},\"yaxis\":{\"title\":{\"text\":\"Energy Consumption (kWh)\"}},\"barmode\":\"stack\",\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1cc7debc-8d7f-4aeb-b904-4f276f245dd0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT 1: Few-Shot Energy Consumption by Shots\n",
        "df_sorted_fewshot = results_df_fewshot.sort_values('num_shots')\n",
        "\n",
        "fig_fewshot_energy = go.Figure()\n",
        "\n",
        "fig_fewshot_energy.add_trace(go.Bar(\n",
        "    name='CPU Energy',\n",
        "    x=df_sorted_fewshot['num_shots'],\n",
        "    y=df_sorted_fewshot['cpu_energy_kwh'],\n",
        "    marker_color='#FF6B6B',\n",
        "    hovertemplate='<b>CPU Energy</b><br>%{y:.6f} kWh<br>Shots: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fewshot_energy.add_trace(go.Bar(\n",
        "    name='GPU Energy',\n",
        "    x=df_sorted_fewshot['num_shots'],\n",
        "    y=df_sorted_fewshot['gpu_energy_kwh'],\n",
        "    marker_color='#4ECDC4',\n",
        "    hovertemplate='<b>GPU Energy</b><br>%{y:.6f} kWh<br>Shots: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fewshot_energy.add_trace(go.Bar(\n",
        "    name='RAM Energy',\n",
        "    x=df_sorted_fewshot['num_shots'],\n",
        "    y=df_sorted_fewshot['ram_energy_kwh'],\n",
        "    marker_color='#95E1D3',\n",
        "    hovertemplate='<b>RAM Energy</b><br>%{y:.6f} kWh<br>Shots: %{x}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig_fewshot_energy.update_layout(\n",
        "    title=dict(text=\"Few-Shot: Energy Consumption by Number of Examples\", font=dict(size=18)),\n",
        "    xaxis_title='Number of Training Examples',\n",
        "    yaxis_title='Energy Consumption (kWh)',\n",
        "    barmode='stack',\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    ),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig_fewshot_energy.show()\n",
        "fig_fewshot_energy.write_html(\"/content/drive/MyDrive/fewshot_energy_by_shots.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "nUufORA0_Nnr",
        "outputId": "28a6af62-e1cd-44c3-b4a5-e91b1c6b5b3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d802920f-9d85-49a7-aa92-71ed92f2c3a9\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d802920f-9d85-49a7-aa92-71ed92f2c3a9\")) {                    Plotly.newPlot(                        \"d802920f-9d85-49a7-aa92-71ed92f2c3a9\",                        [{\"hovertemplate\":\"\\u003cb\\u003eF1 Score\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#4ECDC4\",\"width\":3},\"marker\":{\"line\":{\"color\":\"white\",\"width\":2},\"size\":12},\"mode\":\"lines+markers\",\"name\":\"F1 Score\",\"x\":[100,500,1000],\"y\":[0.009092133016800978,0.019856270121913332,0.02224507210654906],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eExact Match\\u003c\\u002fb\\u003e: %{y:.4f}\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#95E1D3\",\"dash\":\"dash\",\"width\":3},\"marker\":{\"size\":10},\"mode\":\"lines+markers\",\"name\":\"Exact Match\",\"x\":[100,500,1000],\"y\":[0.0004120652711389484,0.008241305422778969,0.006428218229767595],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eCO₂\\u003c\\u002fb\\u003e: %{y:.6f} kg\\u003cbr\\u003eShots: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6B6B\"},\"name\":\"CO₂ Emissions\",\"opacity\":0.6,\"x\":[100,500,1000],\"y\":[0.0022896107320986288,0.002380112213406321,0.0024786727253000643],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Number of Training Examples\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Performance Score\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"CO₂ Emissions (kg)\"}},\"title\":{\"font\":{\"size\":18},\"text\":\"Few-Shot: Performance vs Carbon Emissions\"},\"font\":{\"size\":13},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"height\":500,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d802920f-9d85-49a7-aa92-71ed92f2c3a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT 2: Few-Shot Performance & Emissions by Shots (Dual Y-axis)\n",
        "df_sorted_fewshot = results_df_fewshot.sort_values('num_shots')\n",
        "\n",
        "fig_fewshot_perf = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# F1 Score line\n",
        "fig_fewshot_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_fewshot['num_shots'],\n",
        "        y=df_sorted_fewshot['f1_score'],\n",
        "        name='F1 Score',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#4ECDC4', width=3),\n",
        "        marker=dict(size=12, line=dict(width=2, color='white')),\n",
        "        hovertemplate='<b>F1 Score</b>: %{y:.4f}<br>Shots: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# Exact Match line\n",
        "fig_fewshot_perf.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_sorted_fewshot['num_shots'],\n",
        "        y=df_sorted_fewshot['exact_match'],\n",
        "        name='Exact Match',\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='#95E1D3', width=3, dash='dash'),\n",
        "        marker=dict(size=10),\n",
        "        hovertemplate='<b>Exact Match</b>: %{y:.4f}<br>Shots: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=False\n",
        ")\n",
        "\n",
        "# CO2 Emissions bar\n",
        "fig_fewshot_perf.add_trace(\n",
        "    go.Bar(\n",
        "        x=df_sorted_fewshot['num_shots'],\n",
        "        y=df_sorted_fewshot['emissions_kg'],\n",
        "        name='CO₂ Emissions',\n",
        "        marker_color='#FF6B6B',\n",
        "        opacity=0.6,\n",
        "        hovertemplate='<b>CO₂</b>: %{y:.6f} kg<br>Shots: %{x}<extra></extra>'\n",
        "    ),\n",
        "    secondary_y=True\n",
        ")\n",
        "\n",
        "fig_fewshot_perf.update_xaxes(title_text=\"Number of Training Examples\")\n",
        "fig_fewshot_perf.update_yaxes(title_text=\"Performance Score\", secondary_y=False)\n",
        "fig_fewshot_perf.update_yaxes(title_text=\"CO₂ Emissions (kg)\", secondary_y=True)\n",
        "\n",
        "fig_fewshot_perf.update_layout(\n",
        "    title=dict(text=\"Few-Shot: Performance vs Carbon Emissions\", font=dict(size=18)),\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    font=dict(size=13),\n",
        "    hovermode='x unified',\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"right\",\n",
        "        x=1\n",
        "    )\n",
        ")\n",
        "\n",
        "fig_fewshot_perf.show()\n",
        "fig_fewshot_perf.write_html(\"/content/drive/MyDrive/fewshot_performance_emissions.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6Ma05_hK_N6d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "4FjF39hj_OJk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrtZG214KEs1"
      },
      "source": [
        "#Comparing And Testing All The Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_srVGCAvKJgG"
      },
      "outputs": [],
      "source": [
        "def test_model(model_path, examples, tokenizer_name=\"distilbert-base-uncased\"):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🧪 MODEL TESTING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "\n",
        "    # Auto-detect model type\n",
        "    is_lora = \"lora_adapters\" in model_path or \"lora\" in model_path.lower()\n",
        "\n",
        "    if is_lora:\n",
        "        method = \"LoRA\"\n",
        "        # Load base model + LoRA adapters\n",
        "        base_model = AutoModelForQuestionAnswering.from_pretrained(tokenizer_name)\n",
        "        model = PeftModel.from_pretrained(base_model, model_path)\n",
        "        print(f\"✅ Loaded LoRA model (base + adapters)\")\n",
        "    else:\n",
        "        # Detect if few-shot or full fine-tuning\n",
        "        method = \"Few-Shot\" if \"fewshot\" in model_path.lower() else \"Full Fine-tuning\"\n",
        "        model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "        print(f\"✅ Loaded {method} model\")\n",
        "\n",
        "    print(f\"📋 Method: {method}\")\n",
        "    print(f\"📂 Path: {model_path}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create pipeline\n",
        "    qa_pipeline = pipeline(\n",
        "        \"question-answering\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "\n",
        "    # Test all examples\n",
        "    results = []\n",
        "    for i, ex in enumerate(examples, 1):\n",
        "        # Get prediction\n",
        "        prediction = qa_pipeline(question=ex['question'], context=ex['context'])\n",
        "\n",
        "        # Store result\n",
        "        result = {\n",
        "            'example_num': i,\n",
        "            'method': method,\n",
        "            'question': ex['question'],\n",
        "            'context': ex['context'][:100] + \"...\" if len(ex['context']) > 100 else ex['context'],\n",
        "            'predicted_answer': prediction['answer'],\n",
        "            'expected_answer': ex.get('expected_answer', None),\n",
        "            'confidence': prediction['score'],\n",
        "            'start_position': prediction['start'],\n",
        "            'end_position': prediction['end']\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Print formatted output\n",
        "        print(f\"\\n📝 Example {i}\")\n",
        "        print(f\"Question: {ex['question']}\")\n",
        "        print(f\"Context: {ex['context'][:150]}{'...' if len(ex['context']) > 150 else ''}\")\n",
        "        print(f\"\\n✅ Predicted: '{prediction['answer']}'\")\n",
        "        print(f\"   Confidence: {prediction['score']:.2%}\")\n",
        "\n",
        "        # Check match with expected answer\n",
        "        if ex.get('expected_answer'):\n",
        "            expected = ex['expected_answer'].lower().strip()\n",
        "            predicted = prediction['answer'].lower().strip()\n",
        "            # Flexible matching: either one contains the other\n",
        "            match = (predicted in expected) or (expected in predicted)\n",
        "            print(f\"   Expected: '{ex['expected_answer']}'\")\n",
        "            print(f\"   Match: {'✓ YES' if match else '✗ NO'}\")\n",
        "\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QNVIDnOiKSO-"
      },
      "outputs": [],
      "source": [
        "test_examples = [\n",
        "     {\n",
        "        'question': \"What is the capital of France?\",\n",
        "        'context': \"Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\",\n",
        "        'expected_answer': \"Paris\"\n",
        "    },\n",
        "    {\n",
        "        'question': \"What does Google Colab provide access to?\",\n",
        "        'context': \"Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\",\n",
        "        'expected_answer': \"GPUs and TPUs\"\n",
        "    },\n",
        "    {\n",
        "        'question': \"When was Python created?\",\n",
        "        'context': \"Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\",\n",
        "        'expected_answer': \"1991\"\n",
        "    },\n",
        "    {\n",
        "        'question': \"Who invented the telephone?\",\n",
        "        'context': \"The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\",\n",
        "        'expected_answer': \"Alexander Graham Bell\"\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV9fzNuWKhYg",
        "outputId": "671d8a60-d526-428a-bb3a-b81f859f06f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.config', 'results_distilbert_80pct', 'results_distilbert_lora_r8_80pct', 'wandb', 'results_distilbert_lora_r4_80pct', 'results_distilbert_lora_r16_80pct', 'drive', 'results_distilbert_50pct', 'results_distilbert_fewshot_1000shots', 'results_distilbert_25pct', 'results_distilbert_fewshot_500shots', 'results_distilbert_fewshot_100shots', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir('/content/'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "378CIAFrKiap",
        "outputId": "8e06c364-1d63-4f39-b867-1b7ceb05f779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "TESTING FULL FINE-TUNING MODEL\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "\n",
            "================================================================================\n",
            "🧪 MODEL TESTING\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded Full Fine-tuning model\n",
            "📋 Method: Full Fine-tuning\n",
            "📂 Path: results_distilbert_80pct/final_model\n",
            "================================================================================\n",
            "\n",
            "📝 Example 1\n",
            "Question: What is the capital of France?\n",
            "Context: Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\n",
            "\n",
            "✅ Predicted: 'Paris'\n",
            "   Confidence: 99.16%\n",
            "   Expected: 'Paris'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 2\n",
            "Question: What does Google Colab provide access to?\n",
            "Context: Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\n",
            "\n",
            "✅ Predicted: 'GPUs and TPUs'\n",
            "   Confidence: 72.64%\n",
            "   Expected: 'GPUs and TPUs'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 3\n",
            "Question: When was Python created?\n",
            "Context: Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\n",
            "\n",
            "✅ Predicted: '1991'\n",
            "   Confidence: 87.87%\n",
            "   Expected: '1991'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 4\n",
            "Question: Who invented the telephone?\n",
            "Context: The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\n",
            "\n",
            "✅ Predicted: 'Alexander Graham Bell'\n",
            "   Confidence: 99.49%\n",
            "   Expected: 'Alexander Graham Bell'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test Full Fine-tuning\n",
        "print(\"🔷\" * 40)\n",
        "print(\"TESTING FULL FINE-TUNING MODEL\")\n",
        "print(\"🔷\" * 40)\n",
        "results_full_ft = test_model(\n",
        "    model_path=\"results_distilbert_80pct/final_model\",\n",
        "    examples=test_examples\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Z2FjZyBABPOk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0phY_mC_Ki4W",
        "outputId": "a90a5935-c22f-4086-b018-7bb676615804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "TESTING LORA MODEL\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "\n",
            "================================================================================\n",
            "🧪 MODEL TESTING\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded LoRA model (base + adapters)\n",
            "📋 Method: LoRA\n",
            "📂 Path: results_distilbert_lora_r16_80pct/lora_adapters\n",
            "================================================================================\n",
            "\n",
            "📝 Example 1\n",
            "Question: What is the capital of France?\n",
            "Context: Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\n",
            "\n",
            "✅ Predicted: 'Paris'\n",
            "   Confidence: 74.85%\n",
            "   Expected: 'Paris'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 2\n",
            "Question: What does Google Colab provide access to?\n",
            "Context: Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\n",
            "\n",
            "✅ Predicted: 'GPUs and TPUs'\n",
            "   Confidence: 38.71%\n",
            "   Expected: 'GPUs and TPUs'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 3\n",
            "Question: When was Python created?\n",
            "Context: Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\n",
            "\n",
            "✅ Predicted: '1991'\n",
            "   Confidence: 80.92%\n",
            "   Expected: '1991'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 4\n",
            "Question: Who invented the telephone?\n",
            "Context: The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\n",
            "\n",
            "✅ Predicted: 'Alexander Graham Bell'\n",
            "   Confidence: 95.46%\n",
            "   Expected: 'Alexander Graham Bell'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test LoRA\n",
        "print(\"\\n\" + \"🔷\" * 40)\n",
        "print(\"TESTING LORA MODEL\")\n",
        "print(\"🔷\" * 40)\n",
        "results_lora = test_model(\n",
        "    model_path=\"results_distilbert_lora_r16_80pct/lora_adapters\",\n",
        "    examples=test_examples\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HoMvBwJLBQ2t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3D_mKYRKjG6",
        "outputId": "06faa303-d5ae-45db-9859-c03bbc3220fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "TESTING FEW-SHOT MODEL\n",
            "🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷🔷\n",
            "\n",
            "================================================================================\n",
            "🧪 MODEL TESTING\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded Few-Shot model\n",
            "📋 Method: Few-Shot\n",
            "📂 Path: results_distilbert_fewshot_1000shots/final_model\n",
            "================================================================================\n",
            "\n",
            "📝 Example 1\n",
            "Question: What is the capital of France?\n",
            "Context: Paris is the capital and most populous city of France. It has been one of Europe's major centers of finance, diplomacy, commerce, fashion, and arts.\n",
            "\n",
            "✅ Predicted: 'Paris'\n",
            "   Confidence: 4.59%\n",
            "   Expected: 'Paris'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 2\n",
            "Question: What does Google Colab provide access to?\n",
            "Context: Google Colab provides free access to GPUs and TPUs, which makes it popular for deep learning.\n",
            "\n",
            "✅ Predicted: 'Google Colab provides free access to GPUs'\n",
            "   Confidence: 3.72%\n",
            "   Expected: 'GPUs and TPUs'\n",
            "   Match: ✗ NO\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 3\n",
            "Question: When was Python created?\n",
            "Context: Python was created by Guido van Rossum and first released in 1991. Its design philosophy emphasizes code readability.\n",
            "\n",
            "✅ Predicted: 'van Rossum'\n",
            "   Confidence: 3.33%\n",
            "   Expected: '1991'\n",
            "   Match: ✗ NO\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📝 Example 4\n",
            "Question: Who invented the telephone?\n",
            "Context: The telephone was invented by Alexander Graham Bell in 1876. He made the first successful telephone call on March 10, 1876.\n",
            "\n",
            "✅ Predicted: 'Alexander Graham Bell'\n",
            "   Confidence: 4.67%\n",
            "   Expected: 'Alexander Graham Bell'\n",
            "   Match: ✓ YES\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test Few-Shot\n",
        "print(\"\\n\" + \"🔷\" * 40)\n",
        "print(\"TESTING FEW-SHOT MODEL\")\n",
        "print(\"🔷\" * 40)\n",
        "test_results_fewshot = test_model(\n",
        "    model_path=\"results_distilbert_fewshot_1000shots/final_model\",\n",
        "    examples=test_examples\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Qohx_n_dKyeO"
      },
      "outputs": [],
      "source": [
        "all_results = {\n",
        "    \"Full FT (80%)\": results_full_ft,\n",
        "    \"LoRA (r=16, 80%)\": results_lora,\n",
        "    \"Few-Shot (1000)\": test_results_fewshot\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQQ204BfK75X"
      },
      "source": [
        "##Comparison Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ZW6YIBkRK7ZD"
      },
      "outputs": [],
      "source": [
        "def compare_models(results_dict):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📊 MODEL COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    comparison_data = []\n",
        "\n",
        "    for model_name, results in results_dict.items():\n",
        "        for result in results:\n",
        "            comparison_data.append({\n",
        "                'Model': model_name,\n",
        "                'Question': result['question'][:50] + \"...\",\n",
        "                'Predicted': result['predicted_answer'],\n",
        "                'Expected': result.get('expected_answer', 'N/A'),\n",
        "                'Confidence': result['confidence']\n",
        "            })\n",
        "\n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "    # Group by question to see how different models answer\n",
        "    for question in comparison_df['Question'].unique():\n",
        "        print(f\"\\nQUESTION: {question}\")\n",
        "        question_results = comparison_df[comparison_df['Question'] == question]\n",
        "        for _, row in question_results.iterrows():\n",
        "            exp = str(row['Expected']).lower()\n",
        "            pred = str(row['Predicted']).lower()\n",
        "            match_indicator = \"✓\" if (pred in exp or exp in pred) and exp != 'n/a' else \"✗\"\n",
        "            print(f\"  {match_indicator} {row['Model']:20s}: {row['Predicted']:40s} ({row['Confidence']:.1%})\")\n",
        "        expected_val = question_results.iloc[0]['Expected']\n",
        "        if expected_val != 'N/A':\n",
        "            print(f\"Expected ANSWER: {expected_val}\")\n",
        "\n",
        "    return comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8ko9x4RLGRq",
        "outputId": "ffa0e4c9-aab5-4afb-fc1f-e79fbb399b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 MODEL COMPARISON\n",
            "================================================================================\n",
            "\n",
            "QUESTION: What is the capital of France?...\n",
            "  ✓ Full FT (80%)       : Paris                                    (99.2%)\n",
            "  ✓ LoRA (r=16, 80%)    : Paris                                    (74.9%)\n",
            "  ✓ Few-Shot (1000)     : Paris                                    (4.6%)\n",
            "Expected ANSWER: Paris\n",
            "\n",
            "QUESTION: What does Google Colab provide access to?...\n",
            "  ✓ Full FT (80%)       : GPUs and TPUs                            (72.6%)\n",
            "  ✓ LoRA (r=16, 80%)    : GPUs and TPUs                            (38.7%)\n",
            "  ✗ Few-Shot (1000)     : Google Colab provides free access to GPUs (3.7%)\n",
            "Expected ANSWER: GPUs and TPUs\n",
            "\n",
            "QUESTION: When was Python created?...\n",
            "  ✓ Full FT (80%)       : 1991                                     (87.9%)\n",
            "  ✓ LoRA (r=16, 80%)    : 1991                                     (80.9%)\n",
            "  ✗ Few-Shot (1000)     : van Rossum                               (3.3%)\n",
            "Expected ANSWER: 1991\n",
            "\n",
            "QUESTION: Who invented the telephone?...\n",
            "  ✓ Full FT (80%)       : Alexander Graham Bell                    (99.5%)\n",
            "  ✓ LoRA (r=16, 80%)    : Alexander Graham Bell                    (95.5%)\n",
            "  ✓ Few-Shot (1000)     : Alexander Graham Bell                    (4.7%)\n",
            "Expected ANSWER: Alexander Graham Bell\n"
          ]
        }
      ],
      "source": [
        "comparison_df = compare_models(all_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "6-apjOn1LJOe"
      },
      "outputs": [],
      "source": [
        "# Save comparison results\n",
        "comparison_df.to_csv(\"/content/drive/MyDrive/model_comparison.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "xVCTSPqI5Fxs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yThvYIcx18Yc",
        "outputId": "9a40063d-ca6f-4942-dd6f-6bd4f40eb930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 COMPARISON: FULL FT vs LoRA vs FEW-SHOT\n",
            "================================================================================\n",
            "\n",
            "🔍 Training Efficiency Comparison:\n",
            "           training_method  train_samples  f1_score  emissions_kg  training_time_hours\n",
            "          Full Fine-Tuning          32579  0.467055      0.003866             0.049323\n",
            "          Full Fine-Tuning          65159  0.569492      0.007136             0.087358\n",
            "          Full Fine-Tuning         104255  0.609658      0.011166             0.136250\n",
            "                      LoRA         104255  0.493034      0.009820             0.135649\n",
            "                      LoRA         104255  0.512776      0.009813             0.135268\n",
            "                      LoRA         104255  0.545845      0.009804             0.135895\n",
            "Few-Shot (Frozen Backbone)            100  0.009092      0.002290             0.033616\n",
            "Few-Shot (Frozen Backbone)            500  0.019856      0.002380             0.034983\n",
            "Few-Shot (Frozen Backbone)           1000  0.022245      0.002479             0.036757\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"📊 COMPARISON: FULL FT vs LoRA vs FEW-SHOT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load previous results\n",
        "full_ft_results = pd.read_csv(\"/content/drive/MyDrive/distilbert_dataset_size_results.csv\")\n",
        "lora_results = pd.read_csv(\"/content/drive/MyDrive/distilbert_lora_results.csv\")\n",
        "results_fewshot = pd.read_csv(\"/content/drive/MyDrive/distilbert_fewshot_results.csv\")\n",
        "\n",
        "# Add method identifiers if not present\n",
        "if 'training_method' not in full_ft_results.columns:\n",
        "    full_ft_results['training_method'] = 'Full Fine-tuning'\n",
        "if 'training_method' not in lora_results.columns:\n",
        "    lora_results['training_method'] = 'LoRA'\n",
        "\n",
        "# Combine all results\n",
        "all_methods = pd.concat([full_ft_results, lora_results, results_fewshot], ignore_index=True)\n",
        "\n",
        "print(\"\\n🔍 Training Efficiency Comparison:\")\n",
        "print(all_methods[['training_method', 'train_samples','f1_score', 'emissions_kg', 'training_time_hours']].to_string(index=False))\n",
        "\n",
        "# Save combined results\n",
        "all_methods.to_csv(\"/content/drive/MyDrive/all_training_methods_comparison_distilbert.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0254a8671df14819bdccc13c636da06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d0732239da44eda6d2300f9f6cc00a",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb22bd6ddbc4b1f97b408ae410a70ee",
            "value": "Map: 100%"
          }
        },
        "025fdbbe3408452480d6983566441eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ff18e353554854a1c9924806097bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "032643bf52d6430eb723ded86297447e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "063061b48ad042d2b868dff535a51b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07117a05f70148eca3c2024019cbffbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a22e670f6f984dcf96e3c7d79a0e1a29",
            "placeholder": "​",
            "style": "IPY_MODEL_032643bf52d6430eb723ded86297447e",
            "value": "Map: 100%"
          }
        },
        "0a0f4f885aa14004b07eabef3facb6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c150eb26356940dfbef99ceaa479a48f",
            "placeholder": "​",
            "style": "IPY_MODEL_27423f5250634024b241b61da791fcd0",
            "value": " 1000/1000 [00:00&lt;00:00, 1794.98 examples/s]"
          }
        },
        "0a6d01f5033d44e4bf1b9d289ac89eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bae3ddc1d824da18335f8568342b173": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6fc7fc82a94fdd80e34910363202a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6d01f5033d44e4bf1b9d289ac89eac",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0d1f39e48474305b127305a4bdb6abc",
            "value": 231508
          }
        },
        "0f519a817e584ac780fbfc8b6be3b91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3181e33e6d574faf80c29d7054b2728b",
            "placeholder": "​",
            "style": "IPY_MODEL_063061b48ad042d2b868dff535a51b40",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0f6e2368ab2047db81b743d622bc4f90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10391fec057f4b16be70f3acf9ac10ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1197271181a241cf895c658712fc7ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8f333530c1640e6b71999ec62315cd5",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a961165d31e54a50ba2be0a9a6cddaba",
            "value": 48
          }
        },
        "14f070e40c6d4a6488a362ee11bfd552": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173a4dbe0c864beeaf7f3915b7a163ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92807d108358488d824333bf980baf1f",
            "placeholder": "​",
            "style": "IPY_MODEL_5072fa79f58145c9979813553647817f",
            "value": "README.md: "
          }
        },
        "1bb22bd6ddbc4b1f97b408ae410a70ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f11efa7a3074cb8ac5ef42912944d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521b274e0c914dcaa479a8a327982bbd",
            "max": 16369982,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bab04a025acf48fabff7e01b6c1c4ea9",
            "value": 16369982
          }
        },
        "22d0732239da44eda6d2300f9f6cc00a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23616464687a409e816a80b59fd10062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23726b814b3f43dd9a8961dac48d1feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7807b68ecc7743cbbba24fd1ed22d3aa",
              "IPY_MODEL_e302ea827e154c6ca2155e76268d138b",
              "IPY_MODEL_53b7e2e68d074b1c9026fc88a047cee3"
            ],
            "layout": "IPY_MODEL_f9bfd302e2104e38ada243b78326378a"
          }
        },
        "249e965ef9b442b68905c2562b88628a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0346b917a964f1ca0f656467d4fd714",
              "IPY_MODEL_3ce0f5c70b7447acaea287aa6d9c57dd",
              "IPY_MODEL_0a0f4f885aa14004b07eabef3facb6c4"
            ],
            "layout": "IPY_MODEL_3608ce978a8046dda77607c5f150bc33"
          }
        },
        "26415c2dff7641e2a1d69a75c27a913a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27423f5250634024b241b61da791fcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27f2ee99297c4f2e8efe5596d23f5dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8ca2b60a05648ccac592887ba0254c6",
            "placeholder": "​",
            "style": "IPY_MODEL_5a108186003f4ceaa3959ac72d7b2b7a",
            "value": "config.json: 100%"
          }
        },
        "2c413302a6d1413a91e221a54035ad48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e94733bc4c54eb7823243c066adfbec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71fe67e483645d89e7286719f7f3415",
            "placeholder": "​",
            "style": "IPY_MODEL_23616464687a409e816a80b59fd10062",
            "value": " 268M/268M [00:00&lt;00:00, 215MB/s]"
          }
        },
        "2f12c90a58014c46a9b62a9a45a6dc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7f829a4c3e4498ac17c25c40f7885b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f944c76f7b1469ba26e7181ea46e5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7f829a4c3e4498ac17c25c40f7885b",
            "placeholder": "​",
            "style": "IPY_MODEL_60f75fdadc584bdf959a074a2f1b473b",
            "value": "squad_v2/validation-00000-of-00001.parqu(…): 100%"
          }
        },
        "3067bdfae3fe4cfa98bf058f5846ba8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3181e33e6d574faf80c29d7054b2728b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d37f6449b1479cb15a5be414ae0e15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3436237e20a14c38a6022d2b8dde4cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4825fdd305a439f8be641d16f8ad879",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b2f13393d049efb90395d2bb9054b4",
            "value": " 466k/466k [00:00&lt;00:00, 2.76MB/s]"
          }
        },
        "358b210639694eacb5a4386f7605c407": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3608ce978a8046dda77607c5f150bc33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3884bb1ebc52495a82e676fdfe94cacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82ecfae2b00f488ea05bfc9937899dd7",
              "IPY_MODEL_38989071c87546c0af48454d71dc29e5",
              "IPY_MODEL_51031e0c4f144797bb08a801eff85ec8"
            ],
            "layout": "IPY_MODEL_a84ad6235d6b4e519e687464df4370b8"
          }
        },
        "38989071c87546c0af48454d71dc29e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61588aaa31de4d65bd8e9fa0afc82c78",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6509aaf2c7e475281a9a40de0819cac",
            "value": 11873
          }
        },
        "39077809c0514e67bbef1e65716aa4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14f070e40c6d4a6488a362ee11bfd552",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69a7436347d2401b9599ceac3d1b7652",
            "value": 11873
          }
        },
        "3a839281bcb34695bd2dc1a06f311002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca1f8d40efe949d886d8942822aa1ade",
              "IPY_MODEL_1f11efa7a3074cb8ac5ef42912944d11",
              "IPY_MODEL_5ce028160e6e40b68cb51f2f5360eda3"
            ],
            "layout": "IPY_MODEL_7b34aa654a7849ad8aa6e359ac03bc8b"
          }
        },
        "3a8430b6680948d3bbf7be2feb9d1f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af0f61c625b4f8e8b1351490135adc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc51a21357474a7abfc9cdf4e31ba6cd",
            "max": 130319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8caefc0fdfc46e6b52e0e2541218688",
            "value": 130319
          }
        },
        "3bd0937be04e4f5896f52b62ac14d894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e3f563b817403ea325b612e77d72b3",
            "placeholder": "​",
            "style": "IPY_MODEL_9c2cc9bc1be4478fb9f7243b08093aa2",
            "value": " 65159/65159 [00:37&lt;00:00, 1742.95 examples/s]"
          }
        },
        "3ce0f5c70b7447acaea287aa6d9c57dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee308a32731a440eaa9297b26dd1546d",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c413302a6d1413a91e221a54035ad48",
            "value": 1000
          }
        },
        "3f1d1f4451b04a7f93535155017fb3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "400f5f78ff5645478c926177a6691b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c954fb49d8764a8ba26b576c712e0124",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c72ffefd0b8e4b018c7d228d41124074",
            "value": 500
          }
        },
        "4329bd70bde84898a1b9274bb3010622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69488844fabb449f9ea0c461de2bdadf",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f86f0ef3b694464a81454fc99dc30737",
            "value": 483
          }
        },
        "450666f0c24b4b5d8b9fbb58caf8cc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27f2ee99297c4f2e8efe5596d23f5dd2",
              "IPY_MODEL_4329bd70bde84898a1b9274bb3010622",
              "IPY_MODEL_f9ba16f45a2547d0bcc9c7f2343d2464"
            ],
            "layout": "IPY_MODEL_455f3d1e2f904a0992b18ad7306aaf7f"
          }
        },
        "455f3d1e2f904a0992b18ad7306aaf7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46921d4706e74445b7ee3c59ec5aa607": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48bc3d14d6714126b3ab973383221385": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa5ac3ebc97462db2a81fb2a70b823b",
            "max": 65159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3067bdfae3fe4cfa98bf058f5846ba8c",
            "value": 65159
          }
        },
        "4be4bdc0437b450398c841a7308a10b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a739e61b6ea94425b79681c85157f113",
              "IPY_MODEL_0d6fc7fc82a94fdd80e34910363202a1",
              "IPY_MODEL_85960286dc3142fe9a060376945480af"
            ],
            "layout": "IPY_MODEL_b53693dbb5f34d23afb2718e014655ab"
          }
        },
        "4d992835ffbe4c1e8f8b70b72c5ffbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dd51c094a244bd7b81638c7b1fd2296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eba3a91cf6f4c088d57be6fd64d1bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c128edfc0fb649e2a617895583660b19",
            "placeholder": "​",
            "style": "IPY_MODEL_9f8eb54e4ca0441fbb3655acd5a20312",
            "value": " 32579/32579 [00:18&lt;00:00, 1824.65 examples/s]"
          }
        },
        "5072fa79f58145c9979813553647817f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51031e0c4f144797bb08a801eff85ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0c760d183474412a5be26bbba590b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_51432e9bca1f4d9f8fa414693aad8fd8",
            "value": " 11873/11873 [00:07&lt;00:00, 1761.89 examples/s]"
          }
        },
        "51432e9bca1f4d9f8fa414693aad8fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "520f06d7d1ed4d9197a96766b921abe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521b274e0c914dcaa479a8a327982bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b7e2e68d074b1c9026fc88a047cee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_676a6368aeff4eb28963ed15a41c11d7",
            "placeholder": "​",
            "style": "IPY_MODEL_d664bd4b05ea45149b5323c9d69ca465",
            "value": " 100/100 [00:00&lt;00:00, 1257.26 examples/s]"
          }
        },
        "545ddc94960244f48053a3a5bfd7dfde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552ce30d83d749759e2c67c0c522aec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ff827b9d6d464c9ad37f6ddb7b4d12",
            "placeholder": "​",
            "style": "IPY_MODEL_b2653f772ec54560b98c6cb0c3b20b8e",
            "value": "Map: 100%"
          }
        },
        "5a108186003f4ceaa3959ac72d7b2b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5abd0688edc741a69adbb2ab1da4556b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce028160e6e40b68cb51f2f5360eda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10391fec057f4b16be70f3acf9ac10ad",
            "placeholder": "​",
            "style": "IPY_MODEL_7e8f13db778840ad9a94b8d1c2f29ccb",
            "value": " 16.4M/16.4M [00:00&lt;00:00, 19.8MB/s]"
          }
        },
        "5fe82d285d914d4280d10e207debddfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f75fdadc584bdf959a074a2f1b473b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60fe6db9694543df98319625bff2ffe3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61588aaa31de4d65bd8e9fa0afc82c78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f622d3b3f446338fdbf8b1f88da86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60fe6db9694543df98319625bff2ffe3",
            "placeholder": "​",
            "style": "IPY_MODEL_a79610aa810c4631afa931a3a465e049",
            "value": " 130319/130319 [00:00&lt;00:00, 425196.79 examples/s]"
          }
        },
        "6200352379e04dcebfc8f9bc1828a53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07117a05f70148eca3c2024019cbffbd",
              "IPY_MODEL_48bc3d14d6714126b3ab973383221385",
              "IPY_MODEL_3bd0937be04e4f5896f52b62ac14d894"
            ],
            "layout": "IPY_MODEL_a1a599fb20184a24bb3a288fa222d054"
          }
        },
        "62031443c96745ee8efffac289035af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9254e15c133648cf97b171d34979d9f9",
            "placeholder": "​",
            "style": "IPY_MODEL_f8822d6585fe44b088d8ae76c9c162fa",
            "value": "Map: 100%"
          }
        },
        "64edd12242d945228af4c5a908d2685b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67485b4611d4438a8d1249433a0e071f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31d37f6449b1479cb15a5be414ae0e15",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea9afc46b7a3402b90fcdba7c361a806",
            "value": 1
          }
        },
        "676a6368aeff4eb28963ed15a41c11d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d3bab328594d699ad159c66a1fda91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69488844fabb449f9ea0c461de2bdadf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a7436347d2401b9599ceac3d1b7652": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f48bcdc82ed4e298ccd40a09d202b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62031443c96745ee8efffac289035af1",
              "IPY_MODEL_abe7f5e5b1694065b1c2e517e2ae179d",
              "IPY_MODEL_d4fa94ff87fd4defb76852520ea7c318"
            ],
            "layout": "IPY_MODEL_f981a641d56c42cd92e3ba0c52ea98ba"
          }
        },
        "702ee8bd72ca4f01a58ea4d88340493c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752def0daf0f440c96237a292041d75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75c1cb29719f490ab7192a3f0561d5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7807b68ecc7743cbbba24fd1ed22d3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4517f2067884448be69e76c138fecea",
            "placeholder": "​",
            "style": "IPY_MODEL_efc9cc8c98454097b93ffc40fe787911",
            "value": "Map: 100%"
          }
        },
        "7823f5f7a3624380bf3235d23bdb9263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78b892c5ced44dab96d957e3630b6572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79be407f83a14ae8b9e3a74b2d2bdb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f6e2368ab2047db81b743d622bc4f90",
            "placeholder": "​",
            "style": "IPY_MODEL_dda0557ff727447ab48237c9fe83df19",
            "value": " 500/500 [00:00&lt;00:00, 1665.08 examples/s]"
          }
        },
        "7b34aa654a7849ad8aa6e359ac03bc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8f13db778840ad9a94b8d1c2f29ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80ff827b9d6d464c9ad37f6ddb7b4d12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "818c7d49ecf34d70b451cb8900509481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8238bdd87e5748ab8526c373f52fefc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fe241adc8b54c8dad39b29c584078f6",
              "IPY_MODEL_39077809c0514e67bbef1e65716aa4b0",
              "IPY_MODEL_d6ffe11864344fcb9ce4e6df6f47aa4b"
            ],
            "layout": "IPY_MODEL_5fe82d285d914d4280d10e207debddfb"
          }
        },
        "82ecfae2b00f488ea05bfc9937899dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8430b6680948d3bbf7be2feb9d1f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_75c1cb29719f490ab7192a3f0561d5d0",
            "value": "Map: 100%"
          }
        },
        "83d28e6614064cf1808c652e1f99664c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85960286dc3142fe9a060376945480af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abd0688edc741a69adbb2ab1da4556b",
            "placeholder": "​",
            "style": "IPY_MODEL_4dd51c094a244bd7b81638c7b1fd2296",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]"
          }
        },
        "8c9953d48a454e31b2779f63ef30f24a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f13f8d4e3ef43e8907656c4808f0644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9254e15c133648cf97b171d34979d9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92807d108358488d824333bf980baf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930072e2d391409aaeb2286c307b97eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5637b25b569418f857ed80efa91fd6d",
            "max": 32579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d519d617b7104e51bf6ea1dec1191d3e",
            "value": 32579
          }
        },
        "935cbd1d8c834d45a613976992467e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97bdf9cd3ad943f2882dbe0f6920f657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b49b82da56c4a389fe300e554f2b6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed48aa0cf3224828b2a95b02c1e54f5e",
            "max": 1350511,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0d41af66a604b1eb5a2e0eca31021aa",
            "value": 1350511
          }
        },
        "9b722d05fa3d4fd09b5904f52477d004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a28ed594876e4809b3cb96b5928a9655",
            "placeholder": "​",
            "style": "IPY_MODEL_a26bf8cdd46b49ba82bde8afc79e4494",
            "value": "model.safetensors: 100%"
          }
        },
        "9c2cc9bc1be4478fb9f7243b08093aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f729c7b70284376a7538a164cb66ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f944c76f7b1469ba26e7181ea46e5e3",
              "IPY_MODEL_9b49b82da56c4a389fe300e554f2b6f4",
              "IPY_MODEL_ecf9cd9af17f46caa7061259e2d57334"
            ],
            "layout": "IPY_MODEL_46921d4706e74445b7ee3c59ec5aa607"
          }
        },
        "9f8eb54e4ca0441fbb3655acd5a20312": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fe241adc8b54c8dad39b29c584078f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebb3220e65fc4f82a70fc239754902b7",
            "placeholder": "​",
            "style": "IPY_MODEL_2f12c90a58014c46a9b62a9a45a6dc0f",
            "value": "Generating validation split: 100%"
          }
        },
        "a0346b917a964f1ca0f656467d4fd714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2593041f1d04c6ea8eeaab70681d332",
            "placeholder": "​",
            "style": "IPY_MODEL_752def0daf0f440c96237a292041d75d",
            "value": "Map: 100%"
          }
        },
        "a1a599fb20184a24bb3a288fa222d054": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22e670f6f984dcf96e3c7d79a0e1a29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2593041f1d04c6ea8eeaab70681d332": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26bf8cdd46b49ba82bde8afc79e4494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a28ed594876e4809b3cb96b5928a9655": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4387a39a156400ea211ce9cf0cf183d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5dc664513714c099de9ed45d042e403",
              "IPY_MODEL_3af0f61c625b4f8e8b1351490135adc2",
              "IPY_MODEL_61f622d3b3f446338fdbf8b1f88da86f"
            ],
            "layout": "IPY_MODEL_c675ea72988a4ad186f8597155905571"
          }
        },
        "a5b2f13393d049efb90395d2bb9054b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6468a135f68427f8a9b30e1fd9b55ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bae3ddc1d824da18335f8568342b173",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f13f8d4e3ef43e8907656c4808f0644",
            "value": 466062
          }
        },
        "a739e61b6ea94425b79681c85157f113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae2dbad9916e45f59828eda898b40a93",
            "placeholder": "​",
            "style": "IPY_MODEL_26415c2dff7641e2a1d69a75c27a913a",
            "value": "vocab.txt: 100%"
          }
        },
        "a79610aa810c4631afa931a3a465e049": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a84ad6235d6b4e519e687464df4370b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e5fd0b0add459f91c9e1fd6bb78113": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f333530c1640e6b71999ec62315cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a961165d31e54a50ba2be0a9a6cddaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaa5ac3ebc97462db2a81fb2a70b823b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe7f5e5b1694065b1c2e517e2ae179d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea94bafe0c114e0a9b2fa380e4fbba30",
            "max": 104255,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f1d1f4451b04a7f93535155017fb3f1",
            "value": 104255
          }
        },
        "abf5b82ccd3a44aab62df8eca75b2557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b722d05fa3d4fd09b5904f52477d004",
              "IPY_MODEL_d76bd6d56fac4089b445cbd276a44368",
              "IPY_MODEL_2e94733bc4c54eb7823243c066adfbec"
            ],
            "layout": "IPY_MODEL_e834f87ccd47400ba07940056387013f"
          }
        },
        "adfa979f20234a6eb2308408caeb1e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae0c12e59dd540dea02e5c9f6ace9876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_552ce30d83d749759e2c67c0c522aec1",
              "IPY_MODEL_400f5f78ff5645478c926177a6691b1f",
              "IPY_MODEL_79be407f83a14ae8b9e3a74b2d2bdb45"
            ],
            "layout": "IPY_MODEL_d47fc137f3474bde9e4886c061eb5dcc"
          }
        },
        "ae2dbad9916e45f59828eda898b40a93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb0fa2a1c3244149a24d9cd0a0cde56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dab7cce50eb649e3a0ad1ec6231dd6db",
              "IPY_MODEL_a6468a135f68427f8a9b30e1fd9b55ba",
              "IPY_MODEL_3436237e20a14c38a6022d2b8dde4cf8"
            ],
            "layout": "IPY_MODEL_83d28e6614064cf1808c652e1f99664c"
          }
        },
        "b0d1f39e48474305b127305a4bdb6abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0d41af66a604b1eb5a2e0eca31021aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2653f772ec54560b98c6cb0c3b20b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53693dbb5f34d23afb2718e014655ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e25975c2a5484f833fe23782a7a2f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab04a025acf48fabff7e01b6c1c4ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc51a21357474a7abfc9cdf4e31ba6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c760d183474412a5be26bbba590b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c128edfc0fb649e2a617895583660b19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c150eb26356940dfbef99ceaa479a48f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4825fdd305a439f8be641d16f8ad879": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5dc664513714c099de9ed45d042e403": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9953d48a454e31b2779f63ef30f24a",
            "placeholder": "​",
            "style": "IPY_MODEL_97bdf9cd3ad943f2882dbe0f6920f657",
            "value": "Generating train split: 100%"
          }
        },
        "c675ea72988a4ad186f8597155905571": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72ffefd0b8e4b018c7d228d41124074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8ca2b60a05648ccac592887ba0254c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8caefc0fdfc46e6b52e0e2541218688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c954fb49d8764a8ba26b576c712e0124": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1f8d40efe949d886d8942822aa1ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702ee8bd72ca4f01a58ea4d88340493c",
            "placeholder": "​",
            "style": "IPY_MODEL_e112f6f33e3e41c18be57e1eebaf151b",
            "value": "squad_v2/train-00000-of-00001.parquet: 100%"
          }
        },
        "d07a631dc63d4077997a51dd1bd68d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0254a8671df14819bdccc13c636da06e",
              "IPY_MODEL_930072e2d391409aaeb2286c307b97eb",
              "IPY_MODEL_4eba3a91cf6f4c088d57be6fd64d1bb5"
            ],
            "layout": "IPY_MODEL_ef8c455c0902409fbe6697185b68ff11"
          }
        },
        "d47fc137f3474bde9e4886c061eb5dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4fa94ff87fd4defb76852520ea7c318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_025fdbbe3408452480d6983566441eea",
            "placeholder": "​",
            "style": "IPY_MODEL_adfa979f20234a6eb2308408caeb1e25",
            "value": " 104255/104255 [01:01&lt;00:00, 1649.27 examples/s]"
          }
        },
        "d4ff5a54196c423f8edeb5e7206b4943": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d519d617b7104e51bf6ea1dec1191d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6509aaf2c7e475281a9a40de0819cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d664bd4b05ea45149b5323c9d69ca465": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ffe11864344fcb9ce4e6df6f47aa4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d3bab328594d699ad159c66a1fda91",
            "placeholder": "​",
            "style": "IPY_MODEL_4d992835ffbe4c1e8f8b70b72c5ffbfc",
            "value": " 11873/11873 [00:00&lt;00:00, 453323.73 examples/s]"
          }
        },
        "d71fe67e483645d89e7286719f7f3415": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76bd6d56fac4089b445cbd276a44368": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818c7d49ecf34d70b451cb8900509481",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3d80f1a5e2946a3ae9403835b65fef5",
            "value": 267954768
          }
        },
        "d7b3d7ad327f477080f7c92fb02ea7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_173a4dbe0c864beeaf7f3915b7a163ca",
              "IPY_MODEL_67485b4611d4438a8d1249433a0e071f",
              "IPY_MODEL_fff3cad08d934ee0961af6c59e65b549"
            ],
            "layout": "IPY_MODEL_f1067a5f8ae9465e963c268a459fe78b"
          }
        },
        "dab7cce50eb649e3a0ad1ec6231dd6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f97e13acad9543f899820f5cf3f185c8",
            "placeholder": "​",
            "style": "IPY_MODEL_64edd12242d945228af4c5a908d2685b",
            "value": "tokenizer.json: 100%"
          }
        },
        "dda0557ff727447ab48237c9fe83df19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e112f6f33e3e41c18be57e1eebaf151b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e240cc92999c4820a239e9ebee556339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f519a817e584ac780fbfc8b6be3b91f",
              "IPY_MODEL_1197271181a241cf895c658712fc7ae7",
              "IPY_MODEL_f43eb30acbd54898877c45035443bf0d"
            ],
            "layout": "IPY_MODEL_545ddc94960244f48053a3a5bfd7dfde"
          }
        },
        "e302ea827e154c6ca2155e76268d138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5e25975c2a5484f833fe23782a7a2f7",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_358b210639694eacb5a4386f7605c407",
            "value": 100
          }
        },
        "e834f87ccd47400ba07940056387013f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea94bafe0c114e0a9b2fa380e4fbba30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9afc46b7a3402b90fcdba7c361a806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebb3220e65fc4f82a70fc239754902b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecf9cd9af17f46caa7061259e2d57334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78b892c5ced44dab96d957e3630b6572",
            "placeholder": "​",
            "style": "IPY_MODEL_935cbd1d8c834d45a613976992467e89",
            "value": " 1.35M/1.35M [00:00&lt;00:00, 5.46MB/s]"
          }
        },
        "ed48aa0cf3224828b2a95b02c1e54f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edbb60106e8c43dcb822b50ed2086818": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee308a32731a440eaa9297b26dd1546d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8c455c0902409fbe6697185b68ff11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc9cc8c98454097b93ffc40fe787911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1067a5f8ae9465e963c268a459fe78b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d80f1a5e2946a3ae9403835b65fef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f43eb30acbd54898877c45035443bf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4ff5a54196c423f8edeb5e7206b4943",
            "placeholder": "​",
            "style": "IPY_MODEL_edbb60106e8c43dcb822b50ed2086818",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.90kB/s]"
          }
        },
        "f4517f2067884448be69e76c138fecea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5637b25b569418f857ed80efa91fd6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86f0ef3b694464a81454fc99dc30737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8822d6585fe44b088d8ae76c9c162fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f97e13acad9543f899820f5cf3f185c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f981a641d56c42cd92e3ba0c52ea98ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ba16f45a2547d0bcc9c7f2343d2464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8e5fd0b0add459f91c9e1fd6bb78113",
            "placeholder": "​",
            "style": "IPY_MODEL_520f06d7d1ed4d9197a96766b921abe1",
            "value": " 483/483 [00:00&lt;00:00, 62.0kB/s]"
          }
        },
        "f9bfd302e2104e38ada243b78326378a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e3f563b817403ea325b612e77d72b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff3cad08d934ee0961af6c59e65b549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ff18e353554854a1c9924806097bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_7823f5f7a3624380bf3235d23bdb9263",
            "value": " 8.92k/? [00:00&lt;00:00, 983kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
